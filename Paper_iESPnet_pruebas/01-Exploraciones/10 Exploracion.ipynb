{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DSF e iESPnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torchaudio.transforms    as T\n",
    "import pandas                   as pd\n",
    "\n",
    "from torchvision       import transforms\n",
    "from torch.utils.data  import DataLoader\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\n",
    "from Generator         import SeizureDatasetLabelTimev2, scale_spec, permute_spec, smoothing_label\n",
    "from Model             import iESPnet\n",
    "from TrainEval         import train_model_opt, test_model, train_model, get_thr_output, get_performance_indices\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\n",
    "from utilit_train_test import make_weights_for_balanced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a38ace490f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direccion donde se encuentran los espectrogramas \n",
    "\n",
    "SPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\n",
    "meta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\n",
    "\n",
    "df_meta        = pd.read_csv(meta_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_MASK_PARAM = 10\n",
    "TIME_MASK_PARAN = 20\n",
    "N_CLASSES       = 1\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 128\n",
    "epochs          = 20\n",
    "num_workers     = 4\n",
    "\n",
    "\n",
    "save_path       = 'models_DSF_iESPnet/'\n",
    "patients        = df_meta['rns_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "           \"n_cnn_layers\" : 3,\n",
    "           \"n_rnn_layers\" : 3,\n",
    "           \"rnn_dim\"      : [150, 100, 50],\n",
    "           \"n_class\"      : N_CLASSES,\n",
    "           \"out_ch\"       : [8,8,16],\n",
    "           \"dropout\"      : 0.3,\n",
    "           \"learning_rate\": learning_rate,\n",
    "           \"batch_size\"   : batch_size,\n",
    "           \"num_workers\"  : num_workers,\n",
    "           \"epochs\"       : epochs\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo para un unico paciente s = 0 --- patient = PIT-RNS1603\n",
    "\n",
    "s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = iESPnet(\n",
    "                hparams['n_cnn_layers'],\n",
    "                hparams['n_rnn_layers'],\n",
    "                hparams['rnn_dim'],\n",
    "                hparams['n_class'],\n",
    "                hparams['out_ch'],\n",
    "                hparams['dropout'],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for subject PIT-RNS1603 [s]: 0\n"
     ]
    }
   ],
   "source": [
    "save_runs        = save_path + patients[s] + '/runs/'\n",
    "save_models      = save_path + patients[s] + '/models/'\n",
    "save_predictions = save_path + patients[s] + '/results/'\n",
    "save_figs        = save_path + patients[s] + '/figs/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "if not os.path.exists(save_runs):\n",
    "    os.makedirs(save_runs)\n",
    "    \n",
    "if not os.path.exists(save_models):\n",
    "    os.makedirs(save_models)\n",
    "    \n",
    "if not os.path.exists(save_predictions):\n",
    "    os.makedirs(save_predictions)\n",
    "    \n",
    "if not os.path.exists(save_figs):\n",
    "    os.makedirs(save_figs)\n",
    "\n",
    "print('Running training for subject ' + patients[s] + ' [s]: ' + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train y test de df_meta\n",
    "\n",
    "train_df = df_meta.copy()\n",
    "test_df  = df_meta[df_meta['rns_id'] == patients[s]]\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_df.drop(train_df[train_df['rns_id'] == patients[s]].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders creados\n",
    "\n",
    "train_data_ori = SeizureDatasetLabelTimev2(\n",
    "                                           file=train_df,\n",
    "                                           root_dir=SPE_DIR,\n",
    "                                           transform=None, \n",
    "                                           target_transform=smoothing_label(),\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aca esta el cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "                                        T.FrequencyMasking(FREQ_MASK_PARAM),\n",
    "                                        T.TimeMasking(TIME_MASK_PARAN), \n",
    "                                        permute_spec()                                                                     \n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation only in train data\n",
    "\n",
    "'''\n",
    "\n",
    "train_data_trf = SeizureDatasetLabelTimev2(\n",
    "                                            file=train_df,\n",
    "                                            root_dir=SPE_DIR,\n",
    "                                            transform=transform_train1, \n",
    "                                            target_transform=smoothing_label() \n",
    "                                           )\n",
    "\n",
    "train_data = torch.utils.data.ConcatDataset([train_data_ori, train_data_trf1])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasta aca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data should be balanced, just be \"as it is\"\n",
    "\n",
    "test_data = SeizureDatasetLabelTimev2(\n",
    "                                      file=test_df,\n",
    "                                      root_dir=SPE_DIR,\n",
    "                                      transform=None,\n",
    "                                      target_transform=smoothing_label()  \n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se debe balancear train_df\n",
    "weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=2)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = save_models + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following pytorch suggestion to speed up training\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "kwargs       = {'num_workers': hparams[\"num_workers\"], 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = DataLoader(train_data, batch_size=hparams[\"batch_size\"], sampler=sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''El dataloader es un iterador y se debe interpretar como tal, para acceder se debe utilizar o enumerate o next'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses, avg_train_f1 = train_model_opt(model, hparams, epochs, train_data, sampler, outputfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_thalamus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
