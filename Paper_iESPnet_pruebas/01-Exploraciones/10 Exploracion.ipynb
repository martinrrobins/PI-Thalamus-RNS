{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DSF e iESPnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torchaudio.transforms    as T\n",
    "import torch.optim              as optim\n",
    "import pandas                   as pd\n",
    "\n",
    "from torchvision       import transforms\n",
    "from torch.utils.data  import DataLoader\n",
    "from torch             import nn\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\n",
    "from Generator         import SeizureDatasetLabelTimev2, scale_spec, permute_spec, smoothing_label\n",
    "from Model             import iESPnet\n",
    "from TrainEval         import train_model_opt, test_model, train_model, get_thr_output, get_performance_indices\n",
    "from IO                import get_spectrogram_2\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\n",
    "from utilit_train_test import make_weights_for_balanced_classes\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\n",
    "from models                         import DynamicSpatialFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7372519fd0f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direccion donde se encuentran los espectrogramas \n",
    "\n",
    "SPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\n",
    "meta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\n",
    "\n",
    "df_meta        = pd.read_csv(meta_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe exploración\n",
    "\n",
    "#df_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_meta.rns_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad de datos por pacientes\n",
    "\n",
    "#df_meta.rns_id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad de datos por pacientes\n",
    "\n",
    "#df_meta.rns_id.value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta[df_meta['rns_id' ]== 'PIT-RNS1713']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuación train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables iESPnet\n",
    "\n",
    "FREQ_MASK_PARAM = 10\n",
    "TIME_MASK_PARAN = 20\n",
    "N_CLASSES       = 1\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 64 #128\n",
    "epochs          = 20\n",
    "num_workers     = 4\n",
    "\n",
    "\n",
    "save_path       = 'models_DSF_iESPnet/'\n",
    "patients        = df_meta['rns_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables DSF\n",
    "\n",
    "denoising          = 'autoreject'   # 'autoreject' 'data_augm' \n",
    "model              = 'stager_net'\n",
    "dsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\n",
    "mlp_input          = 'log_diag_cov'\n",
    "dsf_soft_thresh    = False\n",
    "dsf_n_out_channels = None\n",
    "n_channels         = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nhparams1 = {\\n           \"n_channels\"        : 4,\\n           \"mlp_input\"         : mlp_input,\\n           \"n_out_channels\"    : dsf_n_out_channels,\\n           \"apply_soft_thresh\" : dsf_soft_thresh,\\n          }\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiperparametros DynamicSpatialFilter\n",
    "\n",
    "'''\n",
    "\n",
    "hparams1 = {\n",
    "           \"n_channels\"        : 4,\n",
    "           \"mlp_input\"         : mlp_input,\n",
    "           \"n_out_channels\"    : dsf_n_out_channels,\n",
    "           \"apply_soft_thresh\" : dsf_soft_thresh,\n",
    "          }\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros iESPnet\n",
    "\n",
    "hparams = {\n",
    "           \"n_cnn_layers\" : 3,\n",
    "           \"n_rnn_layers\" : 3,\n",
    "           \"rnn_dim\"      : [150, 100, 50],\n",
    "           \"n_class\"      : N_CLASSES,\n",
    "           \"out_ch\"       : [8,8,16],\n",
    "           \"dropout\"      : 0.3,\n",
    "           \"learning_rate\": learning_rate,\n",
    "           \"batch_size\"   : batch_size,\n",
    "           \"num_workers\"  : num_workers,\n",
    "           \"epochs\"       : epochs\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo para un unico paciente s = 0 --- patient = PIT-RNS1603\n",
    "\n",
    "s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DynamicSpatialFilter(\n",
    "                              n_channels, \n",
    "                              mlp_input            = mlp_input, \n",
    "                              n_out_channels       = dsf_n_out_channels, \n",
    "                              apply_soft_thresh    = dsf_soft_thresh\n",
    "                             )\n",
    "\n",
    "model2 = iESPnet(\n",
    "                hparams['n_cnn_layers'],\n",
    "                hparams['n_rnn_layers'],\n",
    "                hparams['rnn_dim'],\n",
    "                hparams['n_class'],\n",
    "                hparams['out_ch'],\n",
    "                hparams['dropout'],\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for subject PIT-RNS1603 [s]: 0\n"
     ]
    }
   ],
   "source": [
    "save_runs        = save_path + patients[s] + '/runs/'\n",
    "save_models      = save_path + patients[s] + '/models/'\n",
    "save_predictions = save_path + patients[s] + '/results/'\n",
    "save_figs        = save_path + patients[s] + '/figs/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "if not os.path.exists(save_runs):\n",
    "    os.makedirs(save_runs)\n",
    "    \n",
    "if not os.path.exists(save_models):\n",
    "    os.makedirs(save_models)\n",
    "    \n",
    "if not os.path.exists(save_predictions):\n",
    "    os.makedirs(save_predictions)\n",
    "    \n",
    "if not os.path.exists(save_figs):\n",
    "    os.makedirs(save_figs)\n",
    "\n",
    "print('Running training for subject ' + patients[s] + ' [s]: ' + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train y test de df_meta\n",
    "\n",
    "train_df = df_meta.copy()\n",
    "test_df  = df_meta[df_meta['rns_id'] == patients[s]]\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_df.drop(train_df[train_df['rns_id'] == patients[s]].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders creados\n",
    "\n",
    "train_data = SeizureDatasetLabelTimev2(\n",
    "                                       file=train_df,\n",
    "                                       root_dir=SPE_DIR,\n",
    "                                       transform=None, \n",
    "                                       target_transform=smoothing_label(),\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "                                        T.FrequencyMasking(FREQ_MASK_PARAM),\n",
    "                                        T.TimeMasking(TIME_MASK_PARAN), \n",
    "                                        permute_spec()                                                                     \n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aca esta el cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntrain_data_trf = SeizureDatasetLabelTimev2(\\n                                            file=train_df,\\n                                            root_dir=SPE_DIR,\\n                                            transform=transform_train1, \\n                                            target_transform=smoothing_label() \\n                                           )\\n\\ntrain_data = torch.utils.data.ConcatDataset([train_data_ori, train_data_trf1])\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data augmentation only in train data\n",
    "\n",
    "'''\n",
    "\n",
    "train_data_trf = SeizureDatasetLabelTimev2(\n",
    "                                            file=train_df,\n",
    "                                            root_dir=SPE_DIR,\n",
    "                                            transform=transform_train1, \n",
    "                                            target_transform=smoothing_label() \n",
    "                                           )\n",
    "\n",
    "train_data = torch.utils.data.ConcatDataset([train_data_ori, train_data_trf1])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasta aca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data should be balanced, just be \"as it is\"\n",
    "\n",
    "test_data = SeizureDatasetLabelTimev2(\n",
    "                                      file=test_df,\n",
    "                                      root_dir=SPE_DIR,\n",
    "                                      transform=None,\n",
    "                                      target_transform=smoothing_label()  \n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se debe balancear train_df\n",
    "weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = save_models + 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Función make_weights_for_balanced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "#classes = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_sample_count = np.zeros(len(classes,), dtype=int)\n",
    "\n",
    "#for n, cl in enumerate(classes):\n",
    "#    class_sample_count[n] = sum(train_df.label==cl)\n",
    "#class_sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = (1 / class_sample_count)\n",
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = train_df.label.to_numpy()\n",
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_weight = weights[target]\n",
    "#samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_concat = 2\n",
    "#for i in range(n_concat):\n",
    "#    if i == 0:\n",
    "#        sampler = samples_weight\n",
    "#        print(sampler.shape)\n",
    "#    else:\n",
    "#        sampler = np.hstack((sampler, samples_weight))\n",
    "#        print(sampler.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion train_model_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses = []\n",
    "avg_train_accs   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following pytorch suggestion to speed up training\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables o atributos de la funcion train_model_opt\n",
    "\n",
    "# model1, model2, hparams, epochs, train_data, transform_train, sampler, save_path\n",
    "\n",
    "# model1: DSF\n",
    "# model2: iESPnet\n",
    "# hparams: \n",
    "# epochs:\n",
    "# train_data: dataloader de iEEG con smoothing label\n",
    "# transforn_train: transformación (augmentation) de espectrogramas \n",
    "# sampler:\n",
    "# save_path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataloader es un iterador y se debe interpretar como tal, para acceder se debe utilizar o enumerate o next'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''El dataloader es un iterador y se debe interpretar como tal, para acceder se debe utilizar o enumerate o next'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': hparams[\"num_workers\"], 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=hparams[\"batch_size\"], sampler=sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model1 to device\n",
    "\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model1 to device\n",
    "\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 120\n"
     ]
    }
   ],
   "source": [
    "print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 1654837\n"
     ]
    }
   ],
   "source": [
    "print('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "optimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler1 = optim.lr_scheduler.OneCycleLR(\n",
    "                                            optimizer1, \n",
    "                                            max_lr          = hparams['learning_rate'], \n",
    "                                            steps_per_epoch = int(len(train_loader)),\n",
    "                                            epochs          = hparams['epochs'],\n",
    "                                            anneal_strategy = 'linear'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler2 = optim.lr_scheduler.OneCycleLR(\n",
    "                                            optimizer2, \n",
    "                                            max_lr          = hparams['learning_rate'], \n",
    "                                            steps_per_epoch = int(len(train_loader)),\n",
    "                                            epochs          = hparams['epochs'],\n",
    "                                            anneal_strategy = 'linear'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfor epoch in range(1, epochs + 1):\\n    # agregar todos los argumentos necesarios\\n    train_losses, train_aucpr = training_DSF_iESPnet(model, device, train_loader, transform_train, criterion, optimizer, scheduler, epoch)\\n    \\n    train_loss = np.average(train_losses)\\n\\n    avg_train_losses.append(train_loss)\\n    \\n    avg_train_accs.append(train_aucpr)\\n    \\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # agregar todos los argumentos necesarios\n",
    "    train_losses, train_aucpr = training_DSF_iESPnet(model, device, train_loader, transform_train, criterion, optimizer, scheduler, epoch)\n",
    "    \n",
    "    train_loss = np.average(train_losses)\n",
    "\n",
    "    avg_train_losses.append(train_loss)\n",
    "    \n",
    "    avg_train_accs.append(train_aucpr)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Función training_DSF_iESPnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables o atributos de la funcion training_DSF_iESPnet\n",
    "\n",
    "# model1, model2, device, train_loader, transform_train, criterion, optimizer, scheduler, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.0\n",
    "train_losses = []\n",
    "cont = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, _data in enumerate(train_loader):\n",
    "\n",
    "    cont+=1\n",
    "    eeg, labels = _data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 22500])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 181])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg, labels = eeg.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1.zero_grad(set_to_none=True)\n",
    "optimizer2.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "DynamicSpatialFilter input shape: torch.Size([64, 4, 22500])\n",
      "After reshaping: torch.Size([64, 1, 4, 22500])\n",
      "SpatialFeatureExtractor input shape: torch.Size([64, 1, 4, 22500])\n",
      "SpatialFeatureExtractor output shape: torch.Size([64, 1, 4])\n",
      "MLP output shape: torch.Size([64, 1, 20])\n",
      "W shape: torch.Size([64, 1, 4, 4])\n",
      "Bias shape: torch.Size([64, 1, 4, 1])\n",
      "Output shape: torch.Size([64, 1, 4, 22500])\n"
     ]
    }
   ],
   "source": [
    "outputs1 = model1(eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 22500])\n"
     ]
    }
   ],
   "source": [
    "# reshape para tener el mismo tamaño que necesita el espectrograma\n",
    "\n",
    "outputs1 = outputs1.squeeze(1)\n",
    "print(outputs1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = outputs1.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables y atributos para crear el espectrograma\n",
    "\n",
    "# signal, fs, n_fft = 256, win_len = None, hop_len = None, power = 2.0\n",
    "\n",
    "ECOG_SAMPLE_RATE = 250\n",
    "ECOG_CHANNELS    = 4\n",
    "TT               = 1000 # window length\n",
    "SPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\n",
    "overlap          = 500 \n",
    "SPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\n",
    "SPEC_NFFT        = 500  # to see changes in 0.5 reso\n",
    "top_db           = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = get_spectrogram_2(outputs1, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4, 120, 181)\n"
     ]
    }
   ],
   "source": [
    "print(spectrograms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 120, 181])\n"
     ]
    }
   ],
   "source": [
    "spectrograms = torch.from_numpy(spectrograms)\n",
    "print(spectrograms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualización de espectrogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_transformed =  transform_train(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 120, 181])\n"
     ]
    }
   ],
   "source": [
    "print(spectrograms_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms2train = torch.cat((spectrograms, spectrograms_transformed), axis=0) #fijate acá el axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms2train = spectrograms2train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2train = torch.cat((labels, labels), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model2(spectrograms2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "probs = m(output2)\n",
    "\n",
    "y_true  = torch.max(labels2train, dim =1)[0]\n",
    "y_pred  = torch.max(probs, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cont==1:\n",
    "    Y_true = y_true\n",
    "    Y_pred = y_pred\n",
    "\n",
    "else:                \n",
    "    Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "    Y_pred = torch.cat((Y_pred, y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss\n",
    "loss = criterion(output2, labels2train)\n",
    "# Perform backward pass\n",
    "loss.backward()\n",
    "train_loss += loss.item()\n",
    "# Perform optimization\n",
    "optimizer1.step()\n",
    "optimizer2.step()\n",
    "scheduler1.step()\n",
    "scheduler2.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_thalamus)",
   "language": "python",
   "name": "env_thalamus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
