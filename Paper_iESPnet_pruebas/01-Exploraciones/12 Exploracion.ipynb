{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibilidad de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import torchaudio.transforms    as T\n",
    "import torch.optim              as optim\n",
    "import pandas                   as pd\n",
    "import numpy                    as np\n",
    "\n",
    "from torchvision       import transforms\n",
    "from torch.utils.data  import DataLoader\n",
    "from torch             import nn\n",
    "from sklearn.metrics   import balanced_accuracy_score, recall_score, precision_score, mean_absolute_error, average_precision_score\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\n",
    "from utilit_train_test import make_weights_for_balanced_classes\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\n",
    "from Generator         import SeizureDatasetLabelTimev2, permute_spec, smoothing_label\n",
    "from Model             import iESPnet\n",
    "from TrainEval         import train_model_v2, test_model_v2, get_performance_indices\n",
    "from IO                import get_spectrogram_2\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\n",
    "from models            import DynamicSpatialFilter\n",
    "\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "# set the seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direccion donde se encuentran los espectrogramas \n",
    "SPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\n",
    "meta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\n",
    "\n",
    "df_meta        = pd.read_csv(meta_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables iESPnet\n",
    "FREQ_MASK_PARAM    = 10\n",
    "TIME_MASK_PARAN    = 20\n",
    "N_CLASSES          = 1\n",
    "learning_rate      = 1e-3\n",
    "batch_size         = 64    #128\n",
    "epochs             = 20\n",
    "num_workers        = 4\n",
    "\n",
    "save_path          = 'models_DSF_iESPnet_prueba/'\n",
    "patients           = df_meta['rns_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables DSF\n",
    "denoising          = 'autoreject'   # 'autoreject' 'data_augm' \n",
    "model              = 'stager_net'\n",
    "dsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\n",
    "mlp_input          = 'log_diag_cov'\n",
    "dsf_soft_thresh    = False\n",
    "dsf_n_out_channels = None\n",
    "n_channels         = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros iESPnet\n",
    "hparams = {\n",
    "           \"n_cnn_layers\" : 3,\n",
    "           \"n_rnn_layers\" : 3,\n",
    "           \"rnn_dim\"      : [150, 100, 50],\n",
    "           \"n_class\"      : N_CLASSES,\n",
    "           \"out_ch\"       : [8,8,16],\n",
    "           \"dropout\"      : 0.3,\n",
    "           \"learning_rate\": learning_rate,\n",
    "           \"batch_size\"   : batch_size,\n",
    "           \"num_workers\"  : num_workers,\n",
    "           \"epochs\"       : epochs\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train y test de df_meta\n",
    "test_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\n",
    "vali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_meta.copy() # hace falta resetear el indice de train_df?\n",
    "test_df  = pd.DataFrame()\n",
    "vali_df  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range (len(test_id)):\n",
    "    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\n",
    "\n",
    "for s in range(len(vali_id)):\n",
    "    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\n",
    "    vali_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentos que se van a realizar\n",
    "experiments_1 = ['exp1','exp2','exp3']\n",
    "experiments_2 = ['.1','.2','.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DynamicSpatialFilter(\n",
    "                              n_channels, \n",
    "                              mlp_input            = mlp_input, \n",
    "                              n_out_channels       = dsf_n_out_channels, \n",
    "                              apply_soft_thresh    = dsf_soft_thresh\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = iESPnet(\n",
    "                 hparams['n_cnn_layers'],\n",
    "                 hparams['n_rnn_layers'],\n",
    "                 hparams['rnn_dim'],\n",
    "                 hparams['n_class'],\n",
    "                 hparams['out_ch'],\n",
    "                 hparams['dropout'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/runs/'\n",
    "save_models      = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/models/'\n",
    "save_predictions = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/results/'\n",
    "save_figs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/figs/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "if not os.path.exists(save_runs):\n",
    "    os.makedirs(save_runs)\n",
    "\n",
    "if not os.path.exists(save_models):\n",
    "    os.makedirs(save_models)\n",
    "\n",
    "if not os.path.exists(save_predictions):\n",
    "    os.makedirs(save_predictions)\n",
    "\n",
    "if not os.path.exists(save_figs):\n",
    "    os.makedirs(save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for: exp1.1\n"
     ]
    }
   ],
   "source": [
    "print('Running training for: ' + experiments_1[s] +  experiments_2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders creados\n",
    "train_data = SeizureDatasetLabelTimev2(\n",
    "                                       file             = train_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None, \n",
    "                                       target_transform = smoothing_label(),\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data should be balanced, just be \"as it is\"\n",
    "test_data  = SeizureDatasetLabelTimev2(\n",
    "                                       file             = test_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None,\n",
    "                                       target_transform = smoothing_label()  \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data should be balanced, just be \"as it is\"\n",
    "vali_data  = SeizureDatasetLabelTimev2(\n",
    "                                       file             = vali_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None,\n",
    "                                       target_transform = smoothing_label()  \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation \n",
    "transform_train = transforms.Compose([\n",
    "                                      T.FrequencyMasking(FREQ_MASK_PARAM),\n",
    "                                      T.TimeMasking(TIME_MASK_PARAN), \n",
    "                                      permute_spec()                                                                     \n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = save_models + 'model_' + str(experiments_1[s] + experiments_2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "avg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\n",
    "                                                                            model1, \n",
    "                                                                            model2, \n",
    "                                                                            hparams, \n",
    "                                                                            epochs, \n",
    "                                                                            train_data, \n",
    "                                                                            vali_data, \n",
    "                                                                            transform_train, \n",
    "                                                                            sampler, \n",
    "                                                                            outputfile,\n",
    "                                                                            experiments_1[s],\n",
    "                                                                            experiments_2[j]\n",
    "                                                                           )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses = []\n",
    "train_accs       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_valid_losses = [] \n",
    "valid_accs       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following pytorch suggestion to speed up training\n",
    "torch.backends.cudnn.benchmark     = True # cambio para reproducibilidad\n",
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': hparams[\"num_workers\"], 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = hparams[\"batch_size\"], sampler = sampler, **kwargs)\n",
    "valid_loader = DataLoader(vali_data, batch_size = hparams[\"batch_size\"], shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model1 to device\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model2 to device\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 120\n",
      "Num Model Parameters 1654837\n"
     ]
    }
   ],
   "source": [
    "print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))\n",
    "print('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\n",
    "optimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "scheduler1 = optim.lr_scheduler.OneCycleLR(\n",
    "                                           optimizer1, \n",
    "                                           max_lr          = hparams['learning_rate'], \n",
    "                                           steps_per_epoch = int(len(train_loader)),\n",
    "                                           epochs          = hparams['epochs'],\n",
    "                                           anneal_strategy = 'linear'\n",
    "                                          )\n",
    "\n",
    "scheduler2 = optim.lr_scheduler.OneCycleLR(\n",
    "                                           optimizer2, \n",
    "                                           max_lr          = hparams['learning_rate'], \n",
    "                                           steps_per_epoch = int(len(train_loader)*2),\n",
    "                                           epochs          = hparams['epochs'],\n",
    "                                           anneal_strategy = 'linear'\n",
    "                                          )\n",
    "      \n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "train_losses, train_aucpr = training_DSF_iESPnet(\n",
    "                                                 model1, \n",
    "                                                 model2, \n",
    "                                                 device, \n",
    "                                                 train_loader, \n",
    "                                                 transform_train, \n",
    "                                                 criterion, \n",
    "                                                 optimizer1, \n",
    "                                                 optimizer2, \n",
    "                                                 scheduler1, \n",
    "                                                 scheduler2, \n",
    "                                                 epoch,\n",
    "                                                 experiment_1,\n",
    "                                                 experiment_2\n",
    "                                                )\n",
    "\n",
    "'''                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1 = experiments_1[s]\n",
    "experiment_2 = experiments_2[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spectrogram\n",
    "ECOG_SAMPLE_RATE = 250\n",
    "ECOG_CHANNELS    = 4\n",
    "TT               = 1000 # window length\n",
    "SPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\n",
    "overlap          = 500 \n",
    "SPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\n",
    "SPEC_NFFT        = 500  # to see changes in 0.5 reso\n",
    "if   experiment_2 == '.1':  \n",
    "    top_db       = 40.0\n",
    "elif experiment_2 == '.2':\n",
    "    top_db       = 60.0\n",
    "elif experiment_2 == '.3':\n",
    "    top_db       = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss   = 0.0\n",
    "train_losses = []\n",
    "cont         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, _data in enumerate(train_loader):\n",
    "    #if batch_idx == 1:  # Saltar la primera iteración\n",
    "        #continue\n",
    "\n",
    "    cont+=1\n",
    "    eeg, labels = _data \n",
    "    eeg, labels = eeg.to(device), labels.to(device)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer1.zero_grad(set_to_none=True)\n",
    "    optimizer2.zero_grad(set_to_none=True)\n",
    "\n",
    "    # Perform forward pass to DSF\n",
    "    outputs1 = model1(eeg)  # (batch, n_class)\n",
    "    outputs1 = outputs1.squeeze(1)\n",
    "    outputs1 = outputs1.to('cpu')\n",
    "\n",
    "    # create spectrogram from outputs1\n",
    "    spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)\n",
    "    spectrograms = torch.from_numpy(spectrograms)\n",
    "    \n",
    "    spectrograms_transformed = transform_train(spectrograms)\n",
    "\n",
    "    spectrograms2train       = torch.cat((spectrograms, spectrograms_transformed), axis=0)\n",
    "    spectrograms2train       = spectrograms2train.to(device)\n",
    "\n",
    "    labels2train = torch.cat((labels, labels), axis=0)\n",
    "\n",
    "    outputs2 = model2(spectrograms2train)\n",
    "\n",
    "    m     = nn.Sigmoid()\n",
    "    probs = m(outputs2)\n",
    "    \n",
    "    y_true  = torch.max(labels2train, dim = 1)[0]\n",
    "    y_pred  = torch.max(probs, dim = 1)[0]\n",
    "    \n",
    "    if cont == 1:\n",
    "        Y_true = y_true\n",
    "        Y_pred = y_pred\n",
    "    else:                \n",
    "        Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "        Y_pred = torch.cat((Y_pred, y_pred), axis=0)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs2, labels2train)\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    # Perform optimization\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    \n",
    "    # record training loss\n",
    "    train_losses.append(loss.item())\n",
    "    del _data\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver el resumen de la memoria de la GPU\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg: torch.Size([64, 4, 22500])\n",
      "labels: torch.Size([64, 181])\n",
      "spectrograms2train: torch.Size([128, 4, 120, 181])\n",
      "labels2train: torch.Size([128, 181])\n",
      "outputs2: torch.Size([128, 181])\n",
      "probs: torch.Size([128, 181])\n",
      "y_true: torch.Size([128])\n",
      "y_pred: torch.Size([128])\n",
      "Y_true: torch.Size([128])\n",
      "Y_pred: torch.Size([128])\n",
      "loss: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def list_gpu_tensors():\n",
    "    \"\"\"Lista todos los tensores en la GPU\"\"\"\n",
    "    # Obtener una lista de los nombres de variables en globals()\n",
    "    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\n",
    "    \n",
    "    for name in tensor_names:\n",
    "        obj = globals()[name]\n",
    "        print(f'{name}: {obj.size()}')\n",
    "\n",
    "def delete_tensor(name):\n",
    "    \"\"\"Elimina un tensor específico por nombre\"\"\"\n",
    "    if name in globals():\n",
    "        obj = globals()[name]\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "            print(f'Deleting tensor: {name}')\n",
    "            del obj\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Recolectar basura\n",
    "gc.collect()\n",
    "\n",
    "# Listar todos los tensores en la GPU\n",
    "list_gpu_tensors()\n",
    "\n",
    "# Eliminar un tensor específico (por ejemplo, 'tensor_name')\n",
    "#delete_tensor('tensor_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg: torch.Size([64, 4, 22500])\n",
      "labels: torch.Size([64, 181])\n",
      "spectrograms2train: torch.Size([128, 4, 120, 181])\n",
      "labels2train: torch.Size([128, 181])\n",
      "outputs2: torch.Size([128, 181])\n",
      "probs: torch.Size([128, 181])\n",
      "y_true: torch.Size([128])\n",
      "y_pred: torch.Size([128])\n",
      "Y_true: torch.Size([128])\n",
      "Y_pred: torch.Size([128])\n",
      "loss: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def list_gpu_tensors():\n",
    "    \"\"\"Lista todos los tensores en la GPU\"\"\"\n",
    "    # Obtener una lista de los nombres de variables en globals()\n",
    "    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\n",
    "    \n",
    "    for name in tensor_names:\n",
    "        obj = globals()[name]\n",
    "        print(f'{name}: {obj.size()}')\n",
    "\n",
    "def delete_tensor(name):\n",
    "    \"\"\"Elimina un tensor específico por nombre\"\"\"\n",
    "    if name in globals():\n",
    "        obj = globals()[name]\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "            print(f'Deleting tensor: {name}')\n",
    "            del obj\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Recolectar basura\n",
    "gc.collect()\n",
    "\n",
    "# Listar todos los tensores en la GPU\n",
    "list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg: torch.Size([64, 4, 22500])\n",
      "labels: torch.Size([64, 181])\n",
      "spectrograms2train: torch.Size([128, 4, 120, 181])\n",
      "labels2train: torch.Size([128, 181])\n",
      "outputs2: torch.Size([128, 181])\n",
      "probs: torch.Size([128, 181])\n",
      "y_true: torch.Size([128])\n",
      "y_pred: torch.Size([128])\n",
      "Y_true: torch.Size([128])\n",
      "Y_pred: torch.Size([128])\n",
      "loss: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "list_gpu_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer1: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9499601116872756, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 4e-05\n",
      "    lr: 4.0382927802153974e-05\n",
      "    max_lr: 0.001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 4e-09\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "optimizer2: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.9499800598205383, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 4e-05\n",
      "    lr: 4.019142572283151e-05\n",
      "    max_lr: 0.001\n",
      "    max_momentum: 0.95\n",
      "    maximize: False\n",
      "    min_lr: 4e-09\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "\n",
    "# Obtener una lista de los nombres de variables en globals() que son instancias de torch.optim.Optimizer\n",
    "optimizers = [name for name, obj in globals().items() if isinstance(obj, torch.optim.Optimizer)]\n",
    "\n",
    "# Imprimir los nombres de los optimizadores\n",
    "for name in optimizers:\n",
    "    obj = globals()[name]\n",
    "    print(f'{name}: {obj}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optimizer2'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arrays = [name for name, obj in globals().items() if isinstance(obj, np.ndarray)]\n",
    "\n",
    "# Imprimir los nombres de los arrays de NumPy y sus formas\n",
    "for name in numpy_arrays:\n",
    "    obj = globals()[name]\n",
    "    print(f'{name}: {obj.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('__name__', '__main__'), ('__doc__', 'Automatically created module for IPython interactive environment'), ('__package__', None), ('__loader__', None), ('__spec__', None), ('__builtin__', <module 'builtins' (built-in)>), ('__builtins__', <module 'builtins' (built-in)>), ('_ih', ['', \"import sys\\nimport os\\n\\nimport torch\\nimport random\\n\\nimport torchaudio.transforms    as T\\nimport torch.optim              as optim\\nimport pandas                   as pd\\nimport numpy                    as np\\n\\nfrom torchvision       import transforms\\nfrom torch.utils.data  import DataLoader\\nfrom torch             import nn\\nfrom sklearn.metrics   import balanced_accuracy_score, recall_score, precision_score, mean_absolute_error, average_precision_score\\n\\nsys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\\nfrom utilit_train_test import make_weights_for_balanced_classes\\n\\nsys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\\nfrom Generator         import SeizureDatasetLabelTimev2, permute_spec, smoothing_label\\nfrom Model             import iESPnet\\nfrom TrainEval         import train_model_v2, test_model_v2, get_performance_indices\\nfrom IO                import get_spectrogram_2\\n\\nsys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\\nfrom models            import DynamicSpatialFilter\\n\\ntorch.set_printoptions(precision=10)\\n\\n# set the seed for reproducibility\\ntorch.manual_seed(0)\\nrandom.seed(0)\", \"# direccion donde se encuentran los espectrogramas \\nSPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\\nmeta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\\n\\ndf_meta        = pd.read_csv(meta_data_file)\", \"# Variables iESPnet\\nFREQ_MASK_PARAM    = 10\\nTIME_MASK_PARAN    = 20\\nN_CLASSES          = 1\\nlearning_rate      = 1e-3\\nbatch_size         = 64    #128\\nepochs             = 20\\nnum_workers        = 4\\n\\nsave_path          = 'models_DSF_iESPnet_prueba/'\\npatients           = df_meta['rns_id'].unique().tolist()\", \"# Variables DSF\\ndenoising          = 'autoreject'   # 'autoreject' 'data_augm' \\nmodel              = 'stager_net'\\ndsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\\nmlp_input          = 'log_diag_cov'\\ndsf_soft_thresh    = False\\ndsf_n_out_channels = None\\nn_channels         = 4\", '# hiperparametros iESPnet\\nhparams = {\\n           \"n_cnn_layers\" : 3,\\n           \"n_rnn_layers\" : 3,\\n           \"rnn_dim\"      : [150, 100, 50],\\n           \"n_class\"      : N_CLASSES,\\n           \"out_ch\"       : [8,8,16],\\n           \"dropout\"      : 0.3,\\n           \"learning_rate\": learning_rate,\\n           \"batch_size\"   : batch_size,\\n           \"num_workers\"  : num_workers,\\n           \"epochs\"       : epochs\\n          }', \"# define train y test de df_meta\\ntest_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\\nvali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']\", 'train_df = df_meta.copy() # hace falta resetear el indice de train_df?\\ntest_df  = pd.DataFrame()\\nvali_df  = pd.DataFrame()', \"for s in range (len(test_id)):\\n    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\\n    test_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\\n\\nfor s in range(len(vali_id)):\\n    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\\n    vali_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)\\n\\ntrain_df.reset_index(drop=True, inplace=True)\", \"# experimentos que se van a realizar\\nexperiments_1 = ['exp1','exp2','exp3']\\nexperiments_2 = ['.1','.2','.3']\", 's = 0\\nj = 0', 'model1 = DynamicSpatialFilter(\\n                              n_channels, \\n                              mlp_input            = mlp_input, \\n                              n_out_channels       = dsf_n_out_channels, \\n                              apply_soft_thresh    = dsf_soft_thresh\\n                             )', \"model2 = iESPnet(\\n                 hparams['n_cnn_layers'],\\n                 hparams['n_rnn_layers'],\\n                 hparams['rnn_dim'],\\n                 hparams['n_class'],\\n                 hparams['out_ch'],\\n                 hparams['dropout'],\\n                )\", \"save_runs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/runs/'\\nsave_models      = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/models/'\\nsave_predictions = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/results/'\\nsave_figs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/figs/'\\n\\nif not os.path.exists(save_path):\\n    os.makedirs(save_path)\\n\\nif not os.path.exists(save_runs):\\n    os.makedirs(save_runs)\\n\\nif not os.path.exists(save_models):\\n    os.makedirs(save_models)\\n\\nif not os.path.exists(save_predictions):\\n    os.makedirs(save_predictions)\\n\\nif not os.path.exists(save_figs):\\n    os.makedirs(save_figs)\", \"print('Running training for: ' + experiments_1[s] +  experiments_2[j])\", '# Dataloaders creados\\ntrain_data = SeizureDatasetLabelTimev2(\\n                                       file             = train_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None, \\n                                       target_transform = smoothing_label(),\\n                                      )', '# testing data should be balanced, just be \"as it is\"\\ntest_data  = SeizureDatasetLabelTimev2(\\n                                       file             = test_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )', '# validation data should be balanced, just be \"as it is\"\\nvali_data  = SeizureDatasetLabelTimev2(\\n                                       file             = vali_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )', '# data augmentation \\ntransform_train = transforms.Compose([\\n                                      T.FrequencyMasking(FREQ_MASK_PARAM),\\n                                      T.TimeMasking(TIME_MASK_PARAN), \\n                                      permute_spec()                                                                     \\n                                    ])', 'weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\\nsampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))', \"outputfile = save_models + 'model_' + str(experiments_1[s] + experiments_2[j])\", \"'''\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'''\", 'avg_train_losses = []\\ntrain_accs       = []', 'avg_valid_losses = [] \\nvalid_accs       = []', 'use_cuda = torch.cuda.is_available()\\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\\nprint(\\'Using {} device\\'.format(device))', '# following pytorch suggestion to speed up training\\ntorch.backends.cudnn.benchmark     = True # cambio para reproducibilidad\\n#torch.backends.cudnn.deterministic = True', 'kwargs = {\\'num_workers\\': hparams[\"num_workers\"], \\'pin_memory\\': True} if use_cuda else {}\\n\\ntrain_loader = DataLoader(train_data, batch_size = hparams[\"batch_size\"], sampler = sampler, **kwargs)\\nvalid_loader = DataLoader(vali_data, batch_size = hparams[\"batch_size\"], shuffle = True, **kwargs)', '#move model1 to device\\nmodel1.to(device)', '#move model2 to device\\nmodel2.to(device)', \"print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))\\nprint('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))\", \"optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\noptimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\n\\nscheduler1 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer1, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n\\nscheduler2 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer2, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)*2),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n      \\ncriterion = nn.BCEWithLogitsLoss().to(device)\", 'epoch = 1', \"'''\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'''                                                \", 'experiment_1 = experiments_1[s]\\nexperiment_2 = experiments_2[j]', \"# create spectrogram\\nECOG_SAMPLE_RATE = 250\\nECOG_CHANNELS    = 4\\nTT               = 1000 # window length\\nSPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\\noverlap          = 500 \\nSPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\\nSPEC_NFFT        = 500  # to see changes in 0.5 reso\\nif   experiment_2 == '.1':  \\n    top_db       = 40.0\\nelif experiment_2 == '.2':\\n    top_db       = 60.0\\nelif experiment_2 == '.3':\\n    top_db       = 80.0\", 'train_loss   = 0.0\\ntrain_losses = []\\ncont         = 0', 'model1.train()', 'model2.train()', \"for batch_idx, _data in enumerate(train_loader):\\n    #if batch_idx == 1:  # Saltar la primera iteración\\n        #continue\\n\\n    cont+=1\\n    eeg, labels = _data \\n    eeg, labels = eeg.to(device), labels.to(device)\\n\\n    # Zero the gradients\\n    optimizer1.zero_grad(set_to_none=True)\\n    optimizer2.zero_grad(set_to_none=True)\\n\\n    # Perform forward pass to DSF\\n    outputs1 = model1(eeg)  # (batch, n_class)\\n    outputs1 = outputs1.squeeze(1)\\n    outputs1 = outputs1.to('cpu')\\n\\n    # create spectrogram from outputs1\\n    spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)\\n    spectrograms = torch.from_numpy(spectrograms)\\n    \\n    spectrograms_transformed = transform_train(spectrograms)\\n\\n    spectrograms2train       = torch.cat((spectrograms, spectrograms_transformed), axis=0)\\n    spectrograms2train       = spectrograms2train.to(device)\\n\\n    labels2train = torch.cat((labels, labels), axis=0)\\n\\n    outputs2 = model2(spectrograms2train)\\n\\n    m     = nn.Sigmoid()\\n    probs = m(outputs2)\\n    \\n    y_true  = torch.max(labels2train, dim = 1)[0]\\n    y_pred  = torch.max(probs, dim = 1)[0]\\n    \\n    if cont == 1:\\n        Y_true = y_true\\n        Y_pred = y_pred\\n    else:                \\n        Y_true = torch.cat((Y_true, y_true), axis=0)\\n        Y_pred = torch.cat((Y_pred, y_pred), axis=0)\\n\\n    # Compute loss\\n    loss = criterion(outputs2, labels2train)\\n\\n    # Perform backward pass\\n    loss.backward()\\n    train_loss += loss.item()\\n    \\n    # Perform optimization\\n    optimizer1.step()\\n    optimizer2.step()\\n    scheduler1.step()\\n    scheduler2.step()\\n    \\n    # record training loss\\n    train_losses.append(loss.item())\\n    del _data\\n    torch.cuda.empty_cache()\\n    \\n    break\", '# Ver el resumen de la memoria de la GPU\\nprint(torch.cuda.memory_summary())', \"import gc\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los objetos en el espacio de nombres local\\nfor name, obj in globals().items():\\n    if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n        print(f'{name}: {obj.size()}')\", 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\ndelete_tensor(\\'tensor_name\\')', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\n#delete_tensor(\\'tensor_name\\')', 'globals().items() ']), ('_oh', {21: '\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n', 27: DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       "), 28: iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       "), 32: '\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n', 36: DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       "), 37: iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")}), ('_dh', [PosixPath('/home/martin/Documentos/PI-Thalamus/01 Thalamus-PI/Paper_iESPnet_pruebas/01-Exploraciones')]), ('In', ['', \"import sys\\nimport os\\n\\nimport torch\\nimport random\\n\\nimport torchaudio.transforms    as T\\nimport torch.optim              as optim\\nimport pandas                   as pd\\nimport numpy                    as np\\n\\nfrom torchvision       import transforms\\nfrom torch.utils.data  import DataLoader\\nfrom torch             import nn\\nfrom sklearn.metrics   import balanced_accuracy_score, recall_score, precision_score, mean_absolute_error, average_precision_score\\n\\nsys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\\nfrom utilit_train_test import make_weights_for_balanced_classes\\n\\nsys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\\nfrom Generator         import SeizureDatasetLabelTimev2, permute_spec, smoothing_label\\nfrom Model             import iESPnet\\nfrom TrainEval         import train_model_v2, test_model_v2, get_performance_indices\\nfrom IO                import get_spectrogram_2\\n\\nsys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\\nfrom models            import DynamicSpatialFilter\\n\\ntorch.set_printoptions(precision=10)\\n\\n# set the seed for reproducibility\\ntorch.manual_seed(0)\\nrandom.seed(0)\", \"# direccion donde se encuentran los espectrogramas \\nSPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\\nmeta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\\n\\ndf_meta        = pd.read_csv(meta_data_file)\", \"# Variables iESPnet\\nFREQ_MASK_PARAM    = 10\\nTIME_MASK_PARAN    = 20\\nN_CLASSES          = 1\\nlearning_rate      = 1e-3\\nbatch_size         = 64    #128\\nepochs             = 20\\nnum_workers        = 4\\n\\nsave_path          = 'models_DSF_iESPnet_prueba/'\\npatients           = df_meta['rns_id'].unique().tolist()\", \"# Variables DSF\\ndenoising          = 'autoreject'   # 'autoreject' 'data_augm' \\nmodel              = 'stager_net'\\ndsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\\nmlp_input          = 'log_diag_cov'\\ndsf_soft_thresh    = False\\ndsf_n_out_channels = None\\nn_channels         = 4\", '# hiperparametros iESPnet\\nhparams = {\\n           \"n_cnn_layers\" : 3,\\n           \"n_rnn_layers\" : 3,\\n           \"rnn_dim\"      : [150, 100, 50],\\n           \"n_class\"      : N_CLASSES,\\n           \"out_ch\"       : [8,8,16],\\n           \"dropout\"      : 0.3,\\n           \"learning_rate\": learning_rate,\\n           \"batch_size\"   : batch_size,\\n           \"num_workers\"  : num_workers,\\n           \"epochs\"       : epochs\\n          }', \"# define train y test de df_meta\\ntest_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\\nvali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']\", 'train_df = df_meta.copy() # hace falta resetear el indice de train_df?\\ntest_df  = pd.DataFrame()\\nvali_df  = pd.DataFrame()', \"for s in range (len(test_id)):\\n    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\\n    test_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\\n\\nfor s in range(len(vali_id)):\\n    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\\n    vali_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)\\n\\ntrain_df.reset_index(drop=True, inplace=True)\", \"# experimentos que se van a realizar\\nexperiments_1 = ['exp1','exp2','exp3']\\nexperiments_2 = ['.1','.2','.3']\", 's = 0\\nj = 0', 'model1 = DynamicSpatialFilter(\\n                              n_channels, \\n                              mlp_input            = mlp_input, \\n                              n_out_channels       = dsf_n_out_channels, \\n                              apply_soft_thresh    = dsf_soft_thresh\\n                             )', \"model2 = iESPnet(\\n                 hparams['n_cnn_layers'],\\n                 hparams['n_rnn_layers'],\\n                 hparams['rnn_dim'],\\n                 hparams['n_class'],\\n                 hparams['out_ch'],\\n                 hparams['dropout'],\\n                )\", \"save_runs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/runs/'\\nsave_models      = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/models/'\\nsave_predictions = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/results/'\\nsave_figs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/figs/'\\n\\nif not os.path.exists(save_path):\\n    os.makedirs(save_path)\\n\\nif not os.path.exists(save_runs):\\n    os.makedirs(save_runs)\\n\\nif not os.path.exists(save_models):\\n    os.makedirs(save_models)\\n\\nif not os.path.exists(save_predictions):\\n    os.makedirs(save_predictions)\\n\\nif not os.path.exists(save_figs):\\n    os.makedirs(save_figs)\", \"print('Running training for: ' + experiments_1[s] +  experiments_2[j])\", '# Dataloaders creados\\ntrain_data = SeizureDatasetLabelTimev2(\\n                                       file             = train_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None, \\n                                       target_transform = smoothing_label(),\\n                                      )', '# testing data should be balanced, just be \"as it is\"\\ntest_data  = SeizureDatasetLabelTimev2(\\n                                       file             = test_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )', '# validation data should be balanced, just be \"as it is\"\\nvali_data  = SeizureDatasetLabelTimev2(\\n                                       file             = vali_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )', '# data augmentation \\ntransform_train = transforms.Compose([\\n                                      T.FrequencyMasking(FREQ_MASK_PARAM),\\n                                      T.TimeMasking(TIME_MASK_PARAN), \\n                                      permute_spec()                                                                     \\n                                    ])', 'weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\\nsampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))', \"outputfile = save_models + 'model_' + str(experiments_1[s] + experiments_2[j])\", \"'''\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'''\", 'avg_train_losses = []\\ntrain_accs       = []', 'avg_valid_losses = [] \\nvalid_accs       = []', 'use_cuda = torch.cuda.is_available()\\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\\nprint(\\'Using {} device\\'.format(device))', '# following pytorch suggestion to speed up training\\ntorch.backends.cudnn.benchmark     = True # cambio para reproducibilidad\\n#torch.backends.cudnn.deterministic = True', 'kwargs = {\\'num_workers\\': hparams[\"num_workers\"], \\'pin_memory\\': True} if use_cuda else {}\\n\\ntrain_loader = DataLoader(train_data, batch_size = hparams[\"batch_size\"], sampler = sampler, **kwargs)\\nvalid_loader = DataLoader(vali_data, batch_size = hparams[\"batch_size\"], shuffle = True, **kwargs)', '#move model1 to device\\nmodel1.to(device)', '#move model2 to device\\nmodel2.to(device)', \"print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))\\nprint('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))\", \"optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\noptimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\n\\nscheduler1 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer1, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n\\nscheduler2 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer2, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)*2),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n      \\ncriterion = nn.BCEWithLogitsLoss().to(device)\", 'epoch = 1', \"'''\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'''                                                \", 'experiment_1 = experiments_1[s]\\nexperiment_2 = experiments_2[j]', \"# create spectrogram\\nECOG_SAMPLE_RATE = 250\\nECOG_CHANNELS    = 4\\nTT               = 1000 # window length\\nSPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\\noverlap          = 500 \\nSPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\\nSPEC_NFFT        = 500  # to see changes in 0.5 reso\\nif   experiment_2 == '.1':  \\n    top_db       = 40.0\\nelif experiment_2 == '.2':\\n    top_db       = 60.0\\nelif experiment_2 == '.3':\\n    top_db       = 80.0\", 'train_loss   = 0.0\\ntrain_losses = []\\ncont         = 0', 'model1.train()', 'model2.train()', \"for batch_idx, _data in enumerate(train_loader):\\n    #if batch_idx == 1:  # Saltar la primera iteración\\n        #continue\\n\\n    cont+=1\\n    eeg, labels = _data \\n    eeg, labels = eeg.to(device), labels.to(device)\\n\\n    # Zero the gradients\\n    optimizer1.zero_grad(set_to_none=True)\\n    optimizer2.zero_grad(set_to_none=True)\\n\\n    # Perform forward pass to DSF\\n    outputs1 = model1(eeg)  # (batch, n_class)\\n    outputs1 = outputs1.squeeze(1)\\n    outputs1 = outputs1.to('cpu')\\n\\n    # create spectrogram from outputs1\\n    spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)\\n    spectrograms = torch.from_numpy(spectrograms)\\n    \\n    spectrograms_transformed = transform_train(spectrograms)\\n\\n    spectrograms2train       = torch.cat((spectrograms, spectrograms_transformed), axis=0)\\n    spectrograms2train       = spectrograms2train.to(device)\\n\\n    labels2train = torch.cat((labels, labels), axis=0)\\n\\n    outputs2 = model2(spectrograms2train)\\n\\n    m     = nn.Sigmoid()\\n    probs = m(outputs2)\\n    \\n    y_true  = torch.max(labels2train, dim = 1)[0]\\n    y_pred  = torch.max(probs, dim = 1)[0]\\n    \\n    if cont == 1:\\n        Y_true = y_true\\n        Y_pred = y_pred\\n    else:                \\n        Y_true = torch.cat((Y_true, y_true), axis=0)\\n        Y_pred = torch.cat((Y_pred, y_pred), axis=0)\\n\\n    # Compute loss\\n    loss = criterion(outputs2, labels2train)\\n\\n    # Perform backward pass\\n    loss.backward()\\n    train_loss += loss.item()\\n    \\n    # Perform optimization\\n    optimizer1.step()\\n    optimizer2.step()\\n    scheduler1.step()\\n    scheduler2.step()\\n    \\n    # record training loss\\n    train_losses.append(loss.item())\\n    del _data\\n    torch.cuda.empty_cache()\\n    \\n    break\", '# Ver el resumen de la memoria de la GPU\\nprint(torch.cuda.memory_summary())', \"import gc\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los objetos en el espacio de nombres local\\nfor name, obj in globals().items():\\n    if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n        print(f'{name}: {obj.size()}')\", 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\ndelete_tensor(\\'tensor_name\\')', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\n#delete_tensor(\\'tensor_name\\')', 'globals().items() ']), ('Out', {21: '\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n', 27: DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       "), 28: iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       "), 32: '\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n', 36: DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       "), 37: iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")}), ('get_ipython', <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x73c7bdbdf520>>), ('exit', <IPython.core.autocall.ZMQExitAutocall object at 0x73c7bd1201f0>), ('quit', <IPython.core.autocall.ZMQExitAutocall object at 0x73c7bd1201f0>), ('open', <function open at 0x73c7c0480d30>), ('_', iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")), ('__', DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")), ('___', '\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'), ('__vsc_ipynb_file__', '/home/martin/Documentos/PI-Thalamus/01 Thalamus-PI/Paper_iESPnet_pruebas/01-Exploraciones/12 Exploracion.ipynb'), ('_i', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\n#delete_tensor(\\'tensor_name\\')'), ('_ii', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\ndelete_tensor(\\'tensor_name\\')'), ('_iii', \"import gc\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los objetos en el espacio de nombres local\\nfor name, obj in globals().items():\\n    if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n        print(f'{name}: {obj.size()}')\"), ('_i1', \"import sys\\nimport os\\n\\nimport torch\\nimport random\\n\\nimport torchaudio.transforms    as T\\nimport torch.optim              as optim\\nimport pandas                   as pd\\nimport numpy                    as np\\n\\nfrom torchvision       import transforms\\nfrom torch.utils.data  import DataLoader\\nfrom torch             import nn\\nfrom sklearn.metrics   import balanced_accuracy_score, recall_score, precision_score, mean_absolute_error, average_precision_score\\n\\nsys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\\nfrom utilit_train_test import make_weights_for_balanced_classes\\n\\nsys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\\nfrom Generator         import SeizureDatasetLabelTimev2, permute_spec, smoothing_label\\nfrom Model             import iESPnet\\nfrom TrainEval         import train_model_v2, test_model_v2, get_performance_indices\\nfrom IO                import get_spectrogram_2\\n\\nsys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\\nfrom models            import DynamicSpatialFilter\\n\\ntorch.set_printoptions(precision=10)\\n\\n# set the seed for reproducibility\\ntorch.manual_seed(0)\\nrandom.seed(0)\"), ('sys', <module 'sys' (built-in)>), ('os', <module 'os' from '/usr/lib/python3.10/os.py'>), ('torch', <module 'torch' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/__init__.py'>), ('random', <module 'random' from '/usr/lib/python3.10/random.py'>), ('T', <module 'torchaudio.transforms' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torchaudio/transforms/__init__.py'>), ('optim', <module 'torch.optim' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/optim/__init__.py'>), ('pd', <module 'pandas' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/pandas/__init__.py'>), ('np', <module 'numpy' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/numpy/__init__.py'>), ('transforms', <module 'torchvision.transforms' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torchvision/transforms/__init__.py'>), ('DataLoader', <class 'torch.utils.data.dataloader.DataLoader'>), ('nn', <module 'torch.nn' from '/home/martin/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/nn/__init__.py'>), ('balanced_accuracy_score', <function balanced_accuracy_score at 0x73c69350d5a0>), ('recall_score', <function recall_score at 0x73c69350d480>), ('precision_score', <function precision_score at 0x73c69350d360>), ('mean_absolute_error', <function mean_absolute_error at 0x73c693530f70>), ('average_precision_score', <function average_precision_score at 0x73c69350f1c0>), ('make_weights_for_balanced_classes', <function make_weights_for_balanced_classes at 0x73c693533490>), ('SeizureDatasetLabelTimev2', <class 'Generator.SeizureDatasetLabelTimev2'>), ('permute_spec', <class 'Generator.permute_spec'>), ('smoothing_label', <class 'Generator.smoothing_label'>), ('iESPnet', <class 'Model.iESPnet'>), ('train_model_v2', <function train_model_v2 at 0x73c682e0fd00>), ('test_model_v2', <function test_model_v2 at 0x73c682e1c160>), ('get_performance_indices', <function get_performance_indices at 0x73c682e1c5e0>), ('get_spectrogram_2', <function get_spectrogram_2 at 0x73c682e0fbe0>), ('DynamicSpatialFilter', <class 'models.DynamicSpatialFilter'>), ('_i2', \"# direccion donde se encuentran los espectrogramas \\nSPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\\nmeta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\\n\\ndf_meta        = pd.read_csv(meta_data_file)\"), ('SPE_DIR', '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'), ('meta_data_file', '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'), ('df_meta',             rns_id                        data  label  time\n",
       "0      PIT-RNS1603   PIT_RNS1603_20150804-1_E0      0   0.0\n",
       "1      PIT-RNS1603   PIT_RNS1603_20150804-1_E1      0   0.0\n",
       "2      PIT-RNS1603   PIT_RNS1603_20150804-1_E2      0   0.0\n",
       "3      PIT-RNS1603   PIT_RNS1603_20150804-1_E3      0   0.0\n",
       "4      PIT-RNS1603   PIT_RNS1603_20150804-1_E4      0   0.0\n",
       "...            ...                         ...    ...   ...\n",
       "42493  PIT-RNS8076  PIT_RNS8076_20190806-1_E21      0   0.0\n",
       "42494  PIT-RNS8076  PIT_RNS8076_20190806-1_E22      0   0.0\n",
       "42495  PIT-RNS8076  PIT_RNS8076_20190806-1_E23      0   0.0\n",
       "42496  PIT-RNS8076  PIT_RNS8076_20190806-1_E24      0   0.0\n",
       "42497  PIT-RNS8076  PIT_RNS8076_20190806-1_E25      0   0.0\n",
       "\n",
       "[42498 rows x 4 columns]), ('_i3', \"# Variables iESPnet\\nFREQ_MASK_PARAM    = 10\\nTIME_MASK_PARAN    = 20\\nN_CLASSES          = 1\\nlearning_rate      = 1e-3\\nbatch_size         = 64    #128\\nepochs             = 20\\nnum_workers        = 4\\n\\nsave_path          = 'models_DSF_iESPnet_prueba/'\\npatients           = df_meta['rns_id'].unique().tolist()\"), ('FREQ_MASK_PARAM', 10), ('TIME_MASK_PARAN', 20), ('N_CLASSES', 1), ('learning_rate', 0.001), ('batch_size', 64), ('epochs', 20), ('num_workers', 4), ('save_path', 'models_DSF_iESPnet_prueba/'), ('patients', ['PIT-RNS1603', 'PIT-RNS6989', 'PIT-RNS3016', 'PIT-RNS1529', 'PIT-RNS7168', 'PIT-RNS4098', 'PIT-RNS1836', 'PIT-RNS9183', 'PIT-RNS1440', 'PIT-RNS1713', 'PIT-RNS9536', 'PIT-RNS2543', 'PIT-RNS1438', 'PIT-RNS1534', 'PIT-RNS1703', 'PIT-RNS1556', 'PIT-RNS1597', 'PIT-RNS6992', 'PIT-RNS8326', 'PIT-RNS2227', 'PIT-RNS8163', 'PIT-RNS8973', 'PIT-RNS6806', 'PIT-RNS1090', 'PIT-RNS2368', 'PIT-RNS6762', 'PIT-RNS2938', 'PIT-RNS7525', 'PIT-RNS0427', 'PIT-RNS8076']), ('_i4', \"# Variables DSF\\ndenoising          = 'autoreject'   # 'autoreject' 'data_augm' \\nmodel              = 'stager_net'\\ndsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\\nmlp_input          = 'log_diag_cov'\\ndsf_soft_thresh    = False\\ndsf_n_out_channels = None\\nn_channels         = 4\"), ('denoising', 'autoreject'), ('model', 'stager_net'), ('dsf_type', 'dsfd'), ('mlp_input', 'log_diag_cov'), ('dsf_soft_thresh', False), ('dsf_n_out_channels', None), ('n_channels', 4), ('_i5', '# hiperparametros iESPnet\\nhparams = {\\n           \"n_cnn_layers\" : 3,\\n           \"n_rnn_layers\" : 3,\\n           \"rnn_dim\"      : [150, 100, 50],\\n           \"n_class\"      : N_CLASSES,\\n           \"out_ch\"       : [8,8,16],\\n           \"dropout\"      : 0.3,\\n           \"learning_rate\": learning_rate,\\n           \"batch_size\"   : batch_size,\\n           \"num_workers\"  : num_workers,\\n           \"epochs\"       : epochs\\n          }'), ('hparams', {'n_cnn_layers': 3, 'n_rnn_layers': 3, 'rnn_dim': [150, 100, 50], 'n_class': 1, 'out_ch': [8, 8, 16], 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64, 'num_workers': 4, 'epochs': 20}), ('_i6', \"# define train y test de df_meta\\ntest_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\\nvali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']\"), ('test_id', ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']), ('vali_id', ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']), ('_i7', 'train_df = df_meta.copy() # hace falta resetear el indice de train_df?\\ntest_df  = pd.DataFrame()\\nvali_df  = pd.DataFrame()'), ('train_df',             rns_id                        data  label       time\n",
       "0      PIT-RNS1529   PIT_RNS1529_20151118-1_E0      0   0.000000\n",
       "1      PIT-RNS1529   PIT_RNS1529_20151118-1_E1      0   0.000000\n",
       "2      PIT-RNS1529   PIT_RNS1529_20151118-1_E2      0   0.000000\n",
       "3      PIT-RNS1529   PIT_RNS1529_20151118-1_E3      1   2.376081\n",
       "4      PIT-RNS1529   PIT_RNS1529_20151118-1_E4      1  26.543171\n",
       "...            ...                         ...    ...        ...\n",
       "26730  PIT-RNS8076  PIT_RNS8076_20190806-1_E21      0   0.000000\n",
       "26731  PIT-RNS8076  PIT_RNS8076_20190806-1_E22      0   0.000000\n",
       "26732  PIT-RNS8076  PIT_RNS8076_20190806-1_E23      0   0.000000\n",
       "26733  PIT-RNS8076  PIT_RNS8076_20190806-1_E24      0   0.000000\n",
       "26734  PIT-RNS8076  PIT_RNS8076_20190806-1_E25      0   0.000000\n",
       "\n",
       "[26735 rows x 4 columns]), ('test_df',            rns_id                         data  label       time\n",
       "0     PIT-RNS1090    PIT_RNS1090_20170530-1_E0      1  74.645138\n",
       "1     PIT-RNS1090    PIT_RNS1090_20170530-1_E1      1  39.994220\n",
       "2     PIT-RNS1090    PIT_RNS1090_20170530-1_E2      0   0.000000\n",
       "3     PIT-RNS1090    PIT_RNS1090_20170530-1_E3      0   0.000000\n",
       "4     PIT-RNS1090    PIT_RNS1090_20170530-1_E4      0   0.000000\n",
       "...           ...                          ...    ...        ...\n",
       "7962  PIT-RNS3016  PIT_RNS3016_20190723-1_E182      0   0.000000\n",
       "7963  PIT-RNS3016  PIT_RNS3016_20190723-1_E183      0   0.000000\n",
       "7964  PIT-RNS3016  PIT_RNS3016_20190723-1_E184      0   0.000000\n",
       "7965  PIT-RNS3016  PIT_RNS3016_20190723-1_E185      0   0.000000\n",
       "7966  PIT-RNS3016  PIT_RNS3016_20190723-1_E186      0   0.000000\n",
       "\n",
       "[7967 rows x 4 columns]), ('vali_df',            rns_id                         data  label  time\n",
       "0     PIT-RNS1603    PIT_RNS1603_20150804-1_E0      0   0.0\n",
       "1     PIT-RNS1603    PIT_RNS1603_20150804-1_E1      0   0.0\n",
       "2     PIT-RNS1603    PIT_RNS1603_20150804-1_E2      0   0.0\n",
       "3     PIT-RNS1603    PIT_RNS1603_20150804-1_E3      0   0.0\n",
       "4     PIT-RNS1603    PIT_RNS1603_20150804-1_E4      0   0.0\n",
       "...           ...                          ...    ...   ...\n",
       "7791  PIT-RNS6762  PIT_RNS6762_20190903-1_E119      0   0.0\n",
       "7792  PIT-RNS6762  PIT_RNS6762_20190903-1_E120      0   0.0\n",
       "7793  PIT-RNS6762  PIT_RNS6762_20190903-1_E121      0   0.0\n",
       "7794  PIT-RNS6762  PIT_RNS6762_20190903-1_E122      0   0.0\n",
       "7795  PIT-RNS6762  PIT_RNS6762_20190903-1_E123      0   0.0\n",
       "\n",
       "[7796 rows x 4 columns]), ('_i8', \"for s in range (len(test_id)):\\n    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\\n    test_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\\n\\nfor s in range(len(vali_id)):\\n    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\\n    vali_df.reset_index(drop=True, inplace=True)\\n    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)\\n\\ntrain_df.reset_index(drop=True, inplace=True)\"), ('s', 0), ('_i9', \"# experimentos que se van a realizar\\nexperiments_1 = ['exp1','exp2','exp3']\\nexperiments_2 = ['.1','.2','.3']\"), ('experiments_1', ['exp1', 'exp2', 'exp3']), ('experiments_2', ['.1', '.2', '.3']), ('_i10', 's = 0\\nj = 0'), ('j', 0), ('_i11', 'model1 = DynamicSpatialFilter(\\n                              n_channels, \\n                              mlp_input            = mlp_input, \\n                              n_out_channels       = dsf_n_out_channels, \\n                              apply_soft_thresh    = dsf_soft_thresh\\n                             )'), ('model1', DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")), ('_i12', \"model2 = iESPnet(\\n                 hparams['n_cnn_layers'],\\n                 hparams['n_rnn_layers'],\\n                 hparams['rnn_dim'],\\n                 hparams['n_class'],\\n                 hparams['out_ch'],\\n                 hparams['dropout'],\\n                )\"), ('model2', iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")), ('_i13', \"save_runs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/runs/'\\nsave_models      = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/models/'\\nsave_predictions = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/results/'\\nsave_figs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/figs/'\\n\\nif not os.path.exists(save_path):\\n    os.makedirs(save_path)\\n\\nif not os.path.exists(save_runs):\\n    os.makedirs(save_runs)\\n\\nif not os.path.exists(save_models):\\n    os.makedirs(save_models)\\n\\nif not os.path.exists(save_predictions):\\n    os.makedirs(save_predictions)\\n\\nif not os.path.exists(save_figs):\\n    os.makedirs(save_figs)\"), ('save_runs', 'models_DSF_iESPnet_prueba/exp1/exp1.1/runs/'), ('save_models', 'models_DSF_iESPnet_prueba/exp1/exp1.1/models/'), ('save_predictions', 'models_DSF_iESPnet_prueba/exp1/exp1.1/results/'), ('save_figs', 'models_DSF_iESPnet_prueba/exp1/exp1.1/figs/'), ('_i14', \"print('Running training for: ' + experiments_1[s] +  experiments_2[j])\"), ('_i15', '# Dataloaders creados\\ntrain_data = SeizureDatasetLabelTimev2(\\n                                       file             = train_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None, \\n                                       target_transform = smoothing_label(),\\n                                      )'), ('train_data', <Generator.SeizureDatasetLabelTimev2 object at 0x73c682e18a60>), ('_i16', '# testing data should be balanced, just be \"as it is\"\\ntest_data  = SeizureDatasetLabelTimev2(\\n                                       file             = test_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )'), ('test_data', <Generator.SeizureDatasetLabelTimev2 object at 0x73c682e1b580>), ('_i17', '# validation data should be balanced, just be \"as it is\"\\nvali_data  = SeizureDatasetLabelTimev2(\\n                                       file             = vali_df,\\n                                       root_dir         = SPE_DIR,\\n                                       transform        = None,\\n                                       target_transform = smoothing_label()  \\n                                      )'), ('vali_data', <Generator.SeizureDatasetLabelTimev2 object at 0x73c682e1b4c0>), ('_i18', '# data augmentation \\ntransform_train = transforms.Compose([\\n                                      T.FrequencyMasking(FREQ_MASK_PARAM),\\n                                      T.TimeMasking(TIME_MASK_PARAN), \\n                                      permute_spec()                                                                     \\n                                    ])'), ('transform_train', Compose(\n",
       "    FrequencyMasking()\n",
       "    TimeMasking()\n",
       "    <Generator.permute_spec object at 0x73c682e1a050>\n",
       ")), ('_i19', 'weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\\nsampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))'), ('weights', tensor([5.2662067901e-05, 5.2662067901e-05, 5.2662067901e-05,  ...,\n",
       "        5.2662067901e-05, 5.2662067901e-05, 5.2662067901e-05])), ('sampler', <torch.utils.data.sampler.WeightedRandomSampler object at 0x73c682e1bbb0>), ('_i20', \"outputfile = save_models + 'model_' + str(experiments_1[s] + experiments_2[j])\"), ('outputfile', 'models_DSF_iESPnet_prueba/exp1/exp1.1/models/model_exp1.1'), ('_i21', \"'''\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'''\"), ('_21', '\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'), ('_i22', 'avg_train_losses = []\\ntrain_accs       = []'), ('avg_train_losses', []), ('train_accs', []), ('_i23', 'avg_valid_losses = [] \\nvalid_accs       = []'), ('avg_valid_losses', []), ('valid_accs', []), ('_i24', 'use_cuda = torch.cuda.is_available()\\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\\nprint(\\'Using {} device\\'.format(device))'), ('use_cuda', True), ('device', device(type='cuda')), ('_i25', '# following pytorch suggestion to speed up training\\ntorch.backends.cudnn.benchmark     = True # cambio para reproducibilidad\\n#torch.backends.cudnn.deterministic = True'), ('_i26', 'kwargs = {\\'num_workers\\': hparams[\"num_workers\"], \\'pin_memory\\': True} if use_cuda else {}\\n\\ntrain_loader = DataLoader(train_data, batch_size = hparams[\"batch_size\"], sampler = sampler, **kwargs)\\nvalid_loader = DataLoader(vali_data, batch_size = hparams[\"batch_size\"], shuffle = True, **kwargs)'), ('kwargs', {'num_workers': 4, 'pin_memory': True}), ('train_loader', <torch.utils.data.dataloader.DataLoader object at 0x73c682e19a80>), ('valid_loader', <torch.utils.data.dataloader.DataLoader object at 0x73c682e18760>), ('_i27', '#move model1 to device\\nmodel1.to(device)'), ('_27', DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")), ('_i28', '#move model2 to device\\nmodel2.to(device)'), ('_28', iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")), ('_i29', \"print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))\\nprint('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))\"), ('_i30', \"optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\noptimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)\\n\\nscheduler1 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer1, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n\\nscheduler2 = optim.lr_scheduler.OneCycleLR(\\n                                           optimizer2, \\n                                           max_lr          = hparams['learning_rate'], \\n                                           steps_per_epoch = int(len(train_loader)*2),\\n                                           epochs          = hparams['epochs'],\\n                                           anneal_strategy = 'linear'\\n                                          )\\n      \\ncriterion = nn.BCEWithLogitsLoss().to(device)\"), ('optimizer1', AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    base_momentum: 0.85\n",
       "    betas: (0.9499601116872756, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_lr: 4e-05\n",
       "    lr: 4.0382927802153974e-05\n",
       "    max_lr: 0.001\n",
       "    max_momentum: 0.95\n",
       "    maximize: False\n",
       "    min_lr: 4e-09\n",
       "    weight_decay: 0.0001\n",
       ")), ('optimizer2', AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    base_momentum: 0.85\n",
       "    betas: (0.9499800598205383, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_lr: 4e-05\n",
       "    lr: 4.019142572283151e-05\n",
       "    max_lr: 0.001\n",
       "    max_momentum: 0.95\n",
       "    maximize: False\n",
       "    min_lr: 4e-09\n",
       "    weight_decay: 0.0001\n",
       ")), ('scheduler1', <torch.optim.lr_scheduler.OneCycleLR object at 0x73c7bc7c1810>), ('scheduler2', <torch.optim.lr_scheduler.OneCycleLR object at 0x73c7bc7c1e10>), ('criterion', BCEWithLogitsLoss()), ('_i31', 'epoch = 1'), ('epoch', 1), ('_i32', \"'''\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'''                                                \"), ('_32', '\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'), ('_i33', 'experiment_1 = experiments_1[s]\\nexperiment_2 = experiments_2[j]'), ('experiment_1', 'exp1'), ('experiment_2', '.1'), ('_i34', \"# create spectrogram\\nECOG_SAMPLE_RATE = 250\\nECOG_CHANNELS    = 4\\nTT               = 1000 # window length\\nSPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\\noverlap          = 500 \\nSPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\\nSPEC_NFFT        = 500  # to see changes in 0.5 reso\\nif   experiment_2 == '.1':  \\n    top_db       = 40.0\\nelif experiment_2 == '.2':\\n    top_db       = 60.0\\nelif experiment_2 == '.3':\\n    top_db       = 80.0\"), ('ECOG_SAMPLE_RATE', 250), ('ECOG_CHANNELS', 4), ('TT', 1000), ('SPEC_WIN_LEN', 250), ('overlap', 500), ('SPEC_HOP_LEN', 125), ('SPEC_NFFT', 500), ('top_db', 40.0), ('_i35', 'train_loss   = 0.0\\ntrain_losses = []\\ncont         = 0'), ('train_loss', 0.693661426627358), ('train_losses', [0.693661426627358]), ('cont', 1), ('_i36', 'model1.train()'), ('_36', DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")), ('_i37', 'model2.train()'), ('_37', iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")), ('_i38', \"for batch_idx, _data in enumerate(train_loader):\\n    #if batch_idx == 1:  # Saltar la primera iteración\\n        #continue\\n\\n    cont+=1\\n    eeg, labels = _data \\n    eeg, labels = eeg.to(device), labels.to(device)\\n\\n    # Zero the gradients\\n    optimizer1.zero_grad(set_to_none=True)\\n    optimizer2.zero_grad(set_to_none=True)\\n\\n    # Perform forward pass to DSF\\n    outputs1 = model1(eeg)  # (batch, n_class)\\n    outputs1 = outputs1.squeeze(1)\\n    outputs1 = outputs1.to('cpu')\\n\\n    # create spectrogram from outputs1\\n    spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)\\n    spectrograms = torch.from_numpy(spectrograms)\\n    \\n    spectrograms_transformed = transform_train(spectrograms)\\n\\n    spectrograms2train       = torch.cat((spectrograms, spectrograms_transformed), axis=0)\\n    spectrograms2train       = spectrograms2train.to(device)\\n\\n    labels2train = torch.cat((labels, labels), axis=0)\\n\\n    outputs2 = model2(spectrograms2train)\\n\\n    m     = nn.Sigmoid()\\n    probs = m(outputs2)\\n    \\n    y_true  = torch.max(labels2train, dim = 1)[0]\\n    y_pred  = torch.max(probs, dim = 1)[0]\\n    \\n    if cont == 1:\\n        Y_true = y_true\\n        Y_pred = y_pred\\n    else:                \\n        Y_true = torch.cat((Y_true, y_true), axis=0)\\n        Y_pred = torch.cat((Y_pred, y_pred), axis=0)\\n\\n    # Compute loss\\n    loss = criterion(outputs2, labels2train)\\n\\n    # Perform backward pass\\n    loss.backward()\\n    train_loss += loss.item()\\n    \\n    # Perform optimization\\n    optimizer1.step()\\n    optimizer2.step()\\n    scheduler1.step()\\n    scheduler2.step()\\n    \\n    # record training loss\\n    train_losses.append(loss.item())\\n    del _data\\n    torch.cuda.empty_cache()\\n    \\n    break\"), ('batch_idx', 0), ('eeg', tensor([[[-0.3365942538,  0.4565646350,  0.3017098010,  ...,\n",
       "          -0.2752188444, -0.4093004763, -0.4093004763],\n",
       "         [ 0.0637621507,  0.0637621507,  0.0335465707,  ...,\n",
       "           0.1468549818,  0.3734717965,  0.4046316147],\n",
       "         [-0.3677540421, -1.2034035921, -1.3478717804,  ...,\n",
       "          -2.1108150482, -2.3789784908, -2.4922866821],\n",
       "         [-1.2449500561,  0.2290035784, -0.3677540421,  ...,\n",
       "          -1.9257447720, -1.2855521441, -0.9456269741]],\n",
       "\n",
       "        [[-0.5632360578, -0.6441600323, -0.4904044867,  ...,\n",
       "           0.0032316532,  0.0841556117,  0.1408023834],\n",
       "         [ 0.1812643558,  0.1327099800,  0.2621883154,  ...,\n",
       "           0.1084327996,  0.0760632157,  0.0194164459],\n",
       "         [-0.1100618914, -0.1019694954, -0.1505238712,  ...,\n",
       "          -0.4256653190, -0.4742197096, -0.1748010516],\n",
       "         [-0.1909858435, -0.2152630389, -0.1586162597,  ...,\n",
       "           0.0356012359,  0.0032316532, -0.1100618914]],\n",
       "\n",
       "        [[-0.3005036116,  0.1754093766,  0.1289444864,  ...,\n",
       "          -0.1934935898, -0.0386106707, -0.0386106707],\n",
       "         [-0.1005638391, -0.7623363137, -0.3624567986,  ...,\n",
       "           0.9596801996,  0.8667504191,  0.7752286792],\n",
       "         [ 0.6513223648,  0.4513825774,  0.2824193835,  ...,\n",
       "          -0.4539785087, -0.4075136483, -0.3314802051],\n",
       "         [-0.5004433990,  0.6977872252,  0.7752286792,  ...,\n",
       "          -0.3314802051, -0.1160521358, -0.1160521358]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.7263067365, -1.7817426920, -1.7231073380,  ...,\n",
       "          -2.6612727642, -2.6026372910, -2.3094606400],\n",
       "         [-0.5504007339, -1.4299306870, -1.3712953329,  ...,\n",
       "           0.4463998973,  1.7363772392,  1.6777418852],\n",
       "         [-2.1921899319, -1.3126600981, -0.8435773849,  ...,\n",
       "          -0.1985887438, -0.6090360880, -0.9022127390],\n",
       "         [-0.2572240829, -0.3158594072, -0.3744947314,  ...,\n",
       "           0.3291292489,  0.0945879146, -0.0813180879]],\n",
       "\n",
       "        [[-0.1875902116, -0.3227777183, -0.2957402170,  ...,\n",
       "          -0.1372021437, -0.1372021437, -0.1372021437],\n",
       "         [-1.1806038618,  0.2917109132,  0.2917109132,  ...,\n",
       "          -0.1372021437, -0.1372021437, -0.1372021437],\n",
       "         [ 0.2376359105,  0.2917109132,  0.2376359105,  ...,\n",
       "          -0.1372021437, -0.1372021437, -0.1372021437],\n",
       "         [-1.3428287506, -0.1875902116, -0.4579651952,  ...,\n",
       "          -0.1372021437, -0.1372021437, -0.1372021437]],\n",
       "\n",
       "        [[ 0.4177359045, -0.5041885376, -0.8204041719,  ...,\n",
       "           1.4131470919,  1.3418872356,  1.6091116667],\n",
       "         [ 0.2217712998,  0.3197536170,  0.4177359045,  ...,\n",
       "          -0.8204041719, -0.5531796813, -0.6511619687],\n",
       "         [ 0.6849603653,  0.0035379778, -0.4574242532,  ...,\n",
       "           0.5379869342,  0.2462668717,  0.0770247057],\n",
       "         [-0.2124684751,  0.8542025685,  1.2194093466,  ...,\n",
       "          -0.0944443271,  0.0770247057,  0.0525291301]]], device='cuda:0')), ('labels', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)), ('outputs1', tensor([[[ 1.0571230650,  1.5284662247,  1.5069520473,  ...,\n",
       "           1.4071314335,  1.3824717999,  1.4296525717],\n",
       "         [-0.5314831734, -0.2975863516, -0.4740500152,  ...,\n",
       "          -1.0204575062, -0.8862683177, -0.7883865237],\n",
       "         [ 1.1015125513,  0.3877572715,  0.7691746354,  ...,\n",
       "           2.1416318417,  2.1391296387,  2.0107817650],\n",
       "         [-0.4729399085, -0.8540231586, -0.7154914141,  ...,\n",
       "          -0.2249859571, -0.1862387657, -0.2041627169]],\n",
       "\n",
       "        [[ 0.8967608213,  0.9326105714,  0.8508777022,  ...,\n",
       "           0.8888470531,  0.8924900293,  0.8632448316],\n",
       "         [-0.0543487296, -0.0283283070, -0.0809132308,  ...,\n",
       "          -0.1119955927, -0.1412565708, -0.2010868639],\n",
       "         [ 0.7696955204,  0.7793846130,  0.7874919176,  ...,\n",
       "           0.2704375088,  0.2342232466,  0.2487496734],\n",
       "         [-0.3158974051, -0.2963086665, -0.3188992441,  ...,\n",
       "          -0.5010344386, -0.5220038891, -0.6056686640]],\n",
       "\n",
       "        [[ 0.6765819788, -0.2121437788, -0.1052381396,  ...,\n",
       "           1.2552623749,  0.9915544987,  0.9397338629],\n",
       "         [-0.0564197898,  0.5315872431,  0.6293574572,  ...,\n",
       "           0.2294376343,  0.3463193476,  0.3308519125],\n",
       "         [ 0.1576991677, -1.3117325306, -1.1976671219,  ...,\n",
       "           0.1986377835, -0.0185950994, -0.0424387157],\n",
       "         [-0.3142321408, -0.1444267929, -0.1075297296,  ...,\n",
       "          -0.4764069915, -0.4149537086, -0.4037414193]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.6129894257,  2.8010387421,  2.4971113205,  ...,\n",
       "           2.3657865524,  2.7245464325,  2.8044846058],\n",
       "         [ 0.0933082700, -0.2177407146, -0.2527686954,  ...,\n",
       "           0.2137302756,  0.3054757416,  0.2571405768],\n",
       "         [-1.4164612293, -1.4403387308, -1.1729028225,  ...,\n",
       "          -0.2779052854,  0.4878813028,  0.4391309023],\n",
       "         [-1.1891415119, -0.9976395369, -0.8563073874,  ...,\n",
       "          -0.0962758958, -0.0982989073, -0.2720350027]],\n",
       "\n",
       "        [[ 1.5051660538,  0.7414910793,  0.8754361272,  ...,\n",
       "           1.0144702196,  1.0144702196,  1.0144702196],\n",
       "         [-0.0052792132,  0.1674031466,  0.0733140707,  ...,\n",
       "           0.2601508796,  0.2601508796,  0.2601508796],\n",
       "         [-0.8014326096, -0.0252365470,  0.0669678450,  ...,\n",
       "          -0.4136917293, -0.4136917293, -0.4136917293],\n",
       "         [-0.5325863361, -0.3409140110, -0.4184311926,  ...,\n",
       "          -0.4402115941, -0.4402115941, -0.4402115941]],\n",
       "\n",
       "        [[ 0.0805295706,  0.4731121361,  0.7456161380,  ...,\n",
       "          -0.4117782116, -0.2892247438, -0.3196151853],\n",
       "         [ 0.2280142456,  0.6472351551,  0.8057162762,  ...,\n",
       "           0.3134619594,  0.4122175872,  0.4281774461],\n",
       "         [ 0.0562321842, -0.6934190989, -0.9834682941,  ...,\n",
       "          -0.7740205526, -0.7998239994, -0.9167050123],\n",
       "         [-0.2126272023, -0.0379672050, -0.0410510600,  ...,\n",
       "          -0.3929558992, -0.4063501060, -0.4945664108]]],\n",
       "       grad_fn=<ToCopyBackward0>)), ('spectrograms', tensor([[[[42.1847000122, 40.8246078491, 41.2877235413,  ...,\n",
       "           40.9536285400, 41.1957588196, 40.6115684509],\n",
       "          [41.3685226440, 39.9808197021, 40.2949142456,  ...,\n",
       "           39.9813461304, 40.2711868286, 39.6449165344],\n",
       "          [38.8526992798, 37.6004829407, 37.1911468506,  ...,\n",
       "           37.0110931396, 37.4394416809, 36.6992034912],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.0027790070, 20.0638656616, 23.0511016846,  ...,\n",
       "           23.3404369354, 20.0638656616, 24.1716976166],\n",
       "          [25.0820236206, 20.0638656616, 23.1986522675,  ...,\n",
       "           22.7906799316, 20.0638656616, 23.6314506531],\n",
       "          [22.3351516724, 20.7651996613, 23.7687301636,  ...,\n",
       "           21.2045192719, 20.0638656616, 21.8862762451],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.6563110352, 23.3762893677, 26.4567356110,  ...,\n",
       "           25.7656097412, 20.0638656616, 30.3707656860],\n",
       "          [28.3142623901, 25.1802806854, 27.0135688782,  ...,\n",
       "           25.6342105865, 20.2699260712, 29.9705772400],\n",
       "          [23.5815238953, 28.5849342346, 28.6278247833,  ...,\n",
       "           25.1046829224, 25.7483463287, 28.6995162964],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[36.9560470581, 38.5045242310, 37.5006332397,  ...,\n",
       "           37.6816177368, 38.4132537842, 36.1781272888],\n",
       "          [35.9786453247, 37.6109352112, 36.4316062927,  ...,\n",
       "           36.6866188049, 37.5390396118, 35.0619659424],\n",
       "          [32.9985466003, 34.9101295471, 33.0317802429,  ...,\n",
       "           33.5982856750, 34.9096374512, 31.5700321198],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[39.0105972290, 38.9858703613, 39.0705184937,  ...,\n",
       "           38.9686317444, 38.7612533569, 38.9291763306],\n",
       "          [38.0406723022, 38.0214195251, 38.1282768250,  ...,\n",
       "           38.0352249146, 37.7915992737, 37.9715652466],\n",
       "          [35.0652847290, 35.0607528687, 35.2652435303,  ...,\n",
       "           35.2209854126, 34.8088760376, 35.0456237793],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[20.0638656616, 20.0958404541, 20.0638656616,  ...,\n",
       "           20.5218105316, 21.3718719482, 21.0486240387],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.3990573883, 20.1154670715],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[24.9386043549, 24.7778224945, 25.0652542114,  ...,\n",
       "           24.7063827515, 26.6484489441, 23.4667396545],\n",
       "          [23.6630287170, 23.6781597137, 23.8670845032,  ...,\n",
       "           23.0362243652, 25.5808258057, 22.2663955688],\n",
       "          [20.0638656616, 20.5761432648, 20.0638656616,  ...,\n",
       "           20.0638656616, 22.1773872375, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[35.2584762573, 35.6066551208, 35.4446372986,  ...,\n",
       "           35.7833061218, 35.6092987061, 35.6208801270],\n",
       "          [34.3304786682, 34.6811294556, 34.4856605530,  ...,\n",
       "           34.8988151550, 34.6567916870, 34.6318244934],\n",
       "          [31.5385227203, 31.8658237457, 31.5641670227,  ...,\n",
       "           32.2691764832, 31.7695884705, 31.5424652100],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[33.0788192749, 32.7418365479, 32.7439460754,  ...,\n",
       "           32.5280952454, 33.0162353516, 32.6201477051],\n",
       "          [32.0944061279, 31.7364044189, 31.7373924255,  ...,\n",
       "           31.4278450012, 32.1298675537, 31.6825771332],\n",
       "          [29.0693740845, 28.6355495453, 28.6200294495,  ...,\n",
       "           27.7806205750, 29.5714797974, 28.8901157379],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[30.2505455017, 30.1308040619, 30.3832263947,  ...,\n",
       "           31.0682506561, 30.4399890900, 31.8277244568],\n",
       "          [29.2828369141, 29.1707153320, 29.4672584534,  ...,\n",
       "           30.2288990021, 29.6541366577, 31.2149772644],\n",
       "          [26.3036346436, 26.2325954437, 26.7135009766,  ...,\n",
       "           27.7036705017, 27.4129447937, 29.5188484192],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.4550380707, 32.1784934998, 33.0395202637,  ...,\n",
       "           33.2698402405, 33.3460388184, 26.1177139282],\n",
       "          [30.2866249084, 31.1594886780, 32.1526756287,  ...,\n",
       "           32.5898818970, 32.5090179443, 23.2331371307],\n",
       "          [26.4509677887, 28.0146102905, 29.5400924683,  ...,\n",
       "           30.6681270599, 30.1489429474, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.8403778076, 29.5790672302, 29.6673946381,  ...,\n",
       "           29.2075271606, 29.8252716064, 27.7963790894],\n",
       "          [28.8480453491, 28.5772552490, 28.7059516907,  ...,\n",
       "           28.1841239929, 28.8244838715, 26.4118003845],\n",
       "          [25.7716464996, 25.4891128540, 25.7745628357,  ...,\n",
       "           24.9638442993, 25.7107391357, 21.6530399323],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[37.7159347534, 32.5705299377, 34.9975624084,  ...,\n",
       "           35.0773086548, 36.0738945007, 21.9620819092],\n",
       "          [36.8329658508, 30.7642745972, 34.3763389587,  ...,\n",
       "           34.3135986328, 35.1477088928, 20.0638656616],\n",
       "          [34.2798385620, 23.7820930481, 32.7722091675,  ...,\n",
       "           32.2110900879, 32.1193084717, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.2069740295, 29.2144546509, 30.0014400482,  ...,\n",
       "           28.7742900848, 28.2130603790, 28.5824108124],\n",
       "          [30.3173351288, 28.3870792389, 29.0652732849,  ...,\n",
       "           27.7433185577, 27.1196479797, 27.4519805908],\n",
       "          [27.4098052979, 26.1612339020, 26.2206344604,  ...,\n",
       "           24.4814147949, 23.7012691498, 23.9311561584],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[36.8090209961, 35.9130477905, 35.1499137878,  ...,\n",
       "           34.5405082703, 31.9696331024, 30.8880577087],\n",
       "          [36.6877098083, 35.5676307678, 34.3781967163,  ...,\n",
       "           34.0414009094, 31.1051559448, 28.8315868378],\n",
       "          [36.3958396912, 34.6544036865, 32.0858840942,  ...,\n",
       "           32.5872917175, 28.2868881226, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[33.0039749146, 30.1730461121, 31.2955551147,  ...,\n",
       "           31.8755874634, 30.7615947723, 29.1464462280],\n",
       "          [32.2819786072, 29.0309219360, 30.4609012604,  ...,\n",
       "           31.1218719482, 29.8478851318, 27.5098323822],\n",
       "          [30.2648334503, 25.4270648956, 27.9727973938,  ...,\n",
       "           28.8325347900, 27.1091556549, 21.3343524933],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[37.6934967041, 37.4828300476, 37.3845748901,  ...,\n",
       "           37.1094360352, 37.9783287048, 31.1296424866],\n",
       "          [36.7375946045, 36.5600166321, 36.4394836426,  ...,\n",
       "           36.2282028198, 36.9647750854, 28.6095638275],\n",
       "          [33.7795372009, 33.8181037903, 33.5143585205,  ...,\n",
       "           33.6611213684, 33.7845077515, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.3640747070, 29.5979957581, 29.6310005188,  ...,\n",
       "           28.8990955353, 28.7560501099, 30.3869037628],\n",
       "          [25.3563327789, 28.7659912109, 28.7287540436,  ...,\n",
       "           27.8606109619, 27.6915779114, 29.2919425964],\n",
       "          [22.4658927917, 26.2637290955, 25.9972476959,  ...,\n",
       "           24.6008148193, 24.7735290527, 25.8096618652],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[23.9693794250, 31.0232906342, 30.3710861206,  ...,\n",
       "           27.9421329498, 28.1474380493, 29.1975746155],\n",
       "          [23.3764629364, 30.5381984711, 29.6399021149,  ...,\n",
       "           27.6590576172, 27.5778026581, 27.5285911560],\n",
       "          [22.4087791443, 29.2844562531, 27.5159034729,  ...,\n",
       "           27.3917026520, 27.6953716278, 21.3698463440],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[32.5275611877, 31.7032203674, 31.7122917175,  ...,\n",
       "           31.5942401886, 32.7085838318, 27.5873775482],\n",
       "          [31.4996376038, 30.6787757874, 30.6975650787,  ...,\n",
       "           30.7085227966, 31.7966537476, 25.8475112915],\n",
       "          [28.2031726837, 27.5655918121, 27.5283584595,  ...,\n",
       "           28.1637420654, 29.0011672974, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[35.3233795166, 35.1993293762, 35.6563987732,  ...,\n",
       "           35.5945549011, 35.4767875671, 34.7708206177],\n",
       "          [34.2808418274, 34.1445617676, 34.6932983398,  ...,\n",
       "           34.6174316406, 34.5452499390, 33.7583351135],\n",
       "          [31.0233898163, 30.8330898285, 31.7522354126,  ...,\n",
       "           31.6033058167, 31.7190780640, 30.6413459778],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.5045452118, 29.9320068359, 29.8019981384,  ...,\n",
       "           29.7867431641, 29.8363971710, 30.1028556824],\n",
       "          [28.5167675018, 28.9795608521, 28.8316421509,  ...,\n",
       "           28.8245315552, 28.8630867004, 29.1191272736],\n",
       "          [25.5003852844, 26.0611934662, 25.8522377014,  ...,\n",
       "           25.8734855652, 25.8890132904, 26.0595989227],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.1375961304, 31.9484806061, 31.8401947021,  ...,\n",
       "           31.7400741577, 31.3387298584, 31.9715785980],\n",
       "          [30.1433925629, 31.0741195679, 30.9124450684,  ...,\n",
       "           30.8200149536, 30.3433647156, 30.9738845825],\n",
       "          [27.0991134644, 28.4630546570, 28.0752964020,  ...,\n",
       "           28.0129451752, 27.2994766235, 27.8237495422],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.7886486053, 30.2292232513, 30.3949584961,  ...,\n",
       "           30.4261550903, 30.2857780457, 30.0124816895],\n",
       "          [28.7368679047, 29.2813415527, 29.4631862640,  ...,\n",
       "           29.4964179993, 29.3334007263, 29.0302734375],\n",
       "          [25.4318847656, 26.3980503082, 26.6052970886,  ...,\n",
       "           26.6569557190, 26.4233875275, 25.9948196411],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]]])), ('spectrograms_transformed', tensor([[[[36.9560470581, 38.5045242310, 37.5006332397,  ...,\n",
       "           37.6816177368, 38.4132537842, 36.1781272888],\n",
       "          [35.9786453247, 37.6109352112, 36.4316062927,  ...,\n",
       "           36.6866188049, 37.5390396118, 35.0619659424],\n",
       "          [32.9985466003, 34.9101295471, 33.0317802429,  ...,\n",
       "           33.5982856750, 34.9096374512, 31.5700321198],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.0027790070, 20.0638656616, 23.0511016846,  ...,\n",
       "           23.3404369354, 20.0638656616, 24.1716976166],\n",
       "          [25.0820236206, 20.0638656616, 23.1986522675,  ...,\n",
       "           22.7906799316, 20.0638656616, 23.6314506531],\n",
       "          [22.3351516724, 20.7651996613, 23.7687301636,  ...,\n",
       "           21.2045192719, 20.0638656616, 21.8862762451],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[42.1847000122, 40.8246078491, 41.2877235413,  ...,\n",
       "           40.9536285400, 41.1957588196, 40.6115684509],\n",
       "          [41.3685226440, 39.9808197021, 40.2949142456,  ...,\n",
       "           39.9813461304, 40.2711868286, 39.6449165344],\n",
       "          [38.8526992798, 37.6004829407, 37.1911468506,  ...,\n",
       "           37.0110931396, 37.4394416809, 36.6992034912],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.6563110352, 23.3762893677, 26.4567356110,  ...,\n",
       "           25.7656097412, 20.0638656616, 30.3707656860],\n",
       "          [28.3142623901, 25.1802806854, 27.0135688782,  ...,\n",
       "           25.6342105865, 20.2699260712, 29.9705772400],\n",
       "          [23.5815238953, 28.5849342346, 28.6278247833,  ...,\n",
       "           25.1046829224, 25.7483463287, 28.6995162964],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[35.2584762573, 35.6066551208, 35.4446372986,  ...,\n",
       "           35.7833061218, 35.6092987061, 35.6208801270],\n",
       "          [34.3304786682, 34.6811294556, 34.4856605530,  ...,\n",
       "           34.8988151550, 34.6567916870, 34.6318244934],\n",
       "          [31.5385227203, 31.8658237457, 31.5641670227,  ...,\n",
       "           32.2691764832, 31.7695884705, 31.5424652100],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[20.0638656616, 20.0958404541, 20.0638656616,  ...,\n",
       "           20.5218105316, 21.3718719482, 21.0486240387],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.3990573883, 20.1154670715],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[39.0105972290, 38.9858703613, 39.0705184937,  ...,\n",
       "           38.9686317444, 38.7612533569, 38.9291763306],\n",
       "          [38.0406723022, 38.0214195251, 38.1282768250,  ...,\n",
       "           38.0352249146, 37.7915992737, 37.9715652466],\n",
       "          [35.0652847290, 35.0607528687, 35.2652435303,  ...,\n",
       "           35.2209854126, 34.8088760376, 35.0456237793],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[24.9386043549, 24.7778224945, 25.0652542114,  ...,\n",
       "           24.7063827515, 26.6484489441, 23.4667396545],\n",
       "          [23.6630287170, 23.6781597137, 23.8670845032,  ...,\n",
       "           23.0362243652, 25.5808258057, 22.2663955688],\n",
       "          [20.0638656616, 20.5761432648, 20.0638656616,  ...,\n",
       "           20.0638656616, 22.1773872375, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[29.8403778076, 29.5790672302, 29.6673946381,  ...,\n",
       "           29.2075271606, 29.8252716064, 27.7963790894],\n",
       "          [28.8480453491, 28.5772552490, 28.7059516907,  ...,\n",
       "           28.1841239929, 28.8244838715, 26.4118003845],\n",
       "          [25.7716464996, 25.4891128540, 25.7745628357,  ...,\n",
       "           24.9638442993, 25.7107391357, 21.6530399323],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[30.2505455017, 30.1308040619, 30.3832263947,  ...,\n",
       "           31.0682506561, 30.4399890900, 31.8277244568],\n",
       "          [29.2828369141, 29.1707153320, 29.4672584534,  ...,\n",
       "           30.2288990021, 29.6541366577, 31.2149772644],\n",
       "          [26.3036346436, 26.2325954437, 26.7135009766,  ...,\n",
       "           27.7036705017, 27.4129447937, 29.5188484192],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[33.0788192749, 32.7418365479, 32.7439460754,  ...,\n",
       "           32.5280952454, 33.0162353516, 32.6201477051],\n",
       "          [32.0944061279, 31.7364044189, 31.7373924255,  ...,\n",
       "           31.4278450012, 32.1298675537, 31.6825771332],\n",
       "          [29.0693740845, 28.6355495453, 28.6200294495,  ...,\n",
       "           27.7806205750, 29.5714797974, 28.8901157379],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.4550380707, 32.1784934998, 33.0395202637,  ...,\n",
       "           33.2698402405, 33.3460388184, 26.1177139282],\n",
       "          [30.2866249084, 31.1594886780, 32.1526756287,  ...,\n",
       "           32.5898818970, 32.5090179443, 23.2331371307],\n",
       "          [26.4509677887, 28.0146102905, 29.5400924683,  ...,\n",
       "           30.6681270599, 30.1489429474, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[33.0039749146, 30.1730461121, 31.2955551147,  ...,\n",
       "           31.8755874634, 30.7615947723, 29.1464462280],\n",
       "          [32.2819786072, 29.0309219360, 30.4609012604,  ...,\n",
       "           31.1218719482, 29.8478851318, 27.5098323822],\n",
       "          [30.2648334503, 25.4270648956, 27.9727973938,  ...,\n",
       "           28.8325347900, 27.1091556549, 21.3343524933],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.2069740295, 29.2144546509, 30.0014400482,  ...,\n",
       "           28.7742900848, 28.2130603790, 28.5824108124],\n",
       "          [30.3173351288, 28.3870792389, 29.0652732849,  ...,\n",
       "           27.7433185577, 27.1196479797, 27.4519805908],\n",
       "          [27.4098052979, 26.1612339020, 26.2206344604,  ...,\n",
       "           24.4814147949, 23.7012691498, 23.9311561584],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[37.7159347534, 32.5705299377, 34.9975624084,  ...,\n",
       "           35.0773086548, 36.0738945007, 21.9620819092],\n",
       "          [36.8329658508, 30.7642745972, 34.3763389587,  ...,\n",
       "           34.3135986328, 35.1477088928, 20.0638656616],\n",
       "          [34.2798385620, 23.7820930481, 32.7722091675,  ...,\n",
       "           32.2110900879, 32.1193084717, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[36.8090209961, 35.9130477905, 35.1499137878,  ...,\n",
       "           34.5405082703, 31.9696331024, 30.8880577087],\n",
       "          [36.6877098083, 35.5676307678, 34.3781967163,  ...,\n",
       "           34.0414009094, 31.1051559448, 28.8315868378],\n",
       "          [36.3958396912, 34.6544036865, 32.0858840942,  ...,\n",
       "           32.5872917175, 28.2868881226, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[32.5275611877, 31.7032203674, 31.7122917175,  ...,\n",
       "           31.5942401886, 32.7085838318, 27.5873775482],\n",
       "          [31.4996376038, 30.6787757874, 30.6975650787,  ...,\n",
       "           30.7085227966, 31.7966537476, 25.8475112915],\n",
       "          [28.2031726837, 27.5655918121, 27.5283584595,  ...,\n",
       "           28.1637420654, 29.0011672974, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.3640747070, 29.5979957581, 29.6310005188,  ...,\n",
       "           28.8990955353, 28.7560501099, 30.3869037628],\n",
       "          [25.3563327789, 28.7659912109, 28.7287540436,  ...,\n",
       "           27.8606109619, 27.6915779114, 29.2919425964],\n",
       "          [22.4658927917, 26.2637290955, 25.9972476959,  ...,\n",
       "           24.6008148193, 24.7735290527, 25.8096618652],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[37.6934967041, 37.4828300476, 37.3845748901,  ...,\n",
       "           37.1094360352, 37.9783287048, 31.1296424866],\n",
       "          [36.7375946045, 36.5600166321, 36.4394836426,  ...,\n",
       "           36.2282028198, 36.9647750854, 28.6095638275],\n",
       "          [33.7795372009, 33.8181037903, 33.5143585205,  ...,\n",
       "           33.6611213684, 33.7845077515, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[23.9693794250, 31.0232906342, 30.3710861206,  ...,\n",
       "           27.9421329498, 28.1474380493, 29.1975746155],\n",
       "          [23.3764629364, 30.5381984711, 29.6399021149,  ...,\n",
       "           27.6590576172, 27.5778026581, 27.5285911560],\n",
       "          [22.4087791443, 29.2844562531, 27.5159034729,  ...,\n",
       "           27.3917026520, 27.6953716278, 21.3698463440],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[29.7886486053, 30.2292232513, 30.3949584961,  ...,\n",
       "           30.4261550903, 30.2857780457, 30.0124816895],\n",
       "          [28.7368679047, 29.2813415527, 29.4631862640,  ...,\n",
       "           29.4964179993, 29.3334007263, 29.0302734375],\n",
       "          [25.4318847656, 26.3980503082, 26.6052970886,  ...,\n",
       "           26.6569557190, 26.4233875275, 25.9948196411],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.5045452118, 29.9320068359, 29.8019981384,  ...,\n",
       "           29.7867431641, 29.8363971710, 30.1028556824],\n",
       "          [28.5167675018, 28.9795608521, 28.8316421509,  ...,\n",
       "           28.8245315552, 28.8630867004, 29.1191272736],\n",
       "          [25.5003852844, 26.0611934662, 25.8522377014,  ...,\n",
       "           25.8734855652, 25.8890132904, 26.0595989227],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[35.3233795166, 35.1993293762, 35.6563987732,  ...,\n",
       "           35.5945549011, 35.4767875671, 34.7708206177],\n",
       "          [34.2808418274, 34.1445617676, 34.6932983398,  ...,\n",
       "           34.6174316406, 34.5452499390, 33.7583351135],\n",
       "          [31.0233898163, 30.8330898285, 31.7522354126,  ...,\n",
       "           31.6033058167, 31.7190780640, 30.6413459778],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.1375961304, 31.9484806061, 31.8401947021,  ...,\n",
       "           31.7400741577, 31.3387298584, 31.9715785980],\n",
       "          [30.1433925629, 31.0741195679, 30.9124450684,  ...,\n",
       "           30.8200149536, 30.3433647156, 30.9738845825],\n",
       "          [27.0991134644, 28.4630546570, 28.0752964020,  ...,\n",
       "           28.0129451752, 27.2994766235, 27.8237495422],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]]])), ('spectrograms2train', tensor([[[[42.1847000122, 40.8246078491, 41.2877235413,  ...,\n",
       "           40.9536285400, 41.1957588196, 40.6115684509],\n",
       "          [41.3685226440, 39.9808197021, 40.2949142456,  ...,\n",
       "           39.9813461304, 40.2711868286, 39.6449165344],\n",
       "          [38.8526992798, 37.6004829407, 37.1911468506,  ...,\n",
       "           37.0110931396, 37.4394416809, 36.6992034912],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.0027790070, 20.0638656616, 23.0511016846,  ...,\n",
       "           23.3404369354, 20.0638656616, 24.1716976166],\n",
       "          [25.0820236206, 20.0638656616, 23.1986522675,  ...,\n",
       "           22.7906799316, 20.0638656616, 23.6314506531],\n",
       "          [22.3351516724, 20.7651996613, 23.7687301636,  ...,\n",
       "           21.2045192719, 20.0638656616, 21.8862762451],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.6563110352, 23.3762893677, 26.4567356110,  ...,\n",
       "           25.7656097412, 20.0638656616, 30.3707656860],\n",
       "          [28.3142623901, 25.1802806854, 27.0135688782,  ...,\n",
       "           25.6342105865, 20.2699260712, 29.9705772400],\n",
       "          [23.5815238953, 28.5849342346, 28.6278247833,  ...,\n",
       "           25.1046829224, 25.7483463287, 28.6995162964],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[36.9560470581, 38.5045242310, 37.5006332397,  ...,\n",
       "           37.6816177368, 38.4132537842, 36.1781272888],\n",
       "          [35.9786453247, 37.6109352112, 36.4316062927,  ...,\n",
       "           36.6866188049, 37.5390396118, 35.0619659424],\n",
       "          [32.9985466003, 34.9101295471, 33.0317802429,  ...,\n",
       "           33.5982856750, 34.9096374512, 31.5700321198],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[39.0105972290, 38.9858703613, 39.0705184937,  ...,\n",
       "           38.9686317444, 38.7612533569, 38.9291763306],\n",
       "          [38.0406723022, 38.0214195251, 38.1282768250,  ...,\n",
       "           38.0352249146, 37.7915992737, 37.9715652466],\n",
       "          [35.0652847290, 35.0607528687, 35.2652435303,  ...,\n",
       "           35.2209854126, 34.8088760376, 35.0456237793],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[20.0638656616, 20.0958404541, 20.0638656616,  ...,\n",
       "           20.5218105316, 21.3718719482, 21.0486240387],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.3990573883, 20.1154670715],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[24.9386043549, 24.7778224945, 25.0652542114,  ...,\n",
       "           24.7063827515, 26.6484489441, 23.4667396545],\n",
       "          [23.6630287170, 23.6781597137, 23.8670845032,  ...,\n",
       "           23.0362243652, 25.5808258057, 22.2663955688],\n",
       "          [20.0638656616, 20.5761432648, 20.0638656616,  ...,\n",
       "           20.0638656616, 22.1773872375, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[35.2584762573, 35.6066551208, 35.4446372986,  ...,\n",
       "           35.7833061218, 35.6092987061, 35.6208801270],\n",
       "          [34.3304786682, 34.6811294556, 34.4856605530,  ...,\n",
       "           34.8988151550, 34.6567916870, 34.6318244934],\n",
       "          [31.5385227203, 31.8658237457, 31.5641670227,  ...,\n",
       "           32.2691764832, 31.7695884705, 31.5424652100],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[33.0788192749, 32.7418365479, 32.7439460754,  ...,\n",
       "           32.5280952454, 33.0162353516, 32.6201477051],\n",
       "          [32.0944061279, 31.7364044189, 31.7373924255,  ...,\n",
       "           31.4278450012, 32.1298675537, 31.6825771332],\n",
       "          [29.0693740845, 28.6355495453, 28.6200294495,  ...,\n",
       "           27.7806205750, 29.5714797974, 28.8901157379],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[30.2505455017, 30.1308040619, 30.3832263947,  ...,\n",
       "           31.0682506561, 30.4399890900, 31.8277244568],\n",
       "          [29.2828369141, 29.1707153320, 29.4672584534,  ...,\n",
       "           30.2288990021, 29.6541366577, 31.2149772644],\n",
       "          [26.3036346436, 26.2325954437, 26.7135009766,  ...,\n",
       "           27.7036705017, 27.4129447937, 29.5188484192],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.4550380707, 32.1784934998, 33.0395202637,  ...,\n",
       "           33.2698402405, 33.3460388184, 26.1177139282],\n",
       "          [30.2866249084, 31.1594886780, 32.1526756287,  ...,\n",
       "           32.5898818970, 32.5090179443, 23.2331371307],\n",
       "          [26.4509677887, 28.0146102905, 29.5400924683,  ...,\n",
       "           30.6681270599, 30.1489429474, 20.0638656616],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.8403778076, 29.5790672302, 29.6673946381,  ...,\n",
       "           29.2075271606, 29.8252716064, 27.7963790894],\n",
       "          [28.8480453491, 28.5772552490, 28.7059516907,  ...,\n",
       "           28.1841239929, 28.8244838715, 26.4118003845],\n",
       "          [25.7716464996, 25.4891128540, 25.7745628357,  ...,\n",
       "           24.9638442993, 25.7107391357, 21.6530399323],\n",
       "          ...,\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[33.0039749146, 30.1730461121, 31.2955551147,  ...,\n",
       "           31.8755874634, 30.7615947723, 29.1464462280],\n",
       "          [32.2819786072, 29.0309219360, 30.4609012604,  ...,\n",
       "           31.1218719482, 29.8478851318, 27.5098323822],\n",
       "          [30.2648334503, 25.4270648956, 27.9727973938,  ...,\n",
       "           28.8325347900, 27.1091556549, 21.3343524933],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.2069740295, 29.2144546509, 30.0014400482,  ...,\n",
       "           28.7742900848, 28.2130603790, 28.5824108124],\n",
       "          [30.3173351288, 28.3870792389, 29.0652732849,  ...,\n",
       "           27.7433185577, 27.1196479797, 27.4519805908],\n",
       "          [27.4098052979, 26.1612339020, 26.2206344604,  ...,\n",
       "           24.4814147949, 23.7012691498, 23.9311561584],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[37.7159347534, 32.5705299377, 34.9975624084,  ...,\n",
       "           35.0773086548, 36.0738945007, 21.9620819092],\n",
       "          [36.8329658508, 30.7642745972, 34.3763389587,  ...,\n",
       "           34.3135986328, 35.1477088928, 20.0638656616],\n",
       "          [34.2798385620, 23.7820930481, 32.7722091675,  ...,\n",
       "           32.2110900879, 32.1193084717, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[36.8090209961, 35.9130477905, 35.1499137878,  ...,\n",
       "           34.5405082703, 31.9696331024, 30.8880577087],\n",
       "          [36.6877098083, 35.5676307678, 34.3781967163,  ...,\n",
       "           34.0414009094, 31.1051559448, 28.8315868378],\n",
       "          [36.3958396912, 34.6544036865, 32.0858840942,  ...,\n",
       "           32.5872917175, 28.2868881226, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[32.5275611877, 31.7032203674, 31.7122917175,  ...,\n",
       "           31.5942401886, 32.7085838318, 27.5873775482],\n",
       "          [31.4996376038, 30.6787757874, 30.6975650787,  ...,\n",
       "           30.7085227966, 31.7966537476, 25.8475112915],\n",
       "          [28.2031726837, 27.5655918121, 27.5283584595,  ...,\n",
       "           28.1637420654, 29.0011672974, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[26.3640747070, 29.5979957581, 29.6310005188,  ...,\n",
       "           28.8990955353, 28.7560501099, 30.3869037628],\n",
       "          [25.3563327789, 28.7659912109, 28.7287540436,  ...,\n",
       "           27.8606109619, 27.6915779114, 29.2919425964],\n",
       "          [22.4658927917, 26.2637290955, 25.9972476959,  ...,\n",
       "           24.6008148193, 24.7735290527, 25.8096618652],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[37.6934967041, 37.4828300476, 37.3845748901,  ...,\n",
       "           37.1094360352, 37.9783287048, 31.1296424866],\n",
       "          [36.7375946045, 36.5600166321, 36.4394836426,  ...,\n",
       "           36.2282028198, 36.9647750854, 28.6095638275],\n",
       "          [33.7795372009, 33.8181037903, 33.5143585205,  ...,\n",
       "           33.6611213684, 33.7845077515, 20.0638656616],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[23.9693794250, 31.0232906342, 30.3710861206,  ...,\n",
       "           27.9421329498, 28.1474380493, 29.1975746155],\n",
       "          [23.3764629364, 30.5381984711, 29.6399021149,  ...,\n",
       "           27.6590576172, 27.5778026581, 27.5285911560],\n",
       "          [22.4087791443, 29.2844562531, 27.5159034729,  ...,\n",
       "           27.3917026520, 27.6953716278, 21.3698463440],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]],\n",
       "\n",
       "\n",
       "        [[[29.7886486053, 30.2292232513, 30.3949584961,  ...,\n",
       "           30.4261550903, 30.2857780457, 30.0124816895],\n",
       "          [28.7368679047, 29.2813415527, 29.4631862640,  ...,\n",
       "           29.4964179993, 29.3334007263, 29.0302734375],\n",
       "          [25.4318847656, 26.3980503082, 26.6052970886,  ...,\n",
       "           26.6569557190, 26.4233875275, 25.9948196411],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[29.5045452118, 29.9320068359, 29.8019981384,  ...,\n",
       "           29.7867431641, 29.8363971710, 30.1028556824],\n",
       "          [28.5167675018, 28.9795608521, 28.8316421509,  ...,\n",
       "           28.8245315552, 28.8630867004, 29.1191272736],\n",
       "          [25.5003852844, 26.0611934662, 25.8522377014,  ...,\n",
       "           25.8734855652, 25.8890132904, 26.0595989227],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[35.3233795166, 35.1993293762, 35.6563987732,  ...,\n",
       "           35.5945549011, 35.4767875671, 34.7708206177],\n",
       "          [34.2808418274, 34.1445617676, 34.6932983398,  ...,\n",
       "           34.6174316406, 34.5452499390, 33.7583351135],\n",
       "          [31.0233898163, 30.8330898285, 31.7522354126,  ...,\n",
       "           31.6033058167, 31.7190780640, 30.6413459778],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]],\n",
       "\n",
       "         [[31.1375961304, 31.9484806061, 31.8401947021,  ...,\n",
       "           31.7400741577, 31.3387298584, 31.9715785980],\n",
       "          [30.1433925629, 31.0741195679, 30.9124450684,  ...,\n",
       "           30.8200149536, 30.3433647156, 30.9738845825],\n",
       "          [27.0991134644, 28.4630546570, 28.0752964020,  ...,\n",
       "           28.0129451752, 27.2994766235, 27.8237495422],\n",
       "          ...,\n",
       "          [ 0.0000000000,  0.0000000000,  0.0000000000,  ...,\n",
       "            0.0000000000,  0.0000000000,  0.0000000000],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616],\n",
       "          [20.0638656616, 20.0638656616, 20.0638656616,  ...,\n",
       "           20.0638656616, 20.0638656616, 20.0638656616]]]], device='cuda:0')), ('labels2train', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)), ('outputs2', tensor([[-0.1099342778, -0.0395435542,  0.0182726607,  ...,\n",
       "          0.0152867138,  0.0469388999,  0.0723902211],\n",
       "        [-0.0027360246, -0.0370553583, -0.0743855312,  ...,\n",
       "         -0.1259976029,  0.0389643386,  0.0924044698],\n",
       "        [-0.0993592814, -0.0254135653, -0.0289401188,  ...,\n",
       "          0.0385211185,  0.0818794817,  0.0515264608],\n",
       "        ...,\n",
       "        [ 0.0293693393, -0.0094390661,  0.0463358015,  ...,\n",
       "          0.1373985410,  0.1347483099,  0.0244704261],\n",
       "        [-0.0964960083, -0.0676649436, -0.0587387681,  ...,\n",
       "          0.0738983899,  0.0402776413, -0.0922690406],\n",
       "        [ 0.0469164811, -0.0489447936,  0.0610344708,  ...,\n",
       "          0.0577062666,  0.0063281581,  0.0589281768]], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)), ('m', Sigmoid()), ('probs', tensor([[0.4725440741, 0.4901153743, 0.5045680404,  ..., 0.5038216114,\n",
       "         0.5117325783, 0.5180896521],\n",
       "        [0.4993159473, 0.4907372296, 0.4814122319,  ..., 0.4685422480,\n",
       "         0.5097398162, 0.5230847001],\n",
       "        [0.4751805961, 0.4936469495, 0.4927654266,  ..., 0.5096290708,\n",
       "         0.5204584599, 0.5128787756],\n",
       "        ...,\n",
       "        [0.5073418021, 0.4976402223, 0.5115818977,  ..., 0.5342956781,\n",
       "         0.5336361527, 0.5061172843],\n",
       "        [0.4758946896, 0.4830901921, 0.4853195250,  ..., 0.5184662342,\n",
       "         0.5100680590, 0.4769491255],\n",
       "        [0.5117269754, 0.4877662659, 0.5152538419,  ..., 0.5144225359,\n",
       "         0.5015820265, 0.5147277713]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward0>)), ('y_true', tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 1.], device='cuda:0', dtype=torch.float64)), ('y_pred', tensor([0.5579645634, 0.5461994410, 0.5524026155, 0.5543060899, 0.5525338054,\n",
       "        0.5610695481, 0.5778523684, 0.5527632833, 0.5605435967, 0.5505508780,\n",
       "        0.5458222032, 0.5618371367, 0.5538383722, 0.5609298944, 0.5618994832,\n",
       "        0.5702769160, 0.5705745220, 0.5629146099, 0.5540492535, 0.5693921447,\n",
       "        0.5790189505, 0.5796217322, 0.5572032332, 0.5537611842, 0.5563960671,\n",
       "        0.5757956505, 0.5582692623, 0.5702224970, 0.5476091504, 0.5592283607,\n",
       "        0.5790541172, 0.5578461289, 0.5697925687, 0.5597290993, 0.5554207563,\n",
       "        0.5547884107, 0.5514792204, 0.5515495539, 0.5522425771, 0.5644370317,\n",
       "        0.5666142106, 0.5795472264, 0.5634720325, 0.5712334514, 0.5551217794,\n",
       "        0.5729913116, 0.5706498027, 0.5635304451, 0.5622810125, 0.5587332845,\n",
       "        0.5673164129, 0.5635917783, 0.5617815256, 0.5587698817, 0.5516663194,\n",
       "        0.5812271833, 0.5577105284, 0.5524920821, 0.5495153666, 0.5840366483,\n",
       "        0.5641650558, 0.5678288937, 0.5519585013, 0.5747405887, 0.5710087419,\n",
       "        0.5563946366, 0.5566397905, 0.5959411860, 0.5661067367, 0.5551086664,\n",
       "        0.5787360072, 0.5805657506, 0.5724329948, 0.5504681468, 0.5501505733,\n",
       "        0.5684032440, 0.5659897327, 0.5634322166, 0.5658955574, 0.5604677796,\n",
       "        0.5616497397, 0.5605353713, 0.5733431578, 0.5776491165, 0.5690030456,\n",
       "        0.5700762272, 0.5570225716, 0.5664869547, 0.5647017956, 0.5686284900,\n",
       "        0.5829052925, 0.5804331303, 0.5628849268, 0.5610418320, 0.5641272068,\n",
       "        0.5754125118, 0.5571780205, 0.5701043010, 0.5596294999, 0.5759171247,\n",
       "        0.5673568249, 0.5655035377, 0.5768820047, 0.5793079734, 0.5495651364,\n",
       "        0.5701081753, 0.5542795062, 0.5735532045, 0.5733008385, 0.5662911534,\n",
       "        0.5674970150, 0.5497420430, 0.5463945270, 0.5500103235, 0.5754788518,\n",
       "        0.5677698851, 0.5726191998, 0.5821858644, 0.5639104843, 0.5702239871,\n",
       "        0.5654234886, 0.5577812791, 0.5555641055, 0.5517092347, 0.5797044039,\n",
       "        0.5591069460, 0.5691621304, 0.5764430165], device='cuda:0',\n",
       "       grad_fn=<MaxBackward0>)), ('Y_true', tensor([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 1.], device='cuda:0', dtype=torch.float64)), ('Y_pred', tensor([0.5579645634, 0.5461994410, 0.5524026155, 0.5543060899, 0.5525338054,\n",
       "        0.5610695481, 0.5778523684, 0.5527632833, 0.5605435967, 0.5505508780,\n",
       "        0.5458222032, 0.5618371367, 0.5538383722, 0.5609298944, 0.5618994832,\n",
       "        0.5702769160, 0.5705745220, 0.5629146099, 0.5540492535, 0.5693921447,\n",
       "        0.5790189505, 0.5796217322, 0.5572032332, 0.5537611842, 0.5563960671,\n",
       "        0.5757956505, 0.5582692623, 0.5702224970, 0.5476091504, 0.5592283607,\n",
       "        0.5790541172, 0.5578461289, 0.5697925687, 0.5597290993, 0.5554207563,\n",
       "        0.5547884107, 0.5514792204, 0.5515495539, 0.5522425771, 0.5644370317,\n",
       "        0.5666142106, 0.5795472264, 0.5634720325, 0.5712334514, 0.5551217794,\n",
       "        0.5729913116, 0.5706498027, 0.5635304451, 0.5622810125, 0.5587332845,\n",
       "        0.5673164129, 0.5635917783, 0.5617815256, 0.5587698817, 0.5516663194,\n",
       "        0.5812271833, 0.5577105284, 0.5524920821, 0.5495153666, 0.5840366483,\n",
       "        0.5641650558, 0.5678288937, 0.5519585013, 0.5747405887, 0.5710087419,\n",
       "        0.5563946366, 0.5566397905, 0.5959411860, 0.5661067367, 0.5551086664,\n",
       "        0.5787360072, 0.5805657506, 0.5724329948, 0.5504681468, 0.5501505733,\n",
       "        0.5684032440, 0.5659897327, 0.5634322166, 0.5658955574, 0.5604677796,\n",
       "        0.5616497397, 0.5605353713, 0.5733431578, 0.5776491165, 0.5690030456,\n",
       "        0.5700762272, 0.5570225716, 0.5664869547, 0.5647017956, 0.5686284900,\n",
       "        0.5829052925, 0.5804331303, 0.5628849268, 0.5610418320, 0.5641272068,\n",
       "        0.5754125118, 0.5571780205, 0.5701043010, 0.5596294999, 0.5759171247,\n",
       "        0.5673568249, 0.5655035377, 0.5768820047, 0.5793079734, 0.5495651364,\n",
       "        0.5701081753, 0.5542795062, 0.5735532045, 0.5733008385, 0.5662911534,\n",
       "        0.5674970150, 0.5497420430, 0.5463945270, 0.5500103235, 0.5754788518,\n",
       "        0.5677698851, 0.5726191998, 0.5821858644, 0.5639104843, 0.5702239871,\n",
       "        0.5654234886, 0.5577812791, 0.5555641055, 0.5517092347, 0.5797044039,\n",
       "        0.5591069460, 0.5691621304, 0.5764430165], device='cuda:0',\n",
       "       grad_fn=<MaxBackward0>)), ('loss', tensor(0.6936614266, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)), ('_i39', '# Ver el resumen de la memoria de la GPU\\nprint(torch.cuda.memory_summary())'), ('_i40', \"import gc\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los objetos en el espacio de nombres local\\nfor name, obj in globals().items():\\n    if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n        print(f'{name}: {obj.size()}')\"), ('gc', <module 'gc' (built-in)>), ('name', '__name__'), ('obj', '__main__'), ('_i41', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\ndelete_tensor(\\'tensor_name\\')'), ('list_gpu_tensors', <function list_gpu_tensors at 0x73c6e1da4f70>), ('delete_tensor', <function delete_tensor at 0x73c68299dcf0>), ('_i42', 'import torch\\nimport gc\\n\\ndef list_gpu_tensors():\\n    \"\"\"Lista todos los tensores en la GPU\"\"\"\\n    # Obtener una lista de los nombres de variables en globals()\\n    tensor_names = [name for name, obj in globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda]\\n    \\n    for name in tensor_names:\\n        obj = globals()[name]\\n        print(f\\'{name}: {obj.size()}\\')\\n\\ndef delete_tensor(name):\\n    \"\"\"Elimina un tensor específico por nombre\"\"\"\\n    if name in globals():\\n        obj = globals()[name]\\n        if isinstance(obj, torch.Tensor) and obj.is_cuda:\\n            print(f\\'Deleting tensor: {name}\\')\\n            del obj\\n            torch.cuda.empty_cache()\\n\\n# Recolectar basura\\ngc.collect()\\n\\n# Listar todos los tensores en la GPU\\nlist_gpu_tensors()\\n\\n# Eliminar un tensor específico (por ejemplo, \\'tensor_name\\')\\n#delete_tensor(\\'tensor_name\\')'), ('_i43', 'globals().items() ')])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals().items() if isinstance(obj, torch.Tensor) and obj.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _data,\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for batch_idx, _data in enumerate(train_loader):\\n    cont+=1\\n    eeg, labels = _data \\n    eeg, labels = eeg.to(device), labels.to(device)\\n    break'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for batch_idx, _data in enumerate(train_loader):\n",
    "    cont+=1\n",
    "    eeg, labels = _data \n",
    "    eeg, labels = eeg.to(device), labels.to(device)\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Zero the gradients\\noptimizer1.zero_grad(set_to_none=True)\\noptimizer2.zero_grad(set_to_none=True)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Zero the gradients\n",
    "optimizer1.zero_grad(set_to_none=True)\n",
    "optimizer2.zero_grad(set_to_none=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizando la semilla random.seed el data loader siempre decide por el mismo batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eeg[0,0,:]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''eeg[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Perform forward pass to DSF\\noutputs1 = model1(eeg)  # (batch, n_class)\\noutputs1 = outputs1.squeeze(1)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Perform forward pass to DSF\n",
    "outputs1 = model1(eeg)  # (batch, n_class)\n",
    "outputs1 = outputs1.squeeze(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs1[0,0,:]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if   experiment_1 == 'exp1': # sin normalizacion \\n    pass\\nelif experiment_1 == 'exp2': # normalizacion por canal\\n    mean     = outputs1.mean(dim=2, keepdim=True)\\n    std      = outputs1.std(dim=2, keepdim=True)\\n\\n    outputs1 = (outputs1 - mean) / std\\n\\nelif experiment_1 == 'exp3': # normalizacion global\\n    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if   experiment_1 == 'exp1': # sin normalizacion \n",
    "    pass\n",
    "elif experiment_1 == 'exp2': # normalizacion por canal\n",
    "    mean     = outputs1.mean(dim=2, keepdim=True)\n",
    "    std      = outputs1.std(dim=2, keepdim=True)\n",
    "\n",
    "    outputs1 = (outputs1 - mean) / std\n",
    "\n",
    "elif experiment_1 == 'exp3': # normalizacion global\n",
    "    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"outputs1 = outputs1.to('cpu')\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1 = outputs1.to('cpu')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs1[0,0,:]'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create spectrogram from outputs1\\nspectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# create spectrogram from outputs1\n",
    "spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms[0,0,:,:]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms = torch.from_numpy(spectrograms)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms = torch.from_numpy(spectrograms)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms[0,0,:,:]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms_transformed = transform_train(spectrograms)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms_transformed = transform_train(spectrograms)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms_transformed[0,0,:,:]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms_transformed[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train = torch.cat((spectrograms, spectrograms_transformed), axis=0)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train = torch.cat((spectrograms, spectrograms_transformed), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train[0,0,:,:]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train = spectrograms2train.to(device)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train = spectrograms2train.to(device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train[0,0,:,:]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels2train = torch.cat((labels, labels), axis=0)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''labels2train = torch.cat((labels, labels), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs2 = model2(spectrograms2train)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs2 = model2(spectrograms2train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs2[0,:]  '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs2[0,:]  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m     = nn.Sigmoid()\\nprobs = m(outputs2)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''m     = nn.Sigmoid()\n",
    "probs = m(outputs2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probs[0,:]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''probs[0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_true  = torch.max(labels2train, dim = 1)[0]\\ny_pred  = torch.max(probs, dim = 1)[0]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_true  = torch.max(labels2train, dim = 1)[0]\n",
    "y_pred  = torch.max(probs, dim = 1)[0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if cont == 1:\\n    Y_true = y_true\\n    Y_pred = y_pred\\n\\nelse:                \\n    Y_true = torch.cat((Y_true, y_true), axis=0)\\n    Y_pred = torch.cat((Y_pred, y_pred), axis=0)'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if cont == 1:\n",
    "    Y_true = y_true\n",
    "    Y_pred = y_pred\n",
    "\n",
    "else:                \n",
    "    Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "    Y_pred = torch.cat((Y_pred, y_pred), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_true'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_true'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss = criterion(outputs2, labels2train)'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss = criterion(outputs2, labels2train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss.backward()\\ntrain_loss += loss.item()'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss.backward()\n",
    "train_loss += loss.item()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Perform optimization\\noptimizer1.step()\\noptimizer2.step()\\nscheduler1.step()\\nscheduler2.step()'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Perform optimization\n",
    "optimizer1.step()\n",
    "optimizer2.step()\n",
    "scheduler1.step()\n",
    "scheduler2.step()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# record training loss\\ntrain_losses.append(loss.item())'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# record training loss\n",
    "train_losses.append(loss.item())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'del _data\\ntorch.cuda.empty_cache()'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''del _data\n",
    "torch.cuda.empty_cache()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true, val_pred = Y_true.to('cpu').detach().numpy(), Y_pred.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55797106, 0.54620266, 0.5524    , 0.5542989 , 0.5525311 ,\n",
       "       0.56108165, 0.5778388 , 0.55276626, 0.5605448 , 0.55055296,\n",
       "       0.545822  , 0.5618415 , 0.55384964, 0.5609321 , 0.5619036 ,\n",
       "       0.5702581 , 0.57056797, 0.56290585, 0.5540417 , 0.56938565,\n",
       "       0.57902074, 0.5796253 , 0.55720246, 0.5537558 , 0.55639726,\n",
       "       0.5757947 , 0.5582665 , 0.5702161 , 0.5476137 , 0.5592189 ,\n",
       "       0.5790522 , 0.5578448 , 0.5698016 , 0.55972767, 0.5554231 ,\n",
       "       0.5547875 , 0.5514725 , 0.55154866, 0.55223924, 0.56443137,\n",
       "       0.56661147, 0.5795406 , 0.5634781 , 0.57123744, 0.5551256 ,\n",
       "       0.57297796, 0.57063806, 0.56352264, 0.56227785, 0.5587263 ,\n",
       "       0.5673289 , 0.56358534, 0.56178737, 0.5587469 , 0.5516604 ,\n",
       "       0.5812343 , 0.55771023, 0.5524937 , 0.54951924, 0.5840419 ,\n",
       "       0.56415915, 0.5678297 , 0.55195683, 0.5747315 , 0.5710066 ,\n",
       "       0.5563779 , 0.55663514, 0.5959412 , 0.56611717, 0.55511135,\n",
       "       0.57873577, 0.5805522 , 0.5724227 , 0.550469  , 0.55015546,\n",
       "       0.5684056 , 0.56599617, 0.5634248 , 0.5658929 , 0.56047237,\n",
       "       0.56165236, 0.5605375 , 0.5733414 , 0.5776575 , 0.56900704,\n",
       "       0.5700605 , 0.5570258 , 0.5665062 , 0.5647127 , 0.5686367 ,\n",
       "       0.58290434, 0.5804344 , 0.5628821 , 0.56104237, 0.5641255 ,\n",
       "       0.5754164 , 0.5571722 , 0.5700968 , 0.55963653, 0.5759203 ,\n",
       "       0.5673605 , 0.5654971 , 0.5768842 , 0.5793126 , 0.5495667 ,\n",
       "       0.57010376, 0.5542776 , 0.5735549 , 0.57329315, 0.5662926 ,\n",
       "       0.56749743, 0.5497423 , 0.5464011 , 0.5500061 , 0.5754761 ,\n",
       "       0.5677797 , 0.5726142 , 0.5821877 , 0.56391454, 0.5702215 ,\n",
       "       0.5654196 , 0.55777794, 0.5555735 , 0.55169976, 0.5796991 ,\n",
       "       0.55910516, 0.56916064, 0.5764452 ], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.693660666420691)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aucpr = average_precision_score(y_val_true,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.isnan(val_pred).any():\n",
    "    print('nan found in pred')\n",
    "    train_aucpr = 0\n",
    "else:   \n",
    "    train_aucpr = average_precision_score(y_val_true,val_pred)\n",
    "    \n",
    "print('Train Epoch: {} \\tTrainLoss: {:.6f} \\tTrainAUCpr: {:.6f}'.format(epoch, np.mean(train_losses), train_aucpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tTrainLoss: 0.693661 \tTrainAUCpr: 0.719156\n"
     ]
    }
   ],
   "source": [
    "if np.isnan(val_pred).any():\n",
    "    print('nan found in pred')\n",
    "    train_aucpr = 0\n",
    "else:   \n",
    "    train_aucpr = average_precision_score(y_val_true,val_pred)\n",
    "    \n",
    "print('Train Epoch: {} \\tTrainLoss: {:.6f} \\tTrainAUCpr: {:.6f}'.format(epoch, np.mean(train_losses), train_aucpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7191555105653817)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aucpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nvalid_losses, valid_aucpr = validate_v2(\\n                                        model1,\\n                                        model2,\\n                                        device, \\n                                        valid_loader, \\n                                        criterion, \\n                                        epoch,\\n                                        experiment_1,\\n                                        experiment_2\\n                                       )\\n\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "valid_losses, valid_aucpr = validate_v2(\n",
    "                                        model1,\n",
    "                                        model2,\n",
    "                                        device, \n",
    "                                        valid_loader, \n",
    "                                        criterion, \n",
    "                                        epoch,\n",
    "                                        experiment_1,\n",
    "                                        experiment_2\n",
    "                                       )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECOG_SAMPLE_RATE = 250\n",
    "ECOG_CHANNELS    = 4\n",
    "TT               = 1000 \n",
    "SPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) \n",
    "overlap          = 500 \n",
    "SPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) \n",
    "SPEC_NFFT        = 500\n",
    "if   experiment_2 == '.1':  \n",
    "    top_db       = 40.0\n",
    "elif experiment_2 == '.2':\n",
    "    top_db       = 60.0\n",
    "elif experiment_2 == '.3':\n",
    "    top_db       = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_losses = []\n",
    "cont         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for eeg, labels in valid_loader:\n",
    "        cont+=1\n",
    "    \n",
    "        eeg, labels = eeg.to(device), labels.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2740582228, 1.8588944674, 2.5337054729,  ..., 1.3190456629,\n",
       "        1.0941085815, 0.6892219782], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1    = model1(eeg)\n",
    "outputs1    = outputs1.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1259495020, -0.0817473531, -0.3597738743,  ...,\n",
       "        -0.1269418001, -0.3000434637, -0.1780759096], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if   experiment_1 == 'exp1': # sin normalizacion \n",
    "    pass\n",
    "elif experiment_1 == 'exp2': # normalizacion por canal\n",
    "    mean     = outputs1.mean(dim=2, keepdim=True)\n",
    "    std      = outputs1.std(dim=2, keepdim=True)\n",
    "\n",
    "    outputs1 = (outputs1 - mean) / std\n",
    "\n",
    "elif experiment_1 == 'exp3': # normalizacion global\n",
    "    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = outputs1.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1259495020, -0.0817473531, -0.3597738743,  ...,\n",
       "        -0.1269418001, -0.3000434637, -0.1780759096], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.629631, 37.139008, 35.388412, ..., 37.550705, 36.55433 ,\n",
       "        32.092293],\n",
       "       [15.629631, 36.658447, 35.26042 , ..., 37.148487, 36.000847,\n",
       "        29.547777],\n",
       "       [22.065676, 35.139805, 35.05574 , ..., 35.92053 , 34.417027,\n",
       "        15.629631],\n",
       "       ...,\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        19.849653],\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        18.304625],\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        15.629631]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.6296310425, 37.1390075684, 35.3884124756,  ...,\n",
       "         37.5507049561, 36.5543289185, 32.0922927856],\n",
       "        [15.6296310425, 36.6584472656, 35.2604217529,  ...,\n",
       "         37.1484870911, 36.0008468628, 29.5477771759],\n",
       "        [22.0656757355, 35.1398048401, 35.0557403564,  ...,\n",
       "         35.9205284119, 34.4170265198, 15.6296310425],\n",
       "        ...,\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 19.8496532440],\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 18.3046245575],\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 15.6296310425]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms = torch.from_numpy(spectrograms)\n",
    "spectrograms = spectrograms.to(device)\n",
    "spectrograms[0,0,:,:] #36.8055648804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = model2(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0059469752, -0.0102297068, -0.0369858481, -0.0413380079,\n",
       "        -0.0359258093, -0.0368227400, -0.0326419882, -0.0314023085,\n",
       "        -0.0221088491, -0.0265791081, -0.0238872878, -0.0272487439,\n",
       "        -0.0254285522, -0.0258744024, -0.0237513222, -0.0270480029,\n",
       "        -0.0193257295, -0.0209990256, -0.0188277774, -0.0170827247,\n",
       "        -0.0242496096, -0.0280124061, -0.0205696933, -0.0219697170,\n",
       "        -0.0228655450, -0.0253660195, -0.0217879824, -0.0237421431,\n",
       "        -0.0273988135, -0.0299718417, -0.0305851512, -0.0261827819,\n",
       "        -0.0227456577, -0.0185999684, -0.0277628042, -0.0258902647,\n",
       "        -0.0268729813, -0.0276423581, -0.0333953910, -0.0243354253,\n",
       "        -0.0255109482, -0.0347631983, -0.0294069909, -0.0263698511,\n",
       "        -0.0280011408, -0.0205817483, -0.0239039101, -0.0339091308,\n",
       "        -0.0322487913, -0.0349185579, -0.0409880020, -0.0427820124,\n",
       "        -0.0462918989, -0.0479957722, -0.0471253358, -0.0453363918,\n",
       "        -0.0438458286, -0.0451215245, -0.0424111597, -0.0411241613,\n",
       "        -0.0396528281, -0.0413568802, -0.0469802134, -0.0499314927,\n",
       "        -0.0509527661, -0.0476189367, -0.0516085587, -0.0510338731,\n",
       "        -0.0521153770, -0.0517529808, -0.0524814390, -0.0537201725,\n",
       "        -0.0527259372, -0.0590538941, -0.0524814688, -0.0559558608,\n",
       "        -0.0582814254, -0.0564695187, -0.0587862469, -0.0590403490,\n",
       "        -0.0565140955, -0.0618196540, -0.0564258061, -0.0473044775,\n",
       "        -0.0596514978, -0.0602289401, -0.0565119796, -0.0543296672,\n",
       "        -0.0562030263, -0.0506811552, -0.0626723170, -0.0731078684,\n",
       "        -0.0688590854, -0.0659346879, -0.0659694523, -0.0674966574,\n",
       "        -0.0519302599, -0.0625016391, -0.0572095327, -0.0598167218,\n",
       "        -0.0643082559, -0.0666946620, -0.0640176386, -0.0621907078,\n",
       "        -0.0635809451, -0.0631462485, -0.0700018108, -0.0761525631,\n",
       "        -0.0711284429, -0.0719658583, -0.0627637804, -0.0609409325,\n",
       "        -0.0660687983, -0.0603622533, -0.0597296245, -0.0491867475,\n",
       "        -0.0579329394, -0.0538860373, -0.0495337211, -0.0423052721,\n",
       "        -0.0464404039, -0.0415222682, -0.0476210527, -0.0452839546,\n",
       "        -0.0499376468, -0.0443281941, -0.0468933024, -0.0492076986,\n",
       "        -0.0434852652, -0.0479022674, -0.0433263890, -0.0306700133,\n",
       "        -0.0345584936, -0.0373211615, -0.0342386030, -0.0392281525,\n",
       "        -0.0393782593, -0.0359267108, -0.0329225250, -0.0371737219,\n",
       "        -0.0398523696, -0.0292166136, -0.0329763256, -0.0372353382,\n",
       "        -0.0246807151, -0.0295980684, -0.0335216634, -0.0362731330,\n",
       "        -0.0357457958, -0.0398839079, -0.0294942223, -0.0351192169,\n",
       "        -0.0357702784, -0.0246284269, -0.0341422223, -0.0338926949,\n",
       "        -0.0238450430, -0.0246633105, -0.0350286998, -0.0357010476,\n",
       "        -0.0339251496, -0.0382324867, -0.0379143395, -0.0409652106,\n",
       "        -0.0486397110, -0.0406997092, -0.0362813435, -0.0380316786,\n",
       "        -0.0415018536, -0.0363433398, -0.0354975872, -0.0396464728,\n",
       "        -0.0416641869, -0.0340431593, -0.0404949747, -0.0292541794,\n",
       "        -0.0267237909, -0.0202910714, -0.0220626704, -0.0129798874,\n",
       "         0.0529281832], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2[0,:] #0.0059469901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "probs = m(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5014867187, 0.4974426329, 0.4907546043, 0.4896669686, 0.4910195172,\n",
       "        0.4907953739, 0.4918402433, 0.4921500385, 0.4944730103, 0.4933556020,\n",
       "        0.4940285087, 0.4931882322, 0.4936432540, 0.4935317338, 0.4940624237,\n",
       "        0.4932383895, 0.4951687455, 0.4947504103, 0.4952931702, 0.4957293868,\n",
       "        0.4939378500, 0.4929973483, 0.4948577583, 0.4945077598, 0.4942838550,\n",
       "        0.4936588109, 0.4945532382, 0.4940646887, 0.4931507111, 0.4925076067,\n",
       "        0.4923542738, 0.4934546649, 0.4943138063, 0.4953501523, 0.4930596948,\n",
       "        0.4935277700, 0.4932821393, 0.4930898249, 0.4916518927, 0.4939164519,\n",
       "        0.4936226308, 0.4913100302, 0.4926487505, 0.4934079349, 0.4930001795,\n",
       "        0.4948547781, 0.4940243065, 0.4915235341, 0.4919385016, 0.4912712574,\n",
       "        0.4897544384, 0.4893061519, 0.4884291291, 0.4880033731, 0.4882208109,\n",
       "        0.4886678457, 0.4890402853, 0.4887215495, 0.4893987477, 0.4897204041,\n",
       "        0.4900880754, 0.4896622598, 0.4882570803, 0.4875197411, 0.4872645438,\n",
       "        0.4880975187, 0.4871007204, 0.4872442782, 0.4869740903, 0.4870646298,\n",
       "        0.4868826270, 0.4865731597, 0.4868215322, 0.4852407873, 0.4868826270,\n",
       "        0.4860146940, 0.4854337573, 0.4858863354, 0.4853076637, 0.4852441549,\n",
       "        0.4858751893, 0.4845499992, 0.4858972430, 0.4881760776, 0.4850915074,\n",
       "        0.4849473238, 0.4858757555, 0.4864209294, 0.4859529436, 0.4873324335,\n",
       "        0.4843370318, 0.4817311466, 0.4827920198, 0.4835222960, 0.4835136533,\n",
       "        0.4831322432, 0.4870203435, 0.4843796492, 0.4857015014, 0.4850502312,\n",
       "        0.4839284718, 0.4833325148, 0.4840010703, 0.4844573140, 0.4841101170,\n",
       "        0.4842186570, 0.4825066626, 0.4809710383, 0.4822254181, 0.4820162654,\n",
       "        0.4843141735, 0.4847694635, 0.4834887981, 0.4849140048, 0.4850719869,\n",
       "        0.4877057970, 0.4855208099, 0.4865317345, 0.4876191020, 0.4894252717,\n",
       "        0.4883919954, 0.4896209538, 0.4880969524, 0.4886809289, 0.4875181615,\n",
       "        0.4889197946, 0.4882787764, 0.4877005816, 0.4891304076, 0.4880267680,\n",
       "        0.4891701043, 0.4923331141, 0.4913612604, 0.4906708002, 0.4914411902,\n",
       "        0.4901942015, 0.4901566803, 0.4910193086, 0.4917700589, 0.4907076359,\n",
       "        0.4900382459, 0.4926963747, 0.4917567074, 0.4906922579, 0.4938301742,\n",
       "        0.4926010668, 0.4916203916, 0.4909326732, 0.4910645485, 0.4900303483,\n",
       "        0.4926269948, 0.4912210703, 0.4910583794, 0.4938431978, 0.4914652407,\n",
       "        0.4915276766, 0.4940389693, 0.4938344657, 0.4912437499, 0.4910756946,\n",
       "        0.4915195107, 0.4904430211, 0.4905225039, 0.4897601604, 0.4878425002,\n",
       "        0.4898265004, 0.4909306169, 0.4904932678, 0.4896260202, 0.4909151495,\n",
       "        0.4911265373, 0.4900896549, 0.4895854592, 0.4914900064, 0.4898776412,\n",
       "        0.4926869273, 0.4933195114, 0.4949274063, 0.4944845438, 0.4967550933,\n",
       "        0.5132289529], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0,:] #0.5033283234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(probs.shape) == 1:\n",
    "    probs.unsqueeze_(0)\n",
    "    outputs2.unsqueeze_(0)\n",
    "\n",
    "y_true  = torch.max(labels, dim =1)[0]\n",
    "y_pred  = torch.max(probs, dim=1)[0]\n",
    "\n",
    "if cont == 1:\n",
    "    Y_true = y_true\n",
    "    Y_pred= y_pred\n",
    "\n",
    "else:                \n",
    "    Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "    Y_pred = torch.cat((Y_pred, y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs2, labels)\n",
    "valid_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6773409259, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del eeg, loss\n",
    "torch.cuda.empty_cache()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_aucpr = average_precision_score(Y_true.to('cpu').detach().numpy(), Y_pred.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6773409258907889), np.float64(0.2969577889118119))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(valid_losses), valid_aucpr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_thalamus)",
   "language": "python",
   "name": "env_thalamus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
