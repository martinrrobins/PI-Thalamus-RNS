{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibilidad de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import torchaudio.transforms    as T\n",
    "import torch.optim              as optim\n",
    "import pandas                   as pd\n",
    "import numpy                    as np\n",
    "\n",
    "from torchvision       import transforms\n",
    "from torch.utils.data  import DataLoader\n",
    "from torch             import nn\n",
    "from sklearn.metrics   import balanced_accuracy_score, recall_score, precision_score, mean_absolute_error, average_precision_score\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','05-Train-Test')))\n",
    "from utilit_train_test import make_weights_for_balanced_classes\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\n",
    "from Generator         import SeizureDatasetLabelTimev2, permute_spec, smoothing_label\n",
    "from Model             import iESPnet\n",
    "from TrainEval         import train_model_v2, test_model_v2, get_performance_indices\n",
    "from IO                import get_spectrogram_2\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\n",
    "from models            import DynamicSpatialFilter\n",
    "\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "# set the seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direccion donde se encuentran los espectrogramas \n",
    "SPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\n",
    "meta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\n",
    "\n",
    "df_meta        = pd.read_csv(meta_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables iESPnet\n",
    "FREQ_MASK_PARAM    = 10\n",
    "TIME_MASK_PARAN    = 20\n",
    "N_CLASSES          = 1\n",
    "learning_rate      = 1e-3\n",
    "batch_size         = 64    #128\n",
    "epochs             = 20\n",
    "num_workers        = 4\n",
    "\n",
    "save_path          = 'models_DSF_iESPnet_prueba/'\n",
    "patients           = df_meta['rns_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables DSF\n",
    "denoising          = 'autoreject'   # 'autoreject' 'data_augm' \n",
    "model              = 'stager_net'\n",
    "dsf_type           = 'dsfd'         # 'dsfd' 'dsfm_st'\n",
    "mlp_input          = 'log_diag_cov'\n",
    "dsf_soft_thresh    = False\n",
    "dsf_n_out_channels = None\n",
    "n_channels         = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros iESPnet\n",
    "hparams = {\n",
    "           \"n_cnn_layers\" : 3,\n",
    "           \"n_rnn_layers\" : 3,\n",
    "           \"rnn_dim\"      : [150, 100, 50],\n",
    "           \"n_class\"      : N_CLASSES,\n",
    "           \"out_ch\"       : [8,8,16],\n",
    "           \"dropout\"      : 0.3,\n",
    "           \"learning_rate\": learning_rate,\n",
    "           \"batch_size\"   : batch_size,\n",
    "           \"num_workers\"  : num_workers,\n",
    "           \"epochs\"       : epochs\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train y test de df_meta\n",
    "test_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\n",
    "vali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_meta.copy() # hace falta resetear el indice de train_df?\n",
    "test_df  = pd.DataFrame()\n",
    "vali_df  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range (len(test_id)):\n",
    "    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\n",
    "\n",
    "for s in range(len(vali_id)):\n",
    "    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\n",
    "    vali_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimentos que se van a realizar\n",
    "experiments_1 = ['exp1','exp2','exp3']\n",
    "experiments_2 = ['.1','.2','.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DynamicSpatialFilter(\n",
    "                              n_channels, \n",
    "                              mlp_input            = mlp_input, \n",
    "                              n_out_channels       = dsf_n_out_channels, \n",
    "                              apply_soft_thresh    = dsf_soft_thresh\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = iESPnet(\n",
    "                 hparams['n_cnn_layers'],\n",
    "                 hparams['n_rnn_layers'],\n",
    "                 hparams['rnn_dim'],\n",
    "                 hparams['n_class'],\n",
    "                 hparams['out_ch'],\n",
    "                 hparams['dropout'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/runs/'\n",
    "save_models      = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/models/'\n",
    "save_predictions = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/results/'\n",
    "save_figs        = save_path + experiments_1[s] + '/' + str(experiments_1[s]) + str(experiments_2[j]) + '/figs/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "if not os.path.exists(save_runs):\n",
    "    os.makedirs(save_runs)\n",
    "\n",
    "if not os.path.exists(save_models):\n",
    "    os.makedirs(save_models)\n",
    "\n",
    "if not os.path.exists(save_predictions):\n",
    "    os.makedirs(save_predictions)\n",
    "\n",
    "if not os.path.exists(save_figs):\n",
    "    os.makedirs(save_figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for: exp1.1\n"
     ]
    }
   ],
   "source": [
    "print('Running training for: ' + experiments_1[s] +  experiments_2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders creados\n",
    "train_data = SeizureDatasetLabelTimev2(\n",
    "                                       file             = train_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None, \n",
    "                                       target_transform = smoothing_label(),\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data should be balanced, just be \"as it is\"\n",
    "test_data  = SeizureDatasetLabelTimev2(\n",
    "                                       file             = test_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None,\n",
    "                                       target_transform = smoothing_label()  \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data should be balanced, just be \"as it is\"\n",
    "vali_data  = SeizureDatasetLabelTimev2(\n",
    "                                       file             = vali_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None,\n",
    "                                       target_transform = smoothing_label()  \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation \n",
    "transform_train = transforms.Compose([\n",
    "                                      T.FrequencyMasking(FREQ_MASK_PARAM),\n",
    "                                      T.TimeMasking(TIME_MASK_PARAN), \n",
    "                                      permute_spec()                                                                     \n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = make_weights_for_balanced_classes(train_df, [0,1], n_concat=1)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = save_models + 'model_' + str(experiments_1[s] + experiments_2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\navg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\\n                                                                            model1, \\n                                                                            model2, \\n                                                                            hparams, \\n                                                                            epochs, \\n                                                                            train_data, \\n                                                                            vali_data, \\n                                                                            transform_train, \\n                                                                            sampler, \\n                                                                            outputfile,\\n                                                                            experiments_1[s],\\n                                                                            experiments_2[j]\\n                                                                           )\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "avg_train_losses, train_accs, avg_valid_losses, valid_accs = train_model_v2(\n",
    "                                                                            model1, \n",
    "                                                                            model2, \n",
    "                                                                            hparams, \n",
    "                                                                            epochs, \n",
    "                                                                            train_data, \n",
    "                                                                            vali_data, \n",
    "                                                                            transform_train, \n",
    "                                                                            sampler, \n",
    "                                                                            outputfile,\n",
    "                                                                            experiments_1[s],\n",
    "                                                                            experiments_2[j]\n",
    "                                                                           )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_losses = []\n",
    "train_accs       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_valid_losses = [] \n",
    "valid_accs       = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following pytorch suggestion to speed up training\n",
    "torch.backends.cudnn.benchmark     = False # cambio para reproducibilidad\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': hparams[\"num_workers\"], 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = hparams[\"batch_size\"], sampler = sampler, **kwargs)\n",
    "valid_loader = DataLoader(vali_data, batch_size = hparams[\"batch_size\"], shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model1 to device\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move model2 to device\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 120\n",
      "Num Model Parameters 1654837\n"
     ]
    }
   ],
   "source": [
    "print('Num Model Parameters', sum([param1.nelement() for param1 in model1.parameters()]))\n",
    "print('Num Model Parameters', sum([param2.nelement() for param2 in model2.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.AdamW(model1.parameters(), hparams['learning_rate'], weight_decay=1e-4)\n",
    "optimizer2 = optim.AdamW(model2.parameters(), hparams['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "scheduler1 = optim.lr_scheduler.OneCycleLR(\n",
    "                                           optimizer1, \n",
    "                                           max_lr          = hparams['learning_rate'], \n",
    "                                           steps_per_epoch = int(len(train_loader)),\n",
    "                                           epochs          = hparams['epochs'],\n",
    "                                           anneal_strategy = 'linear'\n",
    "                                          )\n",
    "\n",
    "scheduler2 = optim.lr_scheduler.OneCycleLR(\n",
    "                                           optimizer2, \n",
    "                                           max_lr          = hparams['learning_rate'], \n",
    "                                           steps_per_epoch = int(len(train_loader)*2),\n",
    "                                           epochs          = hparams['epochs'],\n",
    "                                           anneal_strategy = 'linear'\n",
    "                                          )\n",
    "      \n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntrain_losses, train_aucpr = training_DSF_iESPnet(\\n                                                 model1, \\n                                                 model2, \\n                                                 device, \\n                                                 train_loader, \\n                                                 transform_train, \\n                                                 criterion, \\n                                                 optimizer1, \\n                                                 optimizer2, \\n                                                 scheduler1, \\n                                                 scheduler2, \\n                                                 epoch,\\n                                                 experiment_1,\\n                                                 experiment_2\\n                                                )\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "train_losses, train_aucpr = training_DSF_iESPnet(\n",
    "                                                 model1, \n",
    "                                                 model2, \n",
    "                                                 device, \n",
    "                                                 train_loader, \n",
    "                                                 transform_train, \n",
    "                                                 criterion, \n",
    "                                                 optimizer1, \n",
    "                                                 optimizer2, \n",
    "                                                 scheduler1, \n",
    "                                                 scheduler2, \n",
    "                                                 epoch,\n",
    "                                                 experiment_1,\n",
    "                                                 experiment_2\n",
    "                                                )\n",
    "\n",
    "'''                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1 = experiments_1[s]\n",
    "experiment_2 = experiments_2[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spectrogram\n",
    "ECOG_SAMPLE_RATE = 250\n",
    "ECOG_CHANNELS    = 4\n",
    "TT               = 1000 # window length\n",
    "SPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) # win size\n",
    "overlap          = 500 \n",
    "SPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) # Length of hop between windows.\n",
    "SPEC_NFFT        = 500  # to see changes in 0.5 reso\n",
    "if   experiment_2 == '.1':  \n",
    "    top_db       = 40.0\n",
    "elif experiment_2 == '.2':\n",
    "    top_db       = 60.0\n",
    "elif experiment_2 == '.3':\n",
    "    top_db       = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss   = 0.0\n",
    "train_losses = []\n",
    "cont         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 502.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs2, labels2train)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Perform backward pass\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Perform optimization\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/environments/env_thalamus/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 502.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "for batch_idx, _data in enumerate(train_loader):\n",
    "    #if batch_idx == 1:  # Saltar la primera iteración\n",
    "        #continue\n",
    "\n",
    "    cont+=1\n",
    "    eeg, labels = _data \n",
    "    eeg, labels = eeg.to(device), labels.to(device)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer1.zero_grad(set_to_none=True)\n",
    "    optimizer2.zero_grad(set_to_none=True)\n",
    "\n",
    "    # Perform forward pass to DSF\n",
    "    outputs1 = model1(eeg)  # (batch, n_class)\n",
    "    outputs1 = outputs1.squeeze(1)\n",
    "    outputs1 = outputs1.to('cpu')\n",
    "\n",
    "    # create spectrogram from outputs1\n",
    "    spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)\n",
    "    spectrograms = torch.from_numpy(spectrograms)\n",
    "    \n",
    "    spectrograms_transformed = transform_train(spectrograms)\n",
    "\n",
    "    spectrograms2train       = torch.cat((spectrograms, spectrograms_transformed), axis=0)\n",
    "    spectrograms2train       = spectrograms2train.to(device)\n",
    "\n",
    "    labels2train = torch.cat((labels, labels), axis=0)\n",
    "\n",
    "    outputs2 = model2(spectrograms2train)\n",
    "\n",
    "    m     = nn.Sigmoid()\n",
    "    probs = m(outputs2)\n",
    "    \n",
    "    y_true  = torch.max(labels2train, dim = 1)[0]\n",
    "    y_pred  = torch.max(probs, dim = 1)[0]\n",
    "    \n",
    "    if cont == 1:\n",
    "        Y_true = y_true\n",
    "        Y_pred = y_pred\n",
    "    else:                \n",
    "        Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "        Y_pred = torch.cat((Y_pred, y_pred), axis=0)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs2, labels2train)\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    # Perform optimization\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "    \n",
    "    # record training loss\n",
    "    train_losses.append(loss.item())\n",
    "    del _data\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for batch_idx, _data in enumerate(train_loader):\\n    cont+=1\\n    eeg, labels = _data \\n    eeg, labels = eeg.to(device), labels.to(device)\\n    break'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for batch_idx, _data in enumerate(train_loader):\n",
    "    cont+=1\n",
    "    eeg, labels = _data \n",
    "    eeg, labels = eeg.to(device), labels.to(device)\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Zero the gradients\\noptimizer1.zero_grad(set_to_none=True)\\noptimizer2.zero_grad(set_to_none=True)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Zero the gradients\n",
    "optimizer1.zero_grad(set_to_none=True)\n",
    "optimizer2.zero_grad(set_to_none=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizando la semilla random.seed el data loader siempre decide por el mismo batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eeg[0,0,:]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''eeg[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Perform forward pass to DSF\\noutputs1 = model1(eeg)  # (batch, n_class)\\noutputs1 = outputs1.squeeze(1)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Perform forward pass to DSF\n",
    "outputs1 = model1(eeg)  # (batch, n_class)\n",
    "outputs1 = outputs1.squeeze(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs1[0,0,:]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if   experiment_1 == 'exp1': # sin normalizacion \\n    pass\\nelif experiment_1 == 'exp2': # normalizacion por canal\\n    mean     = outputs1.mean(dim=2, keepdim=True)\\n    std      = outputs1.std(dim=2, keepdim=True)\\n\\n    outputs1 = (outputs1 - mean) / std\\n\\nelif experiment_1 == 'exp3': # normalizacion global\\n    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if   experiment_1 == 'exp1': # sin normalizacion \n",
    "    pass\n",
    "elif experiment_1 == 'exp2': # normalizacion por canal\n",
    "    mean     = outputs1.mean(dim=2, keepdim=True)\n",
    "    std      = outputs1.std(dim=2, keepdim=True)\n",
    "\n",
    "    outputs1 = (outputs1 - mean) / std\n",
    "\n",
    "elif experiment_1 == 'exp3': # normalizacion global\n",
    "    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"outputs1 = outputs1.to('cpu')\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1 = outputs1.to('cpu')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs1[0,0,:]'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs1[0,0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create spectrogram from outputs1\\nspectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# create spectrogram from outputs1\n",
    "spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms[0,0,:,:]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms = torch.from_numpy(spectrograms)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms = torch.from_numpy(spectrograms)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms[0,0,:,:]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms_transformed = transform_train(spectrograms)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms_transformed = transform_train(spectrograms)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms_transformed[0,0,:,:]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms_transformed[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train = torch.cat((spectrograms, spectrograms_transformed), axis=0)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train = torch.cat((spectrograms, spectrograms_transformed), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train[0,0,:,:]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train = spectrograms2train.to(device)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train = spectrograms2train.to(device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spectrograms2train[0,0,:,:]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spectrograms2train[0,0,:,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels2train = torch.cat((labels, labels), axis=0)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''labels2train = torch.cat((labels, labels), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs2 = model2(spectrograms2train)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs2 = model2(spectrograms2train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs2[0,:]  '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''outputs2[0,:]  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m     = nn.Sigmoid()\\nprobs = m(outputs2)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''m     = nn.Sigmoid()\n",
    "probs = m(outputs2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probs[0,:]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''probs[0,:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_true  = torch.max(labels2train, dim = 1)[0]\\ny_pred  = torch.max(probs, dim = 1)[0]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_true  = torch.max(labels2train, dim = 1)[0]\n",
    "y_pred  = torch.max(probs, dim = 1)[0]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if cont == 1:\\n    Y_true = y_true\\n    Y_pred = y_pred\\n\\nelse:                \\n    Y_true = torch.cat((Y_true, y_true), axis=0)\\n    Y_pred = torch.cat((Y_pred, y_pred), axis=0)'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if cont == 1:\n",
    "    Y_true = y_true\n",
    "    Y_pred = y_pred\n",
    "\n",
    "else:                \n",
    "    Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "    Y_pred = torch.cat((Y_pred, y_pred), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_true'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_true'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_pred '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_pred '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss = criterion(outputs2, labels2train)'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss = criterion(outputs2, labels2train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss.backward()\\ntrain_loss += loss.item()'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss.backward()\n",
    "train_loss += loss.item()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Perform optimization\\noptimizer1.step()\\noptimizer2.step()\\nscheduler1.step()\\nscheduler2.step()'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Perform optimization\n",
    "optimizer1.step()\n",
    "optimizer2.step()\n",
    "scheduler1.step()\n",
    "scheduler2.step()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# record training loss\\ntrain_losses.append(loss.item())'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# record training loss\n",
    "train_losses.append(loss.item())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'del _data\\ntorch.cuda.empty_cache()'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''del _data\n",
    "torch.cuda.empty_cache()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true, val_pred = Y_true.to('cpu').detach().numpy(), Y_pred.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55797106, 0.54620266, 0.5524    , 0.5542989 , 0.5525311 ,\n",
       "       0.56108165, 0.5778388 , 0.55276626, 0.5605448 , 0.55055296,\n",
       "       0.545822  , 0.5618415 , 0.55384964, 0.5609321 , 0.5619036 ,\n",
       "       0.5702581 , 0.57056797, 0.56290585, 0.5540417 , 0.56938565,\n",
       "       0.57902074, 0.5796253 , 0.55720246, 0.5537558 , 0.55639726,\n",
       "       0.5757947 , 0.5582665 , 0.5702161 , 0.5476137 , 0.5592189 ,\n",
       "       0.5790522 , 0.5578448 , 0.5698016 , 0.55972767, 0.5554231 ,\n",
       "       0.5547875 , 0.5514725 , 0.55154866, 0.55223924, 0.56443137,\n",
       "       0.56661147, 0.5795406 , 0.5634781 , 0.57123744, 0.5551256 ,\n",
       "       0.57297796, 0.57063806, 0.56352264, 0.56227785, 0.5587263 ,\n",
       "       0.5673289 , 0.56358534, 0.56178737, 0.5587469 , 0.5516604 ,\n",
       "       0.5812343 , 0.55771023, 0.5524937 , 0.54951924, 0.5840419 ,\n",
       "       0.56415915, 0.5678297 , 0.55195683, 0.5747315 , 0.5710066 ,\n",
       "       0.5563779 , 0.55663514, 0.5959412 , 0.56611717, 0.55511135,\n",
       "       0.57873577, 0.5805522 , 0.5724227 , 0.550469  , 0.55015546,\n",
       "       0.5684056 , 0.56599617, 0.5634248 , 0.5658929 , 0.56047237,\n",
       "       0.56165236, 0.5605375 , 0.5733414 , 0.5776575 , 0.56900704,\n",
       "       0.5700605 , 0.5570258 , 0.5665062 , 0.5647127 , 0.5686367 ,\n",
       "       0.58290434, 0.5804344 , 0.5628821 , 0.56104237, 0.5641255 ,\n",
       "       0.5754164 , 0.5571722 , 0.5700968 , 0.55963653, 0.5759203 ,\n",
       "       0.5673605 , 0.5654971 , 0.5768842 , 0.5793126 , 0.5495667 ,\n",
       "       0.57010376, 0.5542776 , 0.5735549 , 0.57329315, 0.5662926 ,\n",
       "       0.56749743, 0.5497423 , 0.5464011 , 0.5500061 , 0.5754761 ,\n",
       "       0.5677797 , 0.5726142 , 0.5821877 , 0.56391454, 0.5702215 ,\n",
       "       0.5654196 , 0.55777794, 0.5555735 , 0.55169976, 0.5796991 ,\n",
       "       0.55910516, 0.56916064, 0.5764452 ], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.693660666420691)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aucpr = average_precision_score(y_val_true,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7191555105653817)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aucpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nvalid_losses, valid_aucpr = validate_v2(\\n                                        model1,\\n                                        model2,\\n                                        device, \\n                                        valid_loader, \\n                                        criterion, \\n                                        epoch,\\n                                        experiment_1,\\n                                        experiment_2\\n                                       )\\n\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "valid_losses, valid_aucpr = validate_v2(\n",
    "                                        model1,\n",
    "                                        model2,\n",
    "                                        device, \n",
    "                                        valid_loader, \n",
    "                                        criterion, \n",
    "                                        epoch,\n",
    "                                        experiment_1,\n",
    "                                        experiment_2\n",
    "                                       )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECOG_SAMPLE_RATE = 250\n",
    "ECOG_CHANNELS    = 4\n",
    "TT               = 1000 \n",
    "SPEC_WIN_LEN     = int(ECOG_SAMPLE_RATE * TT / 1000 ) \n",
    "overlap          = 500 \n",
    "SPEC_HOP_LEN     = int(ECOG_SAMPLE_RATE * (TT - overlap) / 1000) \n",
    "SPEC_NFFT        = 500\n",
    "if   experiment_2 == '.1':  \n",
    "    top_db       = 40.0\n",
    "elif experiment_2 == '.2':\n",
    "    top_db       = 60.0\n",
    "elif experiment_2 == '.3':\n",
    "    top_db       = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_losses = []\n",
    "cont         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSpatialFilter(\n",
       "  (feat_extractor): SpatialFeatureExtractor()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iESPnet(\n",
       "  (freqcnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(120, 1), stride=(1, 1), padding=(119, 0), dilation=(2, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (timecnn): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(1, 181), stride=(1, 1), padding=(0, 180), dilation=(1, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): InstanceNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cnn_ori): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (cnn): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "  (rescnn_layers): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (rescnn_layers_ori): Sequential(\n",
       "    (0): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualCNNbatch(\n",
       "      (cnn1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (cnn2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dropout1): Dropout(p=0.3, inplace=False)\n",
       "      (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(40, 181))\n",
       "  (rnn_layers): Sequential(\n",
       "    (0): BidirectionalGRU(\n",
       "      (BiGRU): GRU(1280, 150, batch_first=True, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): BidirectionalGRU(\n",
       "      (BiGRU): GRU(300, 100, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (2): BidirectionalGRU(\n",
       "      (BiGRU): GRU(200, 50, bidirectional=True)\n",
       "      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for eeg, labels in valid_loader:\n",
    "        cont+=1\n",
    "    \n",
    "        eeg, labels = eeg.to(device), labels.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2740582228, 1.8588944674, 2.5337054729,  ..., 1.3190456629,\n",
       "        1.0941085815, 0.6892219782], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1    = model1(eeg)\n",
    "outputs1    = outputs1.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1259495020, -0.0817473531, -0.3597738743,  ...,\n",
       "        -0.1269418001, -0.3000434637, -0.1780759096], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if   experiment_1 == 'exp1': # sin normalizacion \n",
    "    pass\n",
    "elif experiment_1 == 'exp2': # normalizacion por canal\n",
    "    mean     = outputs1.mean(dim=2, keepdim=True)\n",
    "    std      = outputs1.std(dim=2, keepdim=True)\n",
    "\n",
    "    outputs1 = (outputs1 - mean) / std\n",
    "\n",
    "elif experiment_1 == 'exp3': # normalizacion global\n",
    "    outputs1 = (outputs1 - outputs1.mean()) / outputs1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = outputs1.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1259495020, -0.0817473531, -0.3597738743,  ...,\n",
       "        -0.1269418001, -0.3000434637, -0.1780759096], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = get_spectrogram_2(outputs1, device, ECOG_SAMPLE_RATE, SPEC_NFFT, SPEC_WIN_LEN, SPEC_HOP_LEN, top_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.629631, 37.139008, 35.388412, ..., 37.550705, 36.55433 ,\n",
       "        32.092293],\n",
       "       [15.629631, 36.658447, 35.26042 , ..., 37.148487, 36.000847,\n",
       "        29.547777],\n",
       "       [22.065676, 35.139805, 35.05574 , ..., 35.92053 , 34.417027,\n",
       "        15.629631],\n",
       "       ...,\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        19.849653],\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        18.304625],\n",
       "       [15.629631, 15.629631, 15.629631, ..., 15.629631, 15.629631,\n",
       "        15.629631]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.6296310425, 37.1390075684, 35.3884124756,  ...,\n",
       "         37.5507049561, 36.5543289185, 32.0922927856],\n",
       "        [15.6296310425, 36.6584472656, 35.2604217529,  ...,\n",
       "         37.1484870911, 36.0008468628, 29.5477771759],\n",
       "        [22.0656757355, 35.1398048401, 35.0557403564,  ...,\n",
       "         35.9205284119, 34.4170265198, 15.6296310425],\n",
       "        ...,\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 19.8496532440],\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 18.3046245575],\n",
       "        [15.6296310425, 15.6296310425, 15.6296310425,  ...,\n",
       "         15.6296310425, 15.6296310425, 15.6296310425]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms = torch.from_numpy(spectrograms)\n",
    "spectrograms = spectrograms.to(device)\n",
    "spectrograms[0,0,:,:] #36.8055648804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = model2(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0059469752, -0.0102297068, -0.0369858481, -0.0413380079,\n",
       "        -0.0359258093, -0.0368227400, -0.0326419882, -0.0314023085,\n",
       "        -0.0221088491, -0.0265791081, -0.0238872878, -0.0272487439,\n",
       "        -0.0254285522, -0.0258744024, -0.0237513222, -0.0270480029,\n",
       "        -0.0193257295, -0.0209990256, -0.0188277774, -0.0170827247,\n",
       "        -0.0242496096, -0.0280124061, -0.0205696933, -0.0219697170,\n",
       "        -0.0228655450, -0.0253660195, -0.0217879824, -0.0237421431,\n",
       "        -0.0273988135, -0.0299718417, -0.0305851512, -0.0261827819,\n",
       "        -0.0227456577, -0.0185999684, -0.0277628042, -0.0258902647,\n",
       "        -0.0268729813, -0.0276423581, -0.0333953910, -0.0243354253,\n",
       "        -0.0255109482, -0.0347631983, -0.0294069909, -0.0263698511,\n",
       "        -0.0280011408, -0.0205817483, -0.0239039101, -0.0339091308,\n",
       "        -0.0322487913, -0.0349185579, -0.0409880020, -0.0427820124,\n",
       "        -0.0462918989, -0.0479957722, -0.0471253358, -0.0453363918,\n",
       "        -0.0438458286, -0.0451215245, -0.0424111597, -0.0411241613,\n",
       "        -0.0396528281, -0.0413568802, -0.0469802134, -0.0499314927,\n",
       "        -0.0509527661, -0.0476189367, -0.0516085587, -0.0510338731,\n",
       "        -0.0521153770, -0.0517529808, -0.0524814390, -0.0537201725,\n",
       "        -0.0527259372, -0.0590538941, -0.0524814688, -0.0559558608,\n",
       "        -0.0582814254, -0.0564695187, -0.0587862469, -0.0590403490,\n",
       "        -0.0565140955, -0.0618196540, -0.0564258061, -0.0473044775,\n",
       "        -0.0596514978, -0.0602289401, -0.0565119796, -0.0543296672,\n",
       "        -0.0562030263, -0.0506811552, -0.0626723170, -0.0731078684,\n",
       "        -0.0688590854, -0.0659346879, -0.0659694523, -0.0674966574,\n",
       "        -0.0519302599, -0.0625016391, -0.0572095327, -0.0598167218,\n",
       "        -0.0643082559, -0.0666946620, -0.0640176386, -0.0621907078,\n",
       "        -0.0635809451, -0.0631462485, -0.0700018108, -0.0761525631,\n",
       "        -0.0711284429, -0.0719658583, -0.0627637804, -0.0609409325,\n",
       "        -0.0660687983, -0.0603622533, -0.0597296245, -0.0491867475,\n",
       "        -0.0579329394, -0.0538860373, -0.0495337211, -0.0423052721,\n",
       "        -0.0464404039, -0.0415222682, -0.0476210527, -0.0452839546,\n",
       "        -0.0499376468, -0.0443281941, -0.0468933024, -0.0492076986,\n",
       "        -0.0434852652, -0.0479022674, -0.0433263890, -0.0306700133,\n",
       "        -0.0345584936, -0.0373211615, -0.0342386030, -0.0392281525,\n",
       "        -0.0393782593, -0.0359267108, -0.0329225250, -0.0371737219,\n",
       "        -0.0398523696, -0.0292166136, -0.0329763256, -0.0372353382,\n",
       "        -0.0246807151, -0.0295980684, -0.0335216634, -0.0362731330,\n",
       "        -0.0357457958, -0.0398839079, -0.0294942223, -0.0351192169,\n",
       "        -0.0357702784, -0.0246284269, -0.0341422223, -0.0338926949,\n",
       "        -0.0238450430, -0.0246633105, -0.0350286998, -0.0357010476,\n",
       "        -0.0339251496, -0.0382324867, -0.0379143395, -0.0409652106,\n",
       "        -0.0486397110, -0.0406997092, -0.0362813435, -0.0380316786,\n",
       "        -0.0415018536, -0.0363433398, -0.0354975872, -0.0396464728,\n",
       "        -0.0416641869, -0.0340431593, -0.0404949747, -0.0292541794,\n",
       "        -0.0267237909, -0.0202910714, -0.0220626704, -0.0129798874,\n",
       "         0.0529281832], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2[0,:] #0.0059469901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "probs = m(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5014867187, 0.4974426329, 0.4907546043, 0.4896669686, 0.4910195172,\n",
       "        0.4907953739, 0.4918402433, 0.4921500385, 0.4944730103, 0.4933556020,\n",
       "        0.4940285087, 0.4931882322, 0.4936432540, 0.4935317338, 0.4940624237,\n",
       "        0.4932383895, 0.4951687455, 0.4947504103, 0.4952931702, 0.4957293868,\n",
       "        0.4939378500, 0.4929973483, 0.4948577583, 0.4945077598, 0.4942838550,\n",
       "        0.4936588109, 0.4945532382, 0.4940646887, 0.4931507111, 0.4925076067,\n",
       "        0.4923542738, 0.4934546649, 0.4943138063, 0.4953501523, 0.4930596948,\n",
       "        0.4935277700, 0.4932821393, 0.4930898249, 0.4916518927, 0.4939164519,\n",
       "        0.4936226308, 0.4913100302, 0.4926487505, 0.4934079349, 0.4930001795,\n",
       "        0.4948547781, 0.4940243065, 0.4915235341, 0.4919385016, 0.4912712574,\n",
       "        0.4897544384, 0.4893061519, 0.4884291291, 0.4880033731, 0.4882208109,\n",
       "        0.4886678457, 0.4890402853, 0.4887215495, 0.4893987477, 0.4897204041,\n",
       "        0.4900880754, 0.4896622598, 0.4882570803, 0.4875197411, 0.4872645438,\n",
       "        0.4880975187, 0.4871007204, 0.4872442782, 0.4869740903, 0.4870646298,\n",
       "        0.4868826270, 0.4865731597, 0.4868215322, 0.4852407873, 0.4868826270,\n",
       "        0.4860146940, 0.4854337573, 0.4858863354, 0.4853076637, 0.4852441549,\n",
       "        0.4858751893, 0.4845499992, 0.4858972430, 0.4881760776, 0.4850915074,\n",
       "        0.4849473238, 0.4858757555, 0.4864209294, 0.4859529436, 0.4873324335,\n",
       "        0.4843370318, 0.4817311466, 0.4827920198, 0.4835222960, 0.4835136533,\n",
       "        0.4831322432, 0.4870203435, 0.4843796492, 0.4857015014, 0.4850502312,\n",
       "        0.4839284718, 0.4833325148, 0.4840010703, 0.4844573140, 0.4841101170,\n",
       "        0.4842186570, 0.4825066626, 0.4809710383, 0.4822254181, 0.4820162654,\n",
       "        0.4843141735, 0.4847694635, 0.4834887981, 0.4849140048, 0.4850719869,\n",
       "        0.4877057970, 0.4855208099, 0.4865317345, 0.4876191020, 0.4894252717,\n",
       "        0.4883919954, 0.4896209538, 0.4880969524, 0.4886809289, 0.4875181615,\n",
       "        0.4889197946, 0.4882787764, 0.4877005816, 0.4891304076, 0.4880267680,\n",
       "        0.4891701043, 0.4923331141, 0.4913612604, 0.4906708002, 0.4914411902,\n",
       "        0.4901942015, 0.4901566803, 0.4910193086, 0.4917700589, 0.4907076359,\n",
       "        0.4900382459, 0.4926963747, 0.4917567074, 0.4906922579, 0.4938301742,\n",
       "        0.4926010668, 0.4916203916, 0.4909326732, 0.4910645485, 0.4900303483,\n",
       "        0.4926269948, 0.4912210703, 0.4910583794, 0.4938431978, 0.4914652407,\n",
       "        0.4915276766, 0.4940389693, 0.4938344657, 0.4912437499, 0.4910756946,\n",
       "        0.4915195107, 0.4904430211, 0.4905225039, 0.4897601604, 0.4878425002,\n",
       "        0.4898265004, 0.4909306169, 0.4904932678, 0.4896260202, 0.4909151495,\n",
       "        0.4911265373, 0.4900896549, 0.4895854592, 0.4914900064, 0.4898776412,\n",
       "        0.4926869273, 0.4933195114, 0.4949274063, 0.4944845438, 0.4967550933,\n",
       "        0.5132289529], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0,:] #0.5033283234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(probs.shape) == 1:\n",
    "    probs.unsqueeze_(0)\n",
    "    outputs2.unsqueeze_(0)\n",
    "\n",
    "y_true  = torch.max(labels, dim =1)[0]\n",
    "y_pred  = torch.max(probs, dim=1)[0]\n",
    "\n",
    "if cont == 1:\n",
    "    Y_true = y_true\n",
    "    Y_pred= y_pred\n",
    "\n",
    "else:                \n",
    "    Y_true = torch.cat((Y_true, y_true), axis=0)\n",
    "    Y_pred = torch.cat((Y_pred, y_pred), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs2, labels)\n",
    "valid_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6773409259, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del eeg, loss\n",
    "torch.cuda.empty_cache()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_aucpr = average_precision_score(Y_true.to('cpu').detach().numpy(), Y_pred.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6773409258907889), np.float64(0.2969577889118119))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(valid_losses), valid_aucpr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_thalamus)",
   "language": "python",
   "name": "env_thalamus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
