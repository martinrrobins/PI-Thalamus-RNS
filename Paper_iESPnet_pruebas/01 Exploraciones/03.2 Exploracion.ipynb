{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrobins/micromamba/envs/env_thalamus/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','iESPnet_SRC_main','utilities')))\n",
    "from Generator import SeizureDatasetLabelTime, scale_spec, permute_spec, smoothing_label\n",
    "from Model import iESPnet\n",
    "from TrainEval import train_model_opt, test_model, train_model, get_thr_output, get_performance_indices\n",
    "from utilit import make_weights_for_balanced_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_file_v1 = '/home/mrobins/Rns_Data/PITT_PI_v1/METADATA_v1/allfiles_metadata.csv'\n",
    "meta_data_file_v2 = '/home/mrobins/Rns_Data/PITT_PI_v2/METADATA_v2/allfiles_metadata.csv'\n",
    "\n",
    "df_meta1 = pd.read_csv(meta_data_file_v1)\n",
    "df_meta2 = pd.read_csv(meta_data_file_v2)\n",
    "\n",
    "df_meta1.drop(df_meta1[df_meta1['label'] == 2].index, inplace = True)\n",
    "df_meta2.drop(df_meta2[df_meta2['label'] == 2].index, inplace = True)\n",
    "\n",
    "df_meta1.drop(df_meta1[df_meta1['rns_id']=='PIT-RNS9793'].index, inplace = True)\n",
    "df_meta2.drop(df_meta2[df_meta2['rns_id']=='PIT-RNS9793'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea el modelo\n",
    "\n",
    "N_CLASSES       = 1\n",
    "learning_rate   = 1e-3\n",
    "batch_size      = 128\n",
    "epochs          = 20\n",
    "num_workers     = 4\n",
    "\n",
    "hparams = {\n",
    "        \"n_cnn_layers\" : 3,\n",
    "        \"n_rnn_layers\" : 3,\n",
    "        \"rnn_dim\"      : [150, 100, 50],\n",
    "        \"n_class\"      : N_CLASSES,\n",
    "        \"out_ch\"       : [8,8,16],\n",
    "        \"dropout\"      : 0.3,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\"   : batch_size,\n",
    "        \"num_workers\"  : num_workers,\n",
    "        \"epochs\"       : epochs\n",
    "        }\n",
    "\n",
    "model = iESPnet(hparams['n_cnn_layers'],\n",
    "                hparams['n_rnn_layers'],\n",
    "                hparams['rnn_dim'],\n",
    "                hparams['n_class'],\n",
    "                hparams['out_ch'],\n",
    "                hparams['dropout'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "\n",
    "patients1         = df_meta1['rns_id'].unique().tolist()\n",
    "save_path1        = 'SAVEPATH_v1/'\n",
    "save_runs1        = save_path1 + patients1[s] + '/runs/'\n",
    "save_models1      = save_path1 + patients1[s] + '/models/'\n",
    "save_predictions1 = save_path1 + patients1[s] + '/results/'\n",
    "save_figs1        = save_path1 + patients1[s] + '/figs/'\n",
    "\n",
    "patients2         = df_meta2['rns_id'].unique().tolist()\n",
    "save_path2        = 'SAVEPATH_v1/'\n",
    "save_runs2        = save_path2 + patients2[s] + '/runs/'\n",
    "save_models2      = save_path2 + patients2[s] + '/models/'\n",
    "save_predictions2 = save_path2 + patients2[s] + '/results/'\n",
    "save_figs2        = save_path2 + patients2[s] + '/figs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = save_models1 + 'model_opt.pth'\n",
    "checkpoint = torch.load(model_path1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model_path2 = save_models2 + 'model_opt.pth'\n",
    "checkpoint = torch.load(model_path2)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PIT-RNS1603'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PIT-RNS1603'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_losses', 'train_acupr', 'prediction_te', 'prediction_tr', 'hparams', 'threshold', 'train_size'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_results1 = save_predictions1 + patients1[s]+ 'results.npy'\n",
    "path_results1\n",
    "\n",
    "path_results2 = save_predictions2 + patients2[s]+ 'results.npy'\n",
    "path_results2\n",
    "\n",
    "results_patient_01 = np.load(path_results1, allow_pickle=True)\n",
    "results_patient_01=results_patient_01.item()\n",
    "results_patient_01.keys()\n",
    "\n",
    "results_patient_02 = np.load(path_results1, allow_pickle=True)\n",
    "results_patient_02=results_patient_02.item()\n",
    "results_patient_02.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_1  = results_patient_01.get(\"train_losses\")\n",
    "train_acupr_1   = results_patient_01.get(\"train_acupr\") \n",
    "prediction_te_1 = results_patient_01.get(\"prediction_te\") \n",
    "prediction_tr_1 = results_patient_01.get(\"prediction_tr\") \n",
    "\n",
    "train_losses_2  = results_patient_02.get(\"train_losses\")\n",
    "train_acupr_2   = results_patient_02.get(\"train_acupr\") \n",
    "prediction_te_2 = results_patient_02.get(\"prediction_te\") \n",
    "prediction_tr_2 = results_patient_02.get(\"prediction_tr\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'f1', 'precision', 'recall', 'y_true', 'y_pred', 't_true', 't_pred', 'l_true', 'l_pred', 'proba', 'MAE_time'])\n",
      "dict_keys(['accuracy', 'f1', 'precision', 'recall', 'y_true', 'y_pred', 't_true', 't_pred', 'l_true', 'l_pred', 'proba', 'MAE_time'])\n"
     ]
    }
   ],
   "source": [
    "print(prediction_te_1.keys())\n",
    "print(prediction_te_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1  = prediction_te_1.get('accuracy')\n",
    "f1_1        = prediction_te_1.get('f1')\n",
    "precision_1 = prediction_te_1.get('precision')\n",
    "recall_1    = prediction_te_1.get('recall')\n",
    "y_true_1    = prediction_te_1.get('y_true')\n",
    "y_pred_1    = prediction_te_1.get('y_pred')\n",
    "t_true_1    = prediction_te_1.get('t_true')\n",
    "t_pred_1    = prediction_te_1.get('t_pred')\n",
    "l_true_1    = prediction_te_1.get('l_true')\n",
    "l_pred_1    = prediction_te_1.get('l_pred')\n",
    "proba_1     = prediction_te_1.get('proba')\n",
    "MAE_time_1  = prediction_te_1.get('MAE_time')\n",
    "\n",
    "accuracy_2  = prediction_te_2.get('accuracy')\n",
    "f1_2        = prediction_te_2.get('f1')\n",
    "precision_2 = prediction_te_2.get('precision')\n",
    "recall_2    = prediction_te_2.get('recall')\n",
    "y_true_2    = prediction_te_2.get('y_true')\n",
    "y_pred_2    = prediction_te_2.get('y_pred')\n",
    "t_true_2    = prediction_te_2.get('t_true')\n",
    "t_pred_2    = prediction_te_2.get('t_pred')\n",
    "l_true_2    = prediction_te_2.get('l_true')\n",
    "l_pred_2    = prediction_te_2.get('l_pred')\n",
    "proba_2     = prediction_te_2.get('proba')\n",
    "MAE_time_2  = prediction_te_2.get('MAE_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "a.append(float(accuracy_1))\n",
    "a.append(float(f1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248713888643484"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tengo que hacer todo este proceso pero para los 31 pacientes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
