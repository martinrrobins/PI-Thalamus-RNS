{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de performance para cada paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torchaudio.transforms as T\n",
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "\n",
    "from torchvision       import transforms\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..','..','iESPnet_SRC_main','utilities')))\n",
    "from Generator         import SeizureDatasetLabelTimev2, smoothing_label\n",
    "from Model             import iESPnet\n",
    "from TrainEval         import test_model_dsf_iespnet_abl_perpatient, get_performance_indices\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..','03 Dynamic-Spatial-Filtering')))\n",
    "from models            import DynamicSpatialFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direccion donde se encuentran los espectrogramas \n",
    "SPE_DIR        = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/'\n",
    "meta_data_file = '/media/martin/Disco2/Rns_Data/PITT_PI_EEG/METADATA/allfiles_metadata.csv'\n",
    "\n",
    "df_meta        = pd.read_csv(meta_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables iESPnet\n",
    "FREQ_MASK_PARAM       = 10\n",
    "TIME_MASK_PARAN       = 20\n",
    "N_CLASSES             = 1\n",
    "learning_rate_iespnet = 1e-3\n",
    "batch_size            = 64    #128\n",
    "epochs                = 20\n",
    "num_workers           = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables DSF\n",
    "denoising             = 'autoreject'   # 'autoreject' 'data_augm' \n",
    "model                 = 'stager_net'\n",
    "dsf_type              = 'dsfd'         # 'dsfd' 'dsfm_st'\n",
    "mlp_input             = 'log_diag_cov'\n",
    "dsf_soft_thresh       = False\n",
    "dsf_n_out_channels    = None\n",
    "n_channels            = 4\n",
    "learning_rate_dsf     = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparametros iESPnet y DSF\n",
    "hparams = {\n",
    "           \"n_cnn_layers\"          : 3,\n",
    "           \"n_rnn_layers\"          : 3,\n",
    "           \"rnn_dim\"               : [150, 100, 50],\n",
    "           \"n_class\"               : N_CLASSES,\n",
    "           \"out_ch\"                : [8,8,16],\n",
    "           \"dropout\"               : 0.3,\n",
    "           \"learning_rate_iespnet\" : learning_rate_iespnet,\n",
    "           \"learning_rate_dsf\"     : learning_rate_dsf,\n",
    "           \"batch_size\"            : batch_size,\n",
    "           \"num_workers\"           : num_workers,\n",
    "           \"epochs\"                : epochs\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DynamicSpatialFilter(\n",
    "                              n_channels, \n",
    "                              mlp_input            = mlp_input, \n",
    "                              n_out_channels       = dsf_n_out_channels, \n",
    "                              apply_soft_thresh    = dsf_soft_thresh\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = iESPnet(\n",
    "                 hparams['n_cnn_layers'],\n",
    "                 hparams['n_rnn_layers'],\n",
    "                 hparams['rnn_dim'],\n",
    "                 hparams['n_class'],\n",
    "                 hparams['out_ch'],\n",
    "                 hparams['dropout'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path        = '/media/martin/Disco2/Rns_Data/experimentos/dsf_iespnet_noprocess/exp3/'\n",
    "experiment       = 'exp3.2'\n",
    "save_models      = save_path + experiment + '/models/'\n",
    "save_predictions = save_path + experiment + '/results/'\n",
    "outputfile       = save_models + 'model_' + experiment\n",
    "best_path        = outputfile + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id  = ['PIT-RNS1090', 'PIT-RNS8973', 'PIT-RNS1438', 'PIT-RNS8326', 'PIT-RNS3016']\n",
    "vali_id  = ['PIT-RNS1603', 'PIT-RNS1556', 'PIT-RNS1534', 'PIT-RNS6989', 'PIT-RNS2543', 'PIT-RNS7168', 'PIT-RNS6762']\n",
    "\n",
    "\n",
    "train_df = df_meta.copy()\n",
    "test_df  = pd.DataFrame()\n",
    "vali_df  = pd.DataFrame()\n",
    "\n",
    "for s in range (len(test_id)):\n",
    "    test_df = pd.concat([test_df, df_meta[df_meta['rns_id'] == test_id[s]]])\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == test_id[s]].index, inplace = True)\n",
    "\n",
    "for s in range(len(vali_id)):\n",
    "    vali_df=pd.concat([vali_df, df_meta[df_meta['rns_id'] == vali_id[s]]])\n",
    "    vali_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.drop(train_df[train_df['rns_id'] == vali_id[s]].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_train = train_df['rns_id'].unique().tolist()\n",
    "patients_test  = test_df['rns_id'].unique().tolist()\n",
    "patients_vali  = vali_df['rns_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thr = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in training:  PIT-RNS9183\n"
     ]
    }
   ],
   "source": [
    "print('in training: ', patients_train[s] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range (len(patients_train)):\n",
    "    # Dataloaders creados\n",
    "    train_data = SeizureDatasetLabelTimev2(\n",
    "                                           file             = train_df[train_df['rns_id'] == patients_train[s]],\n",
    "                                           root_dir         = SPE_DIR,\n",
    "                                           transform        = None, \n",
    "                                           target_transform = smoothing_label(),\n",
    "                                          )\n",
    "    \n",
    "    print()\n",
    "    print('in training')\n",
    "    # in training\n",
    "    outputs_train = test_model_dsf_iespnet_abl_perpatient(model1, model2, hparams, best_path, train_data)\n",
    "    prediction_tr = get_performance_indices(outputs_train['y_true'], outputs_train['y_prob'], best_thr)\n",
    "\n",
    "    predict_ = { \n",
    "                \"prediction_tr\"   : prediction_tr,\n",
    "               }\n",
    "    \n",
    "    np.save(save_predictions + patients_train[s] + '_results.npy', predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rns_id</th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rns_id, data, label, time]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vali_df[vali_df['rns_id'] == patients_vali[s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "in validation:  PIT-RNS1603\n",
      "Using cuda device\n",
      "torch.Size([64, 4, 22500])\n",
      "torch.Size([64, 4, 22500])\n",
      "torch.Size([64, 4, 22500])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min validation: \u001b[39m\u001b[38;5;124m'\u001b[39m,patients_vali[s])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# in validation\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m outputs_vali \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model_dsf_iespnet_abl_perpatient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvali_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m prediction_va \u001b[38;5;241m=\u001b[39m get_performance_indices(outputs_vali[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m], outputs_vali[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_prob\u001b[39m\u001b[38;5;124m'\u001b[39m], best_thr)\n\u001b[1;32m     16\u001b[0m predict_ \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_va\u001b[39m\u001b[38;5;124m\"\u001b[39m   : prediction_va,\n\u001b[1;32m     18\u001b[0m             }\n",
      "File \u001b[0;32m~/Documentos/PI-Thalamus/01 Thalamus-PI/iESPnet_SRC_main/utilities/TrainEval.py:1567\u001b[0m, in \u001b[0;36mtest_model_dsf_iespnet_abl_perpatient\u001b[0;34m(model1, model2, hparams, model_path, test_data)\u001b[0m\n\u001b[1;32m   1564\u001b[0m model2\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m   1566\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data, batch_size\u001b[38;5;241m=\u001b[39mhparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1567\u001b[0m outputs     \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction_abl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;66;03m# Process is completed.\u001b[39;00m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting process has finished.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/PI-Thalamus/01 Thalamus-PI/iESPnet_SRC_main/utilities/TrainEval.py:1838\u001b[0m, in \u001b[0;36mget_prediction_abl\u001b[0;34m(model1, model2, device, loader)\u001b[0m\n\u001b[1;32m   1835\u001b[0m outputs1 \u001b[38;5;241m=\u001b[39m (outputs1 \u001b[38;5;241m-\u001b[39m outputs1\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m outputs1\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;66;03m# normalizacion global\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m outputs1 \u001b[38;5;241m=\u001b[39m outputs1\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1838\u001b[0m spectrograms \u001b[38;5;241m=\u001b[39m \u001b[43mget_spectrogram_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mECOG_SAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPEC_NFFT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPEC_WIN_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPEC_HOP_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_db\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1839\u001b[0m spectrograms \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(spectrograms)\n\u001b[1;32m   1840\u001b[0m spectrograms \u001b[38;5;241m=\u001b[39m spectrograms\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documentos/PI-Thalamus/01 Thalamus-PI/iESPnet_SRC_main/utilities/IO.py:253\u001b[0m, in \u001b[0;36mget_spectrogram_2\u001b[0;34m(signal, device, fs, n_fft, win_len, hop_len, top_db, power)\u001b[0m\n\u001b[1;32m    251\u001b[0m spec   \u001b[38;5;241m=\u001b[39m spectrogram(signal)\n\u001b[1;32m    252\u001b[0m spec   \u001b[38;5;241m=\u001b[39m spec\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 253\u001b[0m spec   \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_to_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_db\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# save up to 60 Hz\u001b[39;00m\n\u001b[1;32m    256\u001b[0m idx_60 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(freqs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documentos/environments/env_thalamus/lib/python3.10/site-packages/librosa/core/spectrum.py:1814\u001b[0m, in \u001b[0;36mpower_to_db\u001b[0;34m(S, ref, amin, top_db)\u001b[0m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1812\u001b[0m     ref_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(ref)\n\u001b[0;32m-> 1814\u001b[0m log_spec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmagnitude\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1815\u001b[0m log_spec \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mmaximum(amin, ref_value))\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_db \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for s in range (len(patients_vali)):\n",
    "    # testing data should be balanced, just be \"as it is\"\n",
    "    vali_data  = SeizureDatasetLabelTimev2(\n",
    "                                            file             = vali_df[vali_df['rns_id'] == patients_vali[s]],\n",
    "                                            root_dir         = SPE_DIR,\n",
    "                                            transform        = None,\n",
    "                                            target_transform = smoothing_label()  \n",
    "                                            )\n",
    "\n",
    "    print()\n",
    "    print('in validation: ',patients_vali[s])\n",
    "    # in validation\n",
    "    outputs_vali = test_model_dsf_iespnet_abl_perpatient(model1, model2, hparams, best_path, vali_data)\n",
    "    prediction_va = get_performance_indices(outputs_vali['y_true'], outputs_vali['y_prob'], best_thr)\n",
    "\n",
    "    predict_ = { \n",
    "                \"prediction_va\"   : prediction_va,\n",
    "                }\n",
    "\n",
    "    np.save(save_predictions + patients_vali[s] + '_results.npy', predict_)\n",
    "\n",
    "    del vali_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range (len(patients_test)):\n",
    "    # testing data should be balanced, just be \"as it is\"\n",
    "    test_data  = SeizureDatasetLabelTimev2(\n",
    "                                           file             = test_df,\n",
    "                                           root_dir         = SPE_DIR,\n",
    "                                           transform        = None,\n",
    "                                           target_transform = smoothing_label()  \n",
    "                                          )\n",
    "    \n",
    "    print()\n",
    "    print('in testing')\n",
    "    # in testing\n",
    "    outputs_test  = test_model_dsf_iespnet_abl_perpatient(model1, model2, hparams, best_path, test_data)\n",
    "    prediction_te = get_performance_indices(outputs_test['y_true'], outputs_test['y_prob'], best_thr)\n",
    "\n",
    "    predict_ = { \n",
    "                \"prediction_te\"   : prediction_te,\n",
    "               }\n",
    "    \n",
    "    np.save(save_predictions + patients_test[s] + '_results.npy', predict_)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data should be balanced, just be \"as it is\"\n",
    "tes_data  = SeizureDatasetLabelTimev2(\n",
    "                                       file             = vali_df,\n",
    "                                       root_dir         = SPE_DIR,\n",
    "                                       transform        = None,\n",
    "                                       target_transform = smoothing_label()  \n",
    "                                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_thalamus)",
   "language": "python",
   "name": "env_thalamus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
