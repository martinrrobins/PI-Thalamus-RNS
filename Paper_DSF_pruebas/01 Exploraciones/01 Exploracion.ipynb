{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import mne\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mne.datasets.utils import _get_path\n",
    "from mne.datasets.sleep_physionet._utils import _fetch_one\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset\n",
    "from braindecode.preprocessing.preprocess import _preprocess, preprocess, Preprocessor\n",
    "from braindecode.preprocessing.windowers  import _create_windows_from_events\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC18_DIR           = op.join('..','..','..','03 Dynamic-Spatial-Filtering', 'data', 'pc18')\n",
    "PC18_RECORDS       = op.join(PC18_DIR, 'sleep_records.csv')\n",
    "PC18_INFO          = op.join(PC18_DIR, 'age-sex.csv')\n",
    "PC18_SHA1_TRAINING = op.join(PC18_DIR, 'training_SHA1SUMS')\n",
    "PC18_SHA1_TEST     = op.join(PC18_DIR, 'test_SHA1SUMS')\n",
    "PC18_URL           = 'https://physionet.org/files/challenge-2018/1.0.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_records = pd.read_csv(PC18_RECORDS)\n",
    "df_info    = pd.read_csv(PC18_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Record</th>\n",
       "      <th>Record type</th>\n",
       "      <th>Split</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>sha</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>te03-0024</td>\n",
       "      <td>PSG</td>\n",
       "      <td>test</td>\n",
       "      <td>31</td>\n",
       "      <td>male</td>\n",
       "      <td>fe9a52b00a81a8c2c29ec30b4f8e0d21e0d1d0b8</td>\n",
       "      <td>test/te03-0024/te03-0024.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>te03-0024</td>\n",
       "      <td>Header</td>\n",
       "      <td>test</td>\n",
       "      <td>31</td>\n",
       "      <td>male</td>\n",
       "      <td>52b31029da8454f01610745c27eb07d0bda7c301</td>\n",
       "      <td>test/te03-0024/te03-0024.hea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>te03-0031</td>\n",
       "      <td>Header</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>573dc478c0219adb9c66229222dcd3b3a5febafb</td>\n",
       "      <td>test/te03-0031/te03-0031.hea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>te03-0031</td>\n",
       "      <td>PSG</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>de56e1df7cb0d8856eeb900f182e9a3b7f96a4f7</td>\n",
       "      <td>test/te03-0031/te03-0031.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>te03-0032</td>\n",
       "      <td>Header</td>\n",
       "      <td>test</td>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>1fe5c7bd48e9346da4e1082cea42483a2b3f5469</td>\n",
       "      <td>test/te03-0032/te03-0032.hea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject     Record Record type Split  Age   Sex  \\\n",
       "0        0  te03-0024         PSG  test   31  male   \n",
       "1        0  te03-0024      Header  test   31  male   \n",
       "2        1  te03-0031      Header  test   55  male   \n",
       "3        1  te03-0031         PSG  test   55  male   \n",
       "4        2  te03-0032      Header  test   50  male   \n",
       "\n",
       "                                        sha                         fname  \n",
       "0  fe9a52b00a81a8c2c29ec30b4f8e0d21e0d1d0b8  test/te03-0024/te03-0024.mat  \n",
       "1  52b31029da8454f01610745c27eb07d0bda7c301  test/te03-0024/te03-0024.hea  \n",
       "2  573dc478c0219adb9c66229222dcd3b3a5febafb  test/te03-0031/te03-0031.hea  \n",
       "3  de56e1df7cb0d8856eeb900f182e9a3b7f96a4f7  test/te03-0031/te03-0031.mat  \n",
       "4  1fe5c7bd48e9346da4e1082cea42483a2b3f5469  test/te03-0032/te03-0032.hea  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4960 entries, 0 to 4959\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Subject      4960 non-null   int64 \n",
      " 1   Record       4960 non-null   object\n",
      " 2   Record type  4960 non-null   object\n",
      " 3   Split        4960 non-null   object\n",
      " 4   Age          4960 non-null   int64 \n",
      " 5   Sex          4960 non-null   object\n",
      " 6   sha          4960 non-null   object\n",
      " 7   fname        4960 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 310.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_records.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PSG', 'Header', 'Arousal'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_records['Record type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>tr14-0268</td>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>tr14-0272</td>\n",
       "      <td>F</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>tr14-0276</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>tr14-0278</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>tr14-0291</td>\n",
       "      <td>M</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Record Sex  Age\n",
       "1978  tr14-0268   M   49\n",
       "1979  tr14-0272   F   62\n",
       "1980  tr14-0276   M   32\n",
       "1981  tr14-0278   F   73\n",
       "1982  tr14-0291   M   80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1983 entries, 0 to 1982\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Record  1983 non-null   object\n",
      " 1   Sex     1983 non-null   object\n",
      " 2   Age     1983 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 46.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una clase que se encuentra en dataset.py que se piensa que es para cargar el set de datos: necesita de otras funciones como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para guardar localmente el dataset\n",
    "\n",
    "def _data_path(path=None, force_update=False, update_path=None, verbose=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Get path to local copy of PC18 dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    key =  'PC18_DATASET_PATH'\n",
    "    name = 'PC18_DATASET_SLEEP'\n",
    "    path = _get_path(path, key, name)\n",
    "    subdirs = os.listdir(path)\n",
    "\n",
    "    if 'training' in subdirs or 'test' in subdirs:  # the specified path is\n",
    "        # already at the training and test folders level\n",
    "        return path\n",
    "    else:\n",
    "        return op.join('/media/martin/Disco2', 'Dsf_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pc18_data(subjects, path=None, force_update=False, update_path=None, base_url=PC18_URL, verbose=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Get paths to local copies of PhysioNet Challenge 2018 dataset files.\n",
    "\n",
    "    This will fetch data from the publicly available PhysioNet Computing in\n",
    "    Cardiology Challenge 2018 dataset on sleep arousal detection [1]_ [2]_.\n",
    "    This corresponds to 1983 recordings from individual subjects with\n",
    "    (suspected) sleep apnea. The dataset is separated into a training set with\n",
    "    994 recordings for which arousal annotation are available and a test set\n",
    "    with 989 recordings for which the labels have not been revealed. Across the\n",
    "    entire dataset, mean age is 55 years old and 65% of recordings are from\n",
    "    male subjects.\n",
    "\n",
    "    More information can be found on the\n",
    "    `physionet website <https://physionet.org/content/challenge-2018/1.0.0/>`_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subjects : list of int\n",
    "        The subjects to use. Can be in the range of 0-1982 (inclusive). Test\n",
    "        recordings are 0-988, while training recordings are 989-1982.\n",
    "    path : None | str\n",
    "        Location of where to look for the PC18 data storing location. If None,\n",
    "        the environment variable or config parameter ``PC18_DATASET_PATH``\n",
    "        is used. If it doesn't exist, the \"~/mne_data\" directory is used. If\n",
    "        the dataset is not found under the given path, the data will be\n",
    "        automatically downloaded to the specified folder.\n",
    "    force_update : bool\n",
    "        Force update of the dataset even if a local copy exists.\n",
    "    update_path : bool | None\n",
    "        If True, set the PC18_DATASET_PATH in mne-python config to the given\n",
    "        path. If None, the user is prompted.\n",
    "    base_url : str\n",
    "        The URL root.\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paths : list\n",
    "        List of local data paths of the given type.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Mohammad M Ghassemi, Benjamin E Moody, Li-wei H Lehman, Christopher\n",
    "      Song, Qiao Li, Haoqi Sun, Roger G Mark, M Brandon Westover, Gari D\n",
    "      Clifford. You Snooze, You Win: the PhysioNet/Computing in Cardiology\n",
    "      Challenge 2018.\n",
    "    .. [2] Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C.,\n",
    "      Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and\n",
    "      PhysioNet: Components of a new research resource for complex physiologic\n",
    "      signals. Circulation [Online]. 101 (23), pp. e215–e220.)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    records         = pd.read_csv(PC18_RECORDS)\n",
    "    psg_records     = records[records['Record type'] == 'PSG']\n",
    "    hea_records     = records[records['Record type'] == 'Header']\n",
    "    arousal_records = records[records['Record type'] == 'Arousal']\n",
    "\n",
    "    path            = _data_path(path=path, update_path=update_path)\n",
    "    params          = [path, force_update, base_url]\n",
    "\n",
    "    fnames          = []\n",
    "    for subject in subjects:\n",
    "        for idx in np.where(psg_records['Subject'] == subject)[0]:\n",
    "            psg_fname = _fetch_one(psg_records['fname'].iloc[idx], psg_records['sha'].iloc[idx], *params)\n",
    "            hea_fname = _fetch_one(hea_records['fname'].iloc[idx], hea_records['sha'].iloc[idx], *params)\n",
    "            if psg_records['Split'].iloc[idx] == 'training':\n",
    "                train_idx = np.where(\n",
    "                    arousal_records['Subject'] == subject)[0][0]\n",
    "                arousal_fname = _fetch_one(\n",
    "                    arousal_records['fname'].iloc[train_idx],\n",
    "                    arousal_records['sha'].iloc[train_idx], *params)\n",
    "            else:\n",
    "                arousal_fname = None\n",
    "            fnames.append([psg_fname, hea_fname, arousal_fname])\n",
    "\n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wfdb_anns_to_mne_annotations(annots):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Convert wfdb.io.Annotation format to MNE's.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    annots : wfdb.io.Annotation\n",
    "        Annotation object obtained by e.g. loading an annotation file with\n",
    "        wfdb.rdann().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mne.Annotations :\n",
    "        MNE Annotations object.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ann_chs = set(annots.chan)\n",
    "    onsets = annots.sample / annots.fs\n",
    "    new_onset, new_duration, new_description = list(), list(), list()\n",
    "    for ch in ann_chs:\n",
    "        mask = annots.chan == ch\n",
    "        ch_onsets = onsets[mask]\n",
    "        ch_descs = np.array(annots.aux_note)[mask]\n",
    "\n",
    "        # Events with beginning and end, defined by '(event' and 'event)'\n",
    "        if all([(i.startswith('(') or i.endswith(')')) for i in ch_descs]):\n",
    "            pass\n",
    "        else:  # Sleep stage-like annotations\n",
    "            ch_durations = np.concatenate([np.diff(ch_onsets), [30]])\n",
    "            assert all(ch_durations > 0), 'Negative duration'\n",
    "            new_onset.extend(ch_onsets)\n",
    "            new_duration.extend(ch_durations)\n",
    "            new_description.extend(ch_descs)\n",
    "\n",
    "    mne_annots = mne.Annotations(new_onset, new_duration, new_description, orig_time=None)\n",
    "\n",
    "    return mne_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PC18(BaseConcatDataset):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Physionet Challenge 2018 polysomnography dataset.\n",
    "\n",
    "    Sleep dataset from https://physionet.org/content/challenge-2018/1.0.0/.\n",
    "    Contains overnight recordings from 1983 healthy subjects.\n",
    "\n",
    "    See `fetch_pc18_data` for a more complete description.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject_ids: list(int) | str | None\n",
    "        (list of) int of subject(s) to be loaded. If None, load all available\n",
    "        subjects. If 'training', load all training recordings. If 'test', load\n",
    "        all test recordings.\n",
    "    path : None | str\n",
    "        Location of where to look for the PC18 data storing location. If None,\n",
    "        the environment variable or config parameter ``MNE_DATASETS_PC18_PATH``\n",
    "        is used. If it doesn't exist, the \"~/mne_data\" directory is used. If\n",
    "        the dataset is not found under the given path, the data will be\n",
    "        automatically downloaded to the specified folder.\n",
    "    load_eeg_only: bool\n",
    "        If True, only load the EEG channels and discard the others (EOG, EMG,\n",
    "        temperature, respiration) to avoid resampling the other signals.\n",
    "    preproc : list(Preprocessor) | None\n",
    "        List of preprocessors to apply to each file individually. This way the\n",
    "        data can e.g., be downsampled (temporally and spatially) to limit the\n",
    "        memory usage of the entire Dataset object. This also enables applying\n",
    "        preprocessing in parallel over the recordings.\n",
    "    windower : callable | None\n",
    "        Function to split the raw data into windows. If provided, windowing is\n",
    "        integrated into the loading process (after preprocessing) such that\n",
    "        memory usage is minized while allowing parallelization.\n",
    "    n_jobs : int\n",
    "        Number of parallel processes.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, subject_ids=None, path=None, load_eeg_only=True, preproc=None, windower=None, n_jobs=1):\n",
    "        paths = fetch_pc18_data(subject_ids, path=path)\n",
    "        self.info_df = pd.read_csv(PC18_INFO)\n",
    "\n",
    "        if n_jobs == 1:\n",
    "            all_base_ds = [self._load_raw(subject_id, p[0], p[2], load_eeg_only=load_eeg_only,\n",
    "                preproc=preproc, windower=windower)\n",
    "                for subject_id, p in zip(subject_ids, paths)]\n",
    "        else:\n",
    "            all_base_ds = Parallel(n_jobs=n_jobs)(delayed(self._load_raw)(\n",
    "                subject_id, p[0], p[2], load_eeg_only=load_eeg_only,\n",
    "                preproc=preproc, windower=windower)\n",
    "                for subject_id, p in zip(subject_ids, paths))\n",
    "        super().__init__(all_base_ds)\n",
    "\n",
    "    def _load_raw(self, subj_nb, raw_fname, arousal_fname, load_eeg_only, preproc, windower):\n",
    "        raw_fname     = raw_fname[0] if isinstance(raw_fname, tuple) else raw_fname\n",
    "        arousal_fname = arousal_fname[0] if isinstance(arousal_fname, tuple) else arousal_fname\n",
    "\n",
    "\n",
    "        channel_types = ['eeg'] * 7\n",
    "        if load_eeg_only:\n",
    "            channels  = list(range(7))\n",
    "        else:\n",
    "            channel_types += ['emg', 'misc', 'misc', 'misc', 'misc', 'ecg']\n",
    "            channels  = None\n",
    "\n",
    "        # Load raw signals and header\n",
    "        record = wfdb.io.rdrecord(op.splitext(raw_fname)[0], channels=channels)\n",
    "\n",
    "        # Convert to right units for MNE (EEG should be in V)\n",
    "        data = record.p_signal.T\n",
    "        data[np.array(record.units) == 'uV'] /= 1e6\n",
    "        data[np.array(record.units) == 'mV'] /= 1e3\n",
    "        info = mne.create_info(record.sig_name, record.fs, channel_types)\n",
    "        out = mne.io.RawArray(data, info)\n",
    "\n",
    "        # Extract annotations\n",
    "        if arousal_fname is not None:\n",
    "            annots = wfdb.rdann(\n",
    "                                op.splitext(raw_fname)[0], 'arousal', sampfrom=0, sampto=None,\n",
    "                                shift_samps=False, return_label_elements=['symbol'],\n",
    "                                summarize_labels=False\n",
    "                               )\n",
    "            mne_annots = convert_wfdb_anns_to_mne_annotations(annots)\n",
    "            out.set_annotations(mne_annots)\n",
    "        record_name = op.splitext(op.basename(raw_fname))[0]\n",
    "        print(record_name)\n",
    "        record_info = self.info_df[\n",
    "            self.info_df['Record'] == record_name].iloc[0]\n",
    "        if record_info['Record'].startswith('tr'):\n",
    "            split = 'training'\n",
    "        elif record_info['Record'].startswith('te'):\n",
    "            split = 'test'\n",
    "        else:\n",
    "            split = 'unknown'\n",
    "\n",
    "        desc = pd.Series({\n",
    "            'subject': subj_nb,\n",
    "            'record': record_info['Record'],\n",
    "            'split': split,\n",
    "            'age': record_info['Age'],\n",
    "            'sex': record_info['Sex']\n",
    "        }, name='')\n",
    "        out = BaseDataset(out, desc)\n",
    "        print(out)\n",
    "        if preproc is not None:\n",
    "            _preprocess(out, None, preproc)\n",
    "\n",
    "        if windower is not None:\n",
    "            out = windower(out)\n",
    "            out.windows.load_data()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, k):\n",
    "    return k * x\n",
    "\n",
    "def cast(x, dtype):\n",
    "    return x.astype(dtype)\n",
    "\n",
    "def load_data(dataset, window_size_s, n_jobs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Load, preprocess and window data.\n",
    "    \n",
    "    \"\"\"       \n",
    "\n",
    "    subject_ids = [989, 990, 991]\n",
    "    ch_names    = ['F3-M2', 'F4-M1', 'O1-M2', 'O2-M1']\n",
    "    preproc     = [\n",
    "                  Preprocessor('pick_channels', ch_names=ch_names, ordered=True),\n",
    "                  Preprocessor('filter', l_freq=None, h_freq=30, n_jobs=1),\n",
    "                  Preprocessor('resample', sfreq=100., n_jobs=1),\n",
    "                  Preprocessor(scale, k=1e6),\n",
    "                  Preprocessor(cast, dtype=np.float32)\n",
    "                  ]\n",
    "\n",
    "    window_size_samples = int(window_size_s * 100)\n",
    "    mapping             = {'W': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'R': 4}\n",
    "    windower            = partial(\n",
    "                                 _create_windows_from_events, \n",
    "                                 infer_mapping=False,\n",
    "                                 infer_window_size_stride=False, \n",
    "                                 trial_start_offset_samples=0,\n",
    "                                 trial_stop_offset_samples=0,\n",
    "                                 window_size_samples=window_size_samples,\n",
    "                                 window_stride_samples=window_size_samples, \n",
    "                                 mapping=mapping\n",
    "                                 )\n",
    "\n",
    "    dataset = PC18(subject_ids=subject_ids, preproc=preproc, windower=windower, n_jobs=n_jobs)\n",
    "    return dataset\n",
    "\n",
    "windows_dataset = load_data('pc18_debug', 30, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuación luego de cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.PC18 object at 0x7f4d0bd482b0>\n"
     ]
    }
   ],
   "source": [
    "print(windows_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "available_classes = windows_dataset.get_metadata()['target'].unique()\n",
    "print(available_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
